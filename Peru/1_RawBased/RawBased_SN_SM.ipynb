{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RawBased sin normalizar y sin cálculo de matrices de distancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = os.path.abspath('')\n",
    "my_path = my_path.split('\\\\')\n",
    "my_path_py = \"\\\\\".join(my_path[:-1])\n",
    "\n",
    "DF_TOTAL_T=pd.read_csv(my_path_py+'\\\\DatosRaw\\\\DEN_2015to2020.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Son  505  distritos\n"
     ]
    }
   ],
   "source": [
    "listaDistrito = DF_TOTAL_T['Dep-Prov-Distrito'].tolist()\n",
    "listaDistrito = list(dict.fromkeys(listaDistrito))\n",
    "print('Son ', len(listaDistrito), ' distritos')\n",
    "listaDistrito.sort()\n",
    "#print(listaDistrito)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeSeries = pd.read_csv(my_path_py+'\\\\DatosRaw\\\\SerieTemporal_Casos_2015to2020.csv', sep=',')\n",
    "timeSeries = timeSeries.fillna(0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>308</th>\n",
       "      <th>309</th>\n",
       "      <th>310</th>\n",
       "      <th>311</th>\n",
       "      <th>312</th>\n",
       "      <th>313</th>\n",
       "      <th>314</th>\n",
       "      <th>315</th>\n",
       "      <th>316</th>\n",
       "      <th>317</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows × 318 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9  ...      308      309  \\\n",
       "0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.00001  0.00001   \n",
       "1    1.0  1.0  1.0  1.0  3.0  0.0  0.0  0.0  0.0  0.0  ...  4.00000  7.00000   \n",
       "2    0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.00001  0.00001   \n",
       "3    1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.00001  0.00001   \n",
       "4    1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.00001  0.00001   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...      ...      ...   \n",
       "500  3.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.00001  0.00001   \n",
       "501  3.0  1.0  2.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  ...  0.00000  0.00000   \n",
       "502  1.0  1.0  1.0  1.0  2.0  0.0  0.0  0.0  0.0  0.0  ...  0.00001  0.00001   \n",
       "503  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.00000  0.00000   \n",
       "504  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.00001  0.00001   \n",
       "\n",
       "         310       311      312      313      314      315      316      317  \n",
       "0    0.00001   0.00001  0.00001  0.00001  0.00001  0.00001  0.00001  0.00001  \n",
       "1    6.00000  10.00000  1.00000  4.00000  3.00000  9.00000  4.00000  1.00000  \n",
       "2    0.00001   0.00001  0.00001  0.00001  0.00001  0.00001  0.00001  0.00001  \n",
       "3    0.00001   0.00001  0.00001  0.00001  0.00001  0.00001  0.00001  0.00001  \n",
       "4    0.00001   0.00001  0.00001  0.00001  0.00001  0.00001  0.00001  0.00001  \n",
       "..       ...       ...      ...      ...      ...      ...      ...      ...  \n",
       "500  0.00001   0.00001  0.00001  0.00001  0.00001  0.00001  0.00001  0.00001  \n",
       "501  0.00000   0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  \n",
       "502  0.00001   0.00001  0.00001  0.00001  0.00001  0.00001  0.00001  0.00001  \n",
       "503  0.00000   0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  \n",
       "504  0.00001   0.00001  0.00001  0.00001  0.00001  0.00001  0.00001  0.00001  \n",
       "\n",
       "[505 rows x 318 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeSeries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de Distancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import sqrt, log, floor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statistics import mean\n",
    "from fastdtw import fastdtw\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "#Euclidean\n",
    "def euclidean(x, y):\n",
    "    r=np.linalg.norm(x-y)\n",
    "    if math.isnan(r):\n",
    "        r=1\n",
    "    #print(r)\n",
    "    return r\n",
    "\n",
    "#Fast Dynamic time warping\n",
    "def fast_DTW(x, y):\n",
    "    r, _ = fastdtw(x, y, dist=euclidean)\n",
    "    if math.isnan(r):\n",
    "        r=1\n",
    "    #print(r)\n",
    "    return r\n",
    "\n",
    "#Spearman\n",
    "def scorr(x, y):\n",
    "    r = stats.spearmanr(x, y)[0]\n",
    "    if math.isnan(r):\n",
    "        r=0\n",
    "    #print(r)\n",
    "    return 1 - r\n",
    "\n",
    "#RMSE\n",
    "def rmse(x, y):\n",
    "    r=sqrt(mean_squared_error(x,y))\n",
    "    if math.isnan(r):\n",
    "        r=1\n",
    "    #print(r)\n",
    "    return r\n",
    "\n",
    "def lcs(a, b):  \n",
    "    lengths = [[0 for j in range(len(b)+1)] for i in range(len(a)+1)]\n",
    "    # row 0 and column 0 are initialized to 0 already\n",
    "    for i, x in enumerate(a):\n",
    "        for j, y in enumerate(b):\n",
    "            if x == y:\n",
    "                lengths[i+1][j+1] = lengths[i][j] + 1\n",
    "            else:\n",
    "                lengths[i+1][j+1] = max(lengths[i+1][j], lengths[i][j+1])\n",
    "    x, y = len(a), len(b)\n",
    "    result = lengths[x][y]\n",
    "    return result\n",
    "\n",
    "def discretise(x):\n",
    "    return int(x * 10)\n",
    "\n",
    "def multidim_lcs(a, b):\n",
    "    a = a.applymap(discretise)\n",
    "    b = b.applymap(discretise)\n",
    "    rows, dims = a.shape\n",
    "    lcss = [lcs(a[i+2], b[i+2]) for i in range(dims)]\n",
    "    return 1 - sum(lcss) / (rows * dims)\n",
    "\n",
    "#Correlation\n",
    "def corr(x, y):\n",
    "    r=np.dot(x-mean(x),y-mean(y))/((np.linalg.norm(x-mean(x)))*(np.linalg.norm(y-mean(y))))\n",
    "    if math.isnan(r):\n",
    "        r=0\n",
    "    #print(r)\n",
    "    return 1 - r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n= timeSeries.shape[0]\n",
    "timeSeries = timeSeries.replace('nan', np.nan).fillna(0.000001)\n",
    "timeSeries = timeSeries.replace([np.inf, -np.inf], np.nan).fillna(0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(505, 318)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeSeries.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de distancia euclidiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Euclidean\n",
    "euclidean_dist = pd.read_csv('MatrizEuclidiana_RB.csv', sep=',').to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de DTW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DTW \n",
    "dtw_dist = pd.read_csv('MatrizDTW_RB.csv', sep=',').to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de correlación de Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_dist = pd.read_csv('MatrizPearson_RB.csv', sep=',').to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de correlación de Spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scorr\n",
    "scorr_dist = pd.read_csv('MatrizSpearman_RB.csv', sep=',').to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINICIÓN DEL NÚMERO DE CLUSTERS K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "DIAMETER_METHODS = ['mean_cluster', 'farthest']\n",
    "CLUSTER_DISTANCE_METHODS = ['nearest', 'farthest']\n",
    "\n",
    "def inter_cluster_distances(labels, distances, method='nearest'):\n",
    "    \"\"\"Calculates the distances between the two nearest points of each cluster.\n",
    "    :param labels: a list containing cluster labels for each of the n elements\n",
    "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
    "    :param method: `nearest` for the distances between the two nearest points in each cluster, or `farthest`\n",
    "    \"\"\"\n",
    "    if method not in CLUSTER_DISTANCE_METHODS:\n",
    "        raise ValueError(\n",
    "            'method must be one of {}'.format(CLUSTER_DISTANCE_METHODS))\n",
    "\n",
    "    if method == 'nearest':\n",
    "        return __cluster_distances_by_points(labels, distances)\n",
    "    elif method == 'farthest':\n",
    "        return __cluster_distances_by_points(labels, distances, farthest=True)\n",
    "\n",
    "\n",
    "def __cluster_distances_by_points(labels, distances, farthest=False):\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    cluster_distances = np.full((n_unique_labels, n_unique_labels),\n",
    "                                float('inf') if not farthest else 0)\n",
    "\n",
    "    np.fill_diagonal(cluster_distances, 0)\n",
    "\n",
    "    for i in np.arange(0, len(labels) - 1):\n",
    "        for ii in np.arange(i, len(labels)):\n",
    "            if labels[i] != labels[ii] and (\n",
    "                (not farthest and\n",
    "                 distances[i, ii] < cluster_distances[labels[i], labels[ii]])\n",
    "                    or\n",
    "                (farthest and\n",
    "                 distances[i, ii] > cluster_distances[labels[i], labels[ii]])):\n",
    "                cluster_distances[labels[i], labels[ii]] = cluster_distances[\n",
    "                    labels[ii], labels[i]] = distances[i, ii]\n",
    "    return cluster_distances\n",
    "\n",
    "\n",
    "def diameter(labels, distances, method='farthest'):\n",
    "    \"\"\"Calculates cluster diameters\n",
    "    :param labels: a list containing cluster labels for each of the n elements\n",
    "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
    "    :param method: either `mean_cluster` for the mean distance between all elements in each cluster, or `farthest` for the distance between the two points furthest from each other\n",
    "    \"\"\"\n",
    "    if method not in DIAMETER_METHODS:\n",
    "        raise ValueError('method must be one of {}'.format(DIAMETER_METHODS))\n",
    "\n",
    "    n_clusters = len(np.unique(labels))\n",
    "    diameters = np.zeros(n_clusters)\n",
    "\n",
    "    if method == 'mean_cluster':\n",
    "        for i in range(0, len(labels) - 1):\n",
    "            for ii in range(i + 1, len(labels)):\n",
    "                if labels[i] == labels[ii]:\n",
    "                    diameters[labels[i]] += distances[i, ii]\n",
    "\n",
    "        for i in range(len(diameters)):\n",
    "            diameters[i] /= sum(labels == i)\n",
    "\n",
    "    elif method == 'farthest':\n",
    "        for i in range(0, len(labels) - 1):\n",
    "            for ii in range(i + 1, len(labels)):\n",
    "                if labels[i] == labels[ii] and distances[i, ii] > diameters[\n",
    "                        labels[i]]:\n",
    "                    diameters[labels[i]] = distances[i, ii]\n",
    "    return diameters\n",
    "\n",
    "def dunn(labels, distances, diameter_method='farthest',\n",
    "         cdist_method='nearest'):\n",
    "    \"\"\"\n",
    "    Dunn index for cluster validation (larger is better).\n",
    "    \n",
    "    .. math:: D = \\\\min_{i = 1 \\\\ldots n_c; j = i + 1\\ldots n_c} \\\\left\\\\lbrace \\\\frac{d \\\\left( c_i,c_j \\\\right)}{\\\\max_{k = 1 \\\\ldots n_c} \\\\left(diam \\\\left(c_k \\\\right) \\\\right)} \\\\right\\\\rbrace\n",
    "    \n",
    "    where :math:`d(c_i,c_j)` represents the distance between\n",
    "    clusters :math:`c_i` and :math:`c_j`, and :math:`diam(c_k)` is the diameter of cluster :math:`c_k`.\n",
    "    Inter-cluster distance can be defined in many ways, such as the distance between cluster centroids or between their closest elements. Cluster diameter can be defined as the mean distance between all elements in the cluster, between all elements to the cluster centroid, or as the distance between the two furthest elements.\n",
    "    The higher the value of the resulting Dunn index, the better the clustering\n",
    "    result is considered, since higher values indicate that clusters are\n",
    "    compact (small :math:`diam(c_k)`) and far apart (large :math:`d \\\\left( c_i,c_j \\\\right)`).\n",
    "    :param labels: a list containing cluster labels for each of the n elements\n",
    "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
    "    :param diameter_method: see :py:function:`diameter` `method` parameter\n",
    "    :param cdist_method: see :py:function:`diameter` `method` parameter\n",
    "    \n",
    "    .. [Kovacs2005] Kovács, F., Legány, C., & Babos, A. (2005). Cluster validity measurement techniques. 6th International Symposium of Hungarian Researchers on Computational Intelligence.\n",
    "    \"\"\"\n",
    "\n",
    "    labels = LabelEncoder().fit(labels).transform(labels)\n",
    "    \n",
    "    \n",
    "\n",
    "    ic_distances = inter_cluster_distances(labels, distances, cdist_method)\n",
    "    #print(\"IC\",ic_distances)\n",
    "    if len(ic_distances[ic_distances.nonzero()])==0:\n",
    "        min_distance = 0\n",
    "    else:\n",
    "        min_distance = min(ic_distances[ic_distances.nonzero()])\n",
    "    max_diameter = max(diameter(labels, distances, diameter_method))\n",
    "    \n",
    "    \n",
    "\n",
    "    return min_distance / max_diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\cluster\\hierarchy.py:826: ClusterWarning: scipy.cluster: The symmetric non-negative hollow observation matrix looks suspiciously like an uncondensed distance matrix\n",
      "  return linkage(y, method='ward', metric='euclidean')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAC + euclidian distance: \n",
      "SC:  0.7555016941885081\n",
      "CHZ:  2149.2529957382853\n",
      "DUNN:  0.11975131490841735\n",
      "Davies:  0.5770749020222979\n",
      "-------------------\n",
      "HAC + corr distance: \n",
      "SC:  0.6190350105023912\n",
      "CHZ:  619.1839505561219\n",
      "DUNN:  0.9073348158248457\n",
      "Davies:  0.8417970647671499\n",
      "-------------------\n",
      "HAC + scorr distance: \n",
      "SC:  0.6126581791919001\n",
      "CHZ:  525.5057120536561\n",
      "DUNN:  0.6536554202840612\n",
      "Davies:  1.07069044045481\n",
      "-------------------\n",
      "HAC + dtw distance: \n",
      "SC:  0.6555852427676193\n",
      "CHZ:  1026.8588895779778\n",
      "DUNN:  0.16831485155576842\n",
      "Davies:  0.8281366236479585\n"
     ]
    }
   ],
   "source": [
    "import scipy.cluster.hierarchy as hac\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "SIL =[]\n",
    "CHZ_ =[]\n",
    "DUNN_ =[]\n",
    "DAVIES_ =[]\n",
    "\n",
    "#Experimentos HAC\n",
    "HAC_euc = AgglomerativeClustering(n_clusters=k).fit_predict(euclidean_dist)\n",
    "print(\"HAC + euclidian distance: \")\n",
    "sil = silhouette_score(euclidean_dist, HAC_euc)\n",
    "cal= calinski_harabasz_score(euclidean_dist, HAC_euc)\n",
    "davies_ = davies_bouldin_score(euclidean_dist, HAC_euc)\n",
    "try:\n",
    "    dunn_ = dunn(HAC_euc, euclidean_dist, 'farthest', 'farthest')\n",
    "except:\n",
    "    dunn_ = np.nan\n",
    "print(\"SC: \", sil)\n",
    "print(\"CHZ: \", cal)\n",
    "print(\"DUNN: \", dunn_)\n",
    "print(\"Davies: \", davies_)\n",
    "\n",
    "SIL.append(sil)\n",
    "CHZ_.append(cal)\n",
    "DUNN_.append(dunn_)\n",
    "DAVIES_.append(davies_)\n",
    "\n",
    "print(\"-------------------\")\n",
    "\n",
    "HAC_corr = AgglomerativeClustering(n_clusters=k).fit_predict(corr_dist)\n",
    "print(\"HAC + corr distance: \")\n",
    "sil = silhouette_score(corr_dist, HAC_corr)\n",
    "cal= calinski_harabasz_score(corr_dist, HAC_corr)\n",
    "davies_ = davies_bouldin_score(corr_dist, HAC_corr)\n",
    "try:\n",
    "    dunn_ = dunn(HAC_corr, corr_dist, 'farthest', 'farthest')\n",
    "except:\n",
    "    dunn_ = np.nan\n",
    "print(\"SC: \", sil)\n",
    "print(\"CHZ: \", cal)\n",
    "print(\"DUNN: \", dunn_)\n",
    "print(\"Davies: \", davies_)\n",
    "SIL.append(sil)\n",
    "CHZ_.append(cal)\n",
    "DUNN_.append(dunn_)\n",
    "DAVIES_.append(davies_)\n",
    "\n",
    "print(\"-------------------\")\n",
    "\n",
    "HAC_scorr = AgglomerativeClustering(n_clusters=k).fit_predict(scorr_dist)\n",
    "print(\"HAC + scorr distance: \")\n",
    "sil = silhouette_score(scorr_dist, HAC_scorr)\n",
    "cal= calinski_harabasz_score(scorr_dist, HAC_scorr)\n",
    "davies_ = davies_bouldin_score(scorr_dist, HAC_scorr)\n",
    "try:\n",
    "    dunn_ = dunn(HAC_scorr, scorr_dist, 'farthest', 'farthest')\n",
    "except:\n",
    "    dunn_ = np.nan\n",
    "print(\"SC: \", sil)\n",
    "print(\"CHZ: \", cal)\n",
    "print(\"DUNN: \", dunn_)\n",
    "print(\"Davies: \", davies_)\n",
    "SIL.append(sil)\n",
    "CHZ_.append(cal)\n",
    "DUNN_.append(dunn_)\n",
    "DAVIES_.append(davies_)\n",
    "\n",
    "print(\"-------------------\")\n",
    "\n",
    "HAC_dtw = AgglomerativeClustering(n_clusters=k).fit_predict(dtw_dist)\n",
    "print(\"HAC + dtw distance: \")\n",
    "sil = silhouette_score(dtw_dist, HAC_dtw)\n",
    "cal= calinski_harabasz_score(dtw_dist, HAC_dtw)\n",
    "davies_ = davies_bouldin_score(dtw_dist, HAC_dtw)\n",
    "try:\n",
    "    dunn_ = dunn(HAC_dtw, dtw_dist, 'farthest', 'farthest')\n",
    "except:\n",
    "    dunn_ = np.nan\n",
    "print(\"SC: \", sil)\n",
    "print(\"CHZ: \", cal)\n",
    "print(\"DUNN: \", dunn_)\n",
    "print(\"Davies: \", davies_)\n",
    "SIL.append(sil)\n",
    "CHZ_.append(cal)\n",
    "DUNN_.append(dunn_)\n",
    "DAVIES_.append(davies_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KM + euclidian distance: \n",
      "SC:  0.7557470937069032\n",
      "CHZ:  2309.263534551376\n",
      "DUNN:  0.08672637194806244\n",
      "Davies:  0.583980416750956\n",
      "-------------------------\n",
      "KM + corr distance: \n",
      "SC:  0.6456727940230521\n",
      "CHZ:  680.4616441978287\n",
      "DUNN:  0.9073348158248457\n",
      "Davies:  0.8259558808091633\n",
      "-------------------------\n",
      "KM + scorr distance: \n",
      "HAC + scorr distance: \n",
      "SC:  0.6425007187825584\n",
      "CHZ:  629.7328450128024\n",
      "DUNN:  0.6598149279470464\n",
      "Davies:  0.9218236134012923\n",
      "-------------------------\n",
      "KM + dtw distance: \n",
      "SC:  0.6819160897430984\n",
      "CHZ:  1178.5735016005247\n",
      "DUNN:  0.16592498550933762\n",
      "Davies:  0.8098672437092652\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "\n",
    "km_euc = KMeans(n_clusters=k).fit_predict(euclidean_dist)\n",
    "silhouette_avg=silhouette_score(euclidean_dist, km_euc)\n",
    "print(\"KM + euclidian distance: \")\n",
    "sil = silhouette_score(euclidean_dist, km_euc)\n",
    "cal= calinski_harabasz_score(euclidean_dist, km_euc)\n",
    "davies_ = davies_bouldin_score(euclidean_dist, km_euc)\n",
    "try:\n",
    "    dunn_ = dunn(km_euc, euclidean_dist, 'farthest', 'farthest')\n",
    "except:\n",
    "    dunn_ = np.nan\n",
    "print(\"SC: \", sil)\n",
    "print(\"CHZ: \", cal)\n",
    "print(\"DUNN: \", dunn_)\n",
    "print(\"Davies: \", davies_)\n",
    "\n",
    "SIL.append(sil)\n",
    "CHZ_.append(cal)\n",
    "DUNN_.append(dunn_)\n",
    "DAVIES_.append(davies_)\n",
    "\n",
    "print(\"-------------------------\")\n",
    "\n",
    "km_corr = KMeans(n_clusters=k).fit_predict(corr_dist)\n",
    "print(\"KM + corr distance: \")\n",
    "sil = silhouette_score(corr_dist, km_corr)\n",
    "cal= calinski_harabasz_score(corr_dist, km_corr)\n",
    "davies_ = davies_bouldin_score(corr_dist, km_corr)\n",
    "try:\n",
    "    dunn_ = dunn(km_corr, corr_dist, 'farthest', 'farthest')\n",
    "except:\n",
    "    dunn_ = np.nan\n",
    "print(\"SC: \", sil)\n",
    "print(\"CHZ: \", cal)\n",
    "print(\"DUNN: \", dunn_)\n",
    "print(\"Davies: \", davies_)\n",
    "SIL.append(sil)\n",
    "CHZ_.append(cal)\n",
    "DUNN_.append(dunn_)\n",
    "DAVIES_.append(davies_)\n",
    "\n",
    "print(\"-------------------------\")\n",
    "\n",
    "km_scorr = KMeans(n_clusters=k).fit_predict(scorr_dist)\n",
    "print(\"KM + scorr distance: \")\n",
    "HAC_scorr = AgglomerativeClustering(n_clusters=k).fit_predict(scorr_dist)\n",
    "print(\"HAC + scorr distance: \")\n",
    "sil = silhouette_score(scorr_dist, km_scorr)\n",
    "cal= calinski_harabasz_score(scorr_dist, km_scorr)\n",
    "davies_ = davies_bouldin_score(scorr_dist, km_scorr)\n",
    "try:\n",
    "    dunn_ = dunn(km_scorr, scorr_dist, 'farthest', 'farthest')\n",
    "except:\n",
    "    dunn_ = np.nan\n",
    "print(\"SC: \", sil)\n",
    "print(\"CHZ: \", cal)\n",
    "print(\"DUNN: \", dunn_)\n",
    "print(\"Davies: \", davies_)\n",
    "SIL.append(sil)\n",
    "CHZ_.append(cal)\n",
    "DUNN_.append(dunn_)\n",
    "DAVIES_.append(davies_)\n",
    "\n",
    "print(\"-------------------------\")\n",
    "\n",
    "km_dtw = KMeans(n_clusters=k).fit_predict(dtw_dist)\n",
    "print(\"KM + dtw distance: \")\n",
    "sil = silhouette_score(dtw_dist, km_dtw)\n",
    "cal= calinski_harabasz_score(dtw_dist, km_dtw)\n",
    "davies_ = davies_bouldin_score(dtw_dist, km_dtw)\n",
    "try:\n",
    "    dunn_ = dunn(km_dtw, dtw_dist, 'farthest', 'farthest')\n",
    "except:\n",
    "    dunn_ = np.nan\n",
    "print(\"SC: \", sil)\n",
    "print(\"CHZ: \", cal)\n",
    "print(\"DUNN: \", dunn_)\n",
    "print(\"Davies: \", davies_)\n",
    "SIL.append(sil)\n",
    "CHZ_.append(cal)\n",
    "DUNN_.append(dunn_)\n",
    "DAVIES_.append(davies_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentos DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El puntaje es negativo porque los puntos están en promedio más cerca de otro cluster, que del cuál ha sido asignado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_lista = np.arange (0.01, 4, 0.01)\n",
    "sil_list = []\n",
    "for e in epsilon_lista:\n",
    "    try:\n",
    "        DB_corr = DBSCAN(eps=e, min_samples=5).fit_predict(corr_dist)\n",
    "        sil = silhouette_score(corr_dist, DB_corr)\n",
    "        sil_list.append(sil)\n",
    "    except:\n",
    "        pass\n",
    "plt.plot(sil_list)\n",
    "print('Epsilon máximo: ', epsilon_lista[np.argmax(sil_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBScan + euclidian distance: \n",
      "SC:  0.4363244592044793\n",
      "CHZ:  76.7500119068537\n",
      "DUNN:  0.03158907587512208\n",
      "Davies:  0.9179159240166097\n",
      "---------------------------\n",
      "DBSCAN + corr distance: \n",
      "SC:  0.5759711275056483\n",
      "CHZ:  211.11032606123806\n",
      "DUNN:  0.9073348158248457\n",
      "Davies:  1.18497296190995\n",
      "---------------------------\n",
      "DBSCAN + scorr distance: \n",
      "SC:  0.5012463692160323\n",
      "CHZ:  116.54561489053813\n",
      "DUNN:  0.5004913103340635\n",
      "Davies:  1.1216694940326069\n",
      "---------------------------\n",
      "DBSCAN + dtw distance: \n",
      "SC:  0.27347640108948756\n",
      "CHZ:  53.83544045872255\n",
      "DUNN:  0.0009625094847589598\n",
      "Davies:  1.1073656398681977\n"
     ]
    }
   ],
   "source": [
    "DB_euc = DBSCAN(eps=220, min_samples=3).fit_predict(euclidean_dist)\n",
    "print(\"DBScan + euclidian distance: \")\n",
    "sil = silhouette_score(euclidean_dist, DB_euc)\n",
    "cal= calinski_harabasz_score(euclidean_dist, DB_euc)\n",
    "davies_ = davies_bouldin_score(euclidean_dist, DB_euc)\n",
    "try:\n",
    "    dunn_ = dunn(DB_euc, euclidean_dist, 'farthest', 'farthest')\n",
    "except:\n",
    "    dunn_ = np.nan\n",
    "print(\"SC: \", sil)\n",
    "print(\"CHZ: \", cal)\n",
    "print(\"DUNN: \", dunn_)\n",
    "print(\"Davies: \", davies_)\n",
    "\n",
    "SIL.append(sil)\n",
    "CHZ_.append(cal)\n",
    "DUNN_.append(dunn_)\n",
    "DAVIES_.append(davies_)\n",
    "\n",
    "print(\"---------------------------\")\n",
    "\n",
    "#CON CORRELATION\n",
    "DB_corr = DBSCAN(eps=1.61, min_samples=3).fit_predict(corr_dist)\n",
    "print(\"DBSCAN + corr distance: \")\n",
    "sil = silhouette_score(corr_dist, DB_corr)\n",
    "cal= calinski_harabasz_score(corr_dist, DB_corr)\n",
    "davies_ = davies_bouldin_score(corr_dist, DB_corr)\n",
    "try:\n",
    "    dunn_ = dunn(DB_corr, corr_dist, 'farthest', 'farthest')\n",
    "except:\n",
    "    dunn_ = np.nan\n",
    "print(\"SC: \", sil)\n",
    "print(\"CHZ: \", cal)\n",
    "print(\"DUNN: \", dunn_)\n",
    "print(\"Davies: \", davies_)\n",
    "SIL.append(sil)\n",
    "CHZ_.append(cal)\n",
    "DUNN_.append(dunn_)\n",
    "DAVIES_.append(davies_)\n",
    "\n",
    "print(\"---------------------------\")\n",
    "\n",
    "#CON SPEARMAN\n",
    "DB_scorr = DBSCAN(eps=1.61, min_samples=3).fit_predict(scorr_dist)\n",
    "print(\"DBSCAN + scorr distance: \")\n",
    "sil = silhouette_score(scorr_dist, DB_scorr)\n",
    "cal= calinski_harabasz_score(scorr_dist, DB_scorr)\n",
    "davies_ = davies_bouldin_score(scorr_dist, DB_scorr)\n",
    "try:\n",
    "    dunn_ = dunn(DB_scorr, scorr_dist, 'farthest', 'farthest')\n",
    "except:\n",
    "    dunn_ = np.nan\n",
    "print(\"SC: \", sil)\n",
    "print(\"CHZ: \", cal)\n",
    "print(\"DUNN: \", dunn_)\n",
    "print(\"Davies: \", davies_)\n",
    "SIL.append(sil)\n",
    "CHZ_.append(cal)\n",
    "DUNN_.append(dunn_)\n",
    "DAVIES_.append(davies_)\n",
    "print(\"---------------------------\")\n",
    "\n",
    "#CON D TIME WARPING\n",
    "DB_dtw = DBSCAN(eps=220, min_samples=5).fit_predict(dtw_dist)\n",
    "print(\"DBSCAN + dtw distance: \")\n",
    "sil = silhouette_score(dtw_dist, DB_dtw)\n",
    "cal= calinski_harabasz_score(dtw_dist, DB_dtw)\n",
    "davies_ = davies_bouldin_score(dtw_dist, DB_dtw)\n",
    "try:\n",
    "    dunn_ = dunn(DB_dtw, dtw_dist, 'farthest', 'farthest')\n",
    "except:\n",
    "    dunn_ = np.nan\n",
    "print(\"SC: \", sil)\n",
    "print(\"CHZ: \", cal)\n",
    "print(\"DUNN: \", dunn_)\n",
    "print(\"Davies: \", davies_)\n",
    "\n",
    "SIL.append(sil)\n",
    "CHZ_.append(cal)\n",
    "DUNN_.append(dunn_)\n",
    "DAVIES_.append(davies_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux2 = pd.DataFrame()\n",
    "aux2['Dep-Prov-Distrito'] =listaDistrito\n",
    "aux2['Cluster KM Eu'] = km_euc\n",
    "aux2['Cluster HAC Eu'] = HAC_euc\n",
    "aux2['Cluster DB Pear'] = DB_corr\n",
    "aux2.to_csv('ClusterRBCasos_Peru.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1,  2,  3,  4,  5,  6,  7], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(DB_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metrica</th>\n",
       "      <th>SIL HAC RB</th>\n",
       "      <th>SIL KM RB</th>\n",
       "      <th>SIL DB RB</th>\n",
       "      <th>CHZ HAC RB</th>\n",
       "      <th>CHZ KM RB</th>\n",
       "      <th>CHZ DB RB</th>\n",
       "      <th>DUNN HAC RB</th>\n",
       "      <th>DUNN KM RB</th>\n",
       "      <th>DUNN DB RB</th>\n",
       "      <th>DAVIES HAC RB</th>\n",
       "      <th>DAVIES KM RB</th>\n",
       "      <th>DAVIES DB RB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Euclidean</td>\n",
       "      <td>0.755502</td>\n",
       "      <td>0.755747</td>\n",
       "      <td>0.436324</td>\n",
       "      <td>2149.252996</td>\n",
       "      <td>2309.263535</td>\n",
       "      <td>76.750012</td>\n",
       "      <td>0.119751</td>\n",
       "      <td>0.086726</td>\n",
       "      <td>0.031589</td>\n",
       "      <td>0.577075</td>\n",
       "      <td>0.583980</td>\n",
       "      <td>0.917916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pearson</td>\n",
       "      <td>0.619035</td>\n",
       "      <td>0.645673</td>\n",
       "      <td>0.575971</td>\n",
       "      <td>619.183951</td>\n",
       "      <td>680.461644</td>\n",
       "      <td>211.110326</td>\n",
       "      <td>0.907335</td>\n",
       "      <td>0.907335</td>\n",
       "      <td>0.907335</td>\n",
       "      <td>0.841797</td>\n",
       "      <td>0.825956</td>\n",
       "      <td>1.184973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spearman</td>\n",
       "      <td>0.612658</td>\n",
       "      <td>0.642501</td>\n",
       "      <td>0.501246</td>\n",
       "      <td>525.505712</td>\n",
       "      <td>629.732845</td>\n",
       "      <td>116.545615</td>\n",
       "      <td>0.653655</td>\n",
       "      <td>0.659815</td>\n",
       "      <td>0.500491</td>\n",
       "      <td>1.070690</td>\n",
       "      <td>0.921824</td>\n",
       "      <td>1.121669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTW</td>\n",
       "      <td>0.655585</td>\n",
       "      <td>0.681916</td>\n",
       "      <td>0.273476</td>\n",
       "      <td>1026.858890</td>\n",
       "      <td>1178.573502</td>\n",
       "      <td>53.835440</td>\n",
       "      <td>0.168315</td>\n",
       "      <td>0.165925</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.828137</td>\n",
       "      <td>0.809867</td>\n",
       "      <td>1.107366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Metrica  SIL HAC RB  SIL KM RB  SIL DB RB   CHZ HAC RB    CHZ KM RB  \\\n",
       "0  Euclidean    0.755502   0.755747   0.436324  2149.252996  2309.263535   \n",
       "1    Pearson    0.619035   0.645673   0.575971   619.183951   680.461644   \n",
       "2   Spearman    0.612658   0.642501   0.501246   525.505712   629.732845   \n",
       "3        DTW    0.655585   0.681916   0.273476  1026.858890  1178.573502   \n",
       "\n",
       "    CHZ DB RB  DUNN HAC RB  DUNN KM RB  DUNN DB RB  DAVIES HAC RB  \\\n",
       "0   76.750012     0.119751    0.086726    0.031589       0.577075   \n",
       "1  211.110326     0.907335    0.907335    0.907335       0.841797   \n",
       "2  116.545615     0.653655    0.659815    0.500491       1.070690   \n",
       "3   53.835440     0.168315    0.165925    0.000963       0.828137   \n",
       "\n",
       "   DAVIES KM RB  DAVIES DB RB  \n",
       "0      0.583980      0.917916  \n",
       "1      0.825956      1.184973  \n",
       "2      0.921824      1.121669  \n",
       "3      0.809867      1.107366  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_m = []    \n",
    "list_m.append('Euclidean')\n",
    "list_m.append('Pearson')\n",
    "list_m.append('Spearman')\n",
    "list_m.append('DTW')\n",
    "\n",
    "df_sc = pd.DataFrame()   \n",
    "df_sc['Metrica'] = list_m\n",
    "\n",
    "df_sc['SIL HAC RB'] = [SIL[0], SIL[1], SIL[2], SIL[3]]\n",
    "df_sc['SIL KM RB'] = [SIL[4], SIL[5], SIL[6], SIL[7]]\n",
    "df_sc['SIL DB RB'] = [SIL[8], SIL[9], SIL[10], SIL[11]]\n",
    "\n",
    "df_sc['CHZ HAC RB'] = [CHZ_[0], CHZ_[1], CHZ_[2], CHZ_[3]]\n",
    "df_sc['CHZ KM RB'] = [CHZ_[4], CHZ_[5], CHZ_[6], CHZ_[7]]\n",
    "df_sc['CHZ DB RB'] = [CHZ_[8], CHZ_[9], CHZ_[10], CHZ_[11]]\n",
    "\n",
    "\n",
    "df_sc['DUNN HAC RB'] = [DUNN_[0], DUNN_[1], DUNN_[2], DUNN_[3]]\n",
    "df_sc['DUNN KM RB'] = [DUNN_[4], DUNN_[5], DUNN_[6], DUNN_[7]]\n",
    "df_sc['DUNN DB RB'] = [DUNN_[8], DUNN_[9], DUNN_[10], DUNN_[11]]\n",
    "\n",
    "df_sc['DAVIES HAC RB'] = [DAVIES_[0], DAVIES_[1], DAVIES_[2], DAVIES_[3]]\n",
    "df_sc['DAVIES KM RB'] = [DAVIES_[4], DAVIES_[5], DAVIES_[6], DAVIES_[7]]\n",
    "df_sc['DAVIES DB RB'] = [DAVIES_[8], DAVIES_[9], DAVIES_[10], DAVIES_[11]]\n",
    "\n",
    "\n",
    "df_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sc.to_csv('SilScoreRBCasos_2015to2020.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
