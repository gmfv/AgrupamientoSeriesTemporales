{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE BASED QUE FUNCIONA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizando librería Kats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input\n",
    "18Features_Kats.csv\n",
    "\n",
    "#### Outputs\n",
    "ClusterFBNorm.csv\n",
    "18Features_Norm.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "#import tsfeature as tsf\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import pprint\n",
    "from sklearn.decomposition import PCA\n",
    "from kats.consts import TimeSeriesData\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from kats.utils.simulator import Simulator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from kats.tsfeatures.tsfeatures import TsFeatures\n",
    "from scipy.stats import entropy\n",
    "from math import log, e\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = os.path.abspath('')\n",
    "my_path = my_path.split('\\\\')\n",
    "my_path_py = \"\\\\\".join(my_path[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.40807022e-03, 6.04858662e-05, 0.00000000e+00, ...,\n",
       "        1.90476190e-01, 3.95852476e-02, 4.45512821e-01],\n",
       "       [2.48051182e-02, 3.51195163e-04, 0.00000000e+00, ...,\n",
       "        8.33333333e-01, 4.17731600e-02, 3.23717949e-01],\n",
       "       [2.79150599e-03, 3.55606686e-05, 0.00000000e+00, ...,\n",
       "        7.14285714e-02, 3.95926742e-02, 9.61538462e-03],\n",
       "       ...,\n",
       "       [4.03070071e-02, 6.90913318e-03, 0.00000000e+00, ...,\n",
       "        1.90476190e-01, 2.55042767e-01, 1.34615385e-01],\n",
       "       [2.01928911e-02, 1.28111532e-03, 0.00000000e+00, ...,\n",
       "        1.66666667e-01, 8.75781682e-02, 9.77564103e-01],\n",
       "       [1.07941131e-03, 1.34897852e-05, 0.00000000e+00, ...,\n",
       "        2.38095238e-02, 1.24509179e-02, 3.84615385e-02]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "features = pd.read_csv(my_path_py+'\\\\2_FeatureBased\\\\MatrizFeatures\\\\18Features_Kats.csv', sep=',')\n",
    "listaDistrito = list(features['Dep-Prov-Distrito'].values)\n",
    "features = features.drop('Dep-Prov-Distrito', axis=1)\n",
    "scaler =  MinMaxScaler()\n",
    "scaler = scaler.fit(features)\n",
    "normalized = scaler.transform(features)\n",
    "normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Var</th>\n",
       "      <th>aCF1</th>\n",
       "      <th>Trend</th>\n",
       "      <th>Linearity</th>\n",
       "      <th>Curvature</th>\n",
       "      <th>Season</th>\n",
       "      <th>Peak</th>\n",
       "      <th>Trough</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Lumpiness</th>\n",
       "      <th>Spikiness</th>\n",
       "      <th>Lshift</th>\n",
       "      <th>Vchange</th>\n",
       "      <th>Fspots</th>\n",
       "      <th>Cpoints</th>\n",
       "      <th>KlScore</th>\n",
       "      <th>ChangeIdx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.416142</td>\n",
       "      <td>28.037741</td>\n",
       "      <td>-0.019594</td>\n",
       "      <td>0.478521</td>\n",
       "      <td>0.057369</td>\n",
       "      <td>16.105723</td>\n",
       "      <td>0.259515</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>0.877947</td>\n",
       "      <td>1.123065e+03</td>\n",
       "      <td>0.131363</td>\n",
       "      <td>2.235336</td>\n",
       "      <td>453.036663</td>\n",
       "      <td>15</td>\n",
       "      <td>8.0</td>\n",
       "      <td>722.122511</td>\n",
       "      <td>139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.968925</td>\n",
       "      <td>162.793719</td>\n",
       "      <td>-0.019594</td>\n",
       "      <td>0.698416</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>24.055788</td>\n",
       "      <td>0.408785</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.000000e-11</td>\n",
       "      <td>0.809780</td>\n",
       "      <td>2.782585e+04</td>\n",
       "      <td>0.171691</td>\n",
       "      <td>3.804760</td>\n",
       "      <td>1683.966820</td>\n",
       "      <td>29</td>\n",
       "      <td>35.0</td>\n",
       "      <td>762.034875</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.896803</td>\n",
       "      <td>16.483865</td>\n",
       "      <td>-0.019594</td>\n",
       "      <td>0.511541</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>-1.342372</td>\n",
       "      <td>0.448205</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.000000e-11</td>\n",
       "      <td>0.853613</td>\n",
       "      <td>4.816986e+02</td>\n",
       "      <td>0.024675</td>\n",
       "      <td>1.563966</td>\n",
       "      <td>244.599033</td>\n",
       "      <td>15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>722.257988</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.277973</td>\n",
       "      <td>84.933434</td>\n",
       "      <td>-0.019594</td>\n",
       "      <td>0.308881</td>\n",
       "      <td>0.013646</td>\n",
       "      <td>-1.388677</td>\n",
       "      <td>0.487622</td>\n",
       "      <td>1.000000e-11</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.816967</td>\n",
       "      <td>1.288353e+04</td>\n",
       "      <td>3.156452</td>\n",
       "      <td>3.415301</td>\n",
       "      <td>1166.427782</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>185.725861</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.691190</td>\n",
       "      <td>6.586993</td>\n",
       "      <td>-0.019594</td>\n",
       "      <td>0.775271</td>\n",
       "      <td>0.109978</td>\n",
       "      <td>13.397455</td>\n",
       "      <td>0.358239</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.000000e-11</td>\n",
       "      <td>0.793282</td>\n",
       "      <td>1.484992e+02</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.995897</td>\n",
       "      <td>109.760378</td>\n",
       "      <td>26</td>\n",
       "      <td>9.0</td>\n",
       "      <td>677.073513</td>\n",
       "      <td>264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>6.635039</td>\n",
       "      <td>321.295085</td>\n",
       "      <td>-0.019594</td>\n",
       "      <td>0.723762</td>\n",
       "      <td>0.005861</td>\n",
       "      <td>23.381332</td>\n",
       "      <td>0.341699</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>0.773567</td>\n",
       "      <td>1.297361e+05</td>\n",
       "      <td>1.234726</td>\n",
       "      <td>5.865676</td>\n",
       "      <td>3440.615516</td>\n",
       "      <td>26</td>\n",
       "      <td>8.0</td>\n",
       "      <td>803.206199</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>6.295408</td>\n",
       "      <td>399.615990</td>\n",
       "      <td>-0.019594</td>\n",
       "      <td>0.780696</td>\n",
       "      <td>0.019926</td>\n",
       "      <td>-36.253978</td>\n",
       "      <td>0.306853</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>0.765285</td>\n",
       "      <td>5.349600e+05</td>\n",
       "      <td>3.651875</td>\n",
       "      <td>10.209300</td>\n",
       "      <td>9195.444576</td>\n",
       "      <td>31</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1820.287731</td>\n",
       "      <td>212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>12.949082</td>\n",
       "      <td>3202.673627</td>\n",
       "      <td>-0.019594</td>\n",
       "      <td>0.690501</td>\n",
       "      <td>0.045318</td>\n",
       "      <td>-175.632538</td>\n",
       "      <td>0.530664</td>\n",
       "      <td>1.000000e-11</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>0.859131</td>\n",
       "      <td>3.691856e+07</td>\n",
       "      <td>872.908533</td>\n",
       "      <td>31.860500</td>\n",
       "      <td>83632.763411</td>\n",
       "      <td>21</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4652.544429</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>6.487195</td>\n",
       "      <td>593.850800</td>\n",
       "      <td>-0.019594</td>\n",
       "      <td>0.839640</td>\n",
       "      <td>0.059928</td>\n",
       "      <td>111.830241</td>\n",
       "      <td>0.290624</td>\n",
       "      <td>1.000000e-11</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.733766</td>\n",
       "      <td>1.151792e+06</td>\n",
       "      <td>2.262564</td>\n",
       "      <td>10.373444</td>\n",
       "      <td>5509.147684</td>\n",
       "      <td>31</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1597.619581</td>\n",
       "      <td>305.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.346773</td>\n",
       "      <td>6.253082</td>\n",
       "      <td>-0.019594</td>\n",
       "      <td>0.183448</td>\n",
       "      <td>0.006657</td>\n",
       "      <td>-1.879678</td>\n",
       "      <td>0.266920</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>0.988549</td>\n",
       "      <td>6.980402e+01</td>\n",
       "      <td>0.169676</td>\n",
       "      <td>0.918949</td>\n",
       "      <td>84.446675</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>227.132294</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Mean          Var      aCF1     Trend  Linearity   Curvature  \\\n",
       "0     1.416142    28.037741 -0.019594  0.478521   0.057369   16.105723   \n",
       "1     7.968925   162.793719 -0.019594  0.698416   0.005168   24.055788   \n",
       "2     0.896803    16.483865 -0.019594  0.511541   0.000878   -1.342372   \n",
       "3     1.277973    84.933434 -0.019594  0.308881   0.013646   -1.388677   \n",
       "4     0.691190     6.586993 -0.019594  0.775271   0.109978   13.397455   \n",
       "..         ...          ...       ...       ...        ...         ...   \n",
       "500   6.635039   321.295085 -0.019594  0.723762   0.005861   23.381332   \n",
       "501   6.295408   399.615990 -0.019594  0.780696   0.019926  -36.253978   \n",
       "502  12.949082  3202.673627 -0.019594  0.690501   0.045318 -175.632538   \n",
       "503   6.487195   593.850800 -0.019594  0.839640   0.059928  111.830241   \n",
       "504   0.346773     6.253082 -0.019594  0.183448   0.006657   -1.879678   \n",
       "\n",
       "       Season          Peak        Trough   Entropy     Lumpiness   Spikiness  \\\n",
       "0    0.259515  4.000000e+00  6.000000e+00  0.877947  1.123065e+03    0.131363   \n",
       "1    0.408785  3.000000e+00  1.000000e-11  0.809780  2.782585e+04    0.171691   \n",
       "2    0.448205  4.000000e+00  1.000000e-11  0.853613  4.816986e+02    0.024675   \n",
       "3    0.487622  1.000000e-11  1.000000e+00  0.816967  1.288353e+04    3.156452   \n",
       "4    0.358239  3.000000e+00  1.000000e-11  0.793282  1.484992e+02    0.000393   \n",
       "..        ...           ...           ...       ...           ...         ...   \n",
       "500  0.341699  3.000000e+00  6.000000e+00  0.773567  1.297361e+05    1.234726   \n",
       "501  0.306853  2.000000e+00  5.000000e+00  0.765285  5.349600e+05    3.651875   \n",
       "502  0.530664  1.000000e-11  5.000000e+00  0.859131  3.691856e+07  872.908533   \n",
       "503  0.290624  1.000000e-11  1.000000e+00  0.733766  1.151792e+06    2.262564   \n",
       "504  0.266920  3.000000e+00  6.000000e+00  0.988549  6.980402e+01    0.169676   \n",
       "\n",
       "        Lshift       Vchange  Fspots  Cpoints      KlScore  ChangeIdx  \n",
       "0     2.235336    453.036663      15      8.0   722.122511      139.0  \n",
       "1     3.804760   1683.966820      29     35.0   762.034875      101.0  \n",
       "2     1.563966    244.599033      15      3.0   722.257988        3.0  \n",
       "3     3.415301   1166.427782      10      1.0   185.725861       48.0  \n",
       "4     0.995897    109.760378      26      9.0   677.073513      264.0  \n",
       "..         ...           ...     ...      ...          ...        ...  \n",
       "500   5.865676   3440.615516      26      8.0   803.206199       46.0  \n",
       "501  10.209300   9195.444576      31      6.0  1820.287731      212.0  \n",
       "502  31.860500  83632.763411      21      8.0  4652.544429       42.0  \n",
       "503  10.373444   5509.147684      31      7.0  1597.619581      305.0  \n",
       "504   0.918949     84.446675       5      1.0   227.132294       12.0  \n",
       "\n",
       "[505 rows x 18 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Var</th>\n",
       "      <th>aCF1</th>\n",
       "      <th>Trend</th>\n",
       "      <th>Linearity</th>\n",
       "      <th>Curvature</th>\n",
       "      <th>Season</th>\n",
       "      <th>Peak</th>\n",
       "      <th>Trough</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Lumpiness</th>\n",
       "      <th>Spikiness</th>\n",
       "      <th>Lshift</th>\n",
       "      <th>Vchange</th>\n",
       "      <th>Fspots</th>\n",
       "      <th>Cpoints</th>\n",
       "      <th>KlScore</th>\n",
       "      <th>ChangeIdx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004408</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.381939</td>\n",
       "      <td>0.106686</td>\n",
       "      <td>0.756941</td>\n",
       "      <td>0.149136</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884457</td>\n",
       "      <td>7.897180e-09</td>\n",
       "      <td>4.222889e-09</td>\n",
       "      <td>0.014841</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.039585</td>\n",
       "      <td>0.445513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.024805</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.653582</td>\n",
       "      <td>0.009611</td>\n",
       "      <td>0.758684</td>\n",
       "      <td>0.369945</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.815785</td>\n",
       "      <td>1.956661e-07</td>\n",
       "      <td>5.519277e-09</td>\n",
       "      <td>0.025260</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.041773</td>\n",
       "      <td>0.323718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002792</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.422729</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.753115</td>\n",
       "      <td>0.428258</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.859943</td>\n",
       "      <td>3.387212e-09</td>\n",
       "      <td>7.932337e-10</td>\n",
       "      <td>0.010383</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.039593</td>\n",
       "      <td>0.009615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003978</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172377</td>\n",
       "      <td>0.025376</td>\n",
       "      <td>0.753105</td>\n",
       "      <td>0.486565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.823025</td>\n",
       "      <td>9.059452e-08</td>\n",
       "      <td>1.014692e-07</td>\n",
       "      <td>0.022675</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.010181</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.748523</td>\n",
       "      <td>0.204518</td>\n",
       "      <td>0.756347</td>\n",
       "      <td>0.295175</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.799165</td>\n",
       "      <td>1.044218e-09</td>\n",
       "      <td>1.264752e-11</td>\n",
       "      <td>0.006612</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.037116</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.020653</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684892</td>\n",
       "      <td>0.010899</td>\n",
       "      <td>0.758536</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.779304</td>\n",
       "      <td>9.122794e-07</td>\n",
       "      <td>3.969225e-08</td>\n",
       "      <td>0.038943</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.044030</td>\n",
       "      <td>0.147436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.019596</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.755225</td>\n",
       "      <td>0.037056</td>\n",
       "      <td>0.745460</td>\n",
       "      <td>0.219161</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.770960</td>\n",
       "      <td>3.761736e-06</td>\n",
       "      <td>1.173954e-07</td>\n",
       "      <td>0.067781</td>\n",
       "      <td>0.004979</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.099784</td>\n",
       "      <td>0.679487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.040307</td>\n",
       "      <td>0.006909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.643804</td>\n",
       "      <td>0.084274</td>\n",
       "      <td>0.714898</td>\n",
       "      <td>0.550235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.865502</td>\n",
       "      <td>2.596042e-04</td>\n",
       "      <td>2.806106e-05</td>\n",
       "      <td>0.211526</td>\n",
       "      <td>0.045281</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.255043</td>\n",
       "      <td>0.134615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.020193</td>\n",
       "      <td>0.001281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.828040</td>\n",
       "      <td>0.111445</td>\n",
       "      <td>0.777930</td>\n",
       "      <td>0.195155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.739207</td>\n",
       "      <td>8.099177e-06</td>\n",
       "      <td>7.273377e-08</td>\n",
       "      <td>0.068871</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.087578</td>\n",
       "      <td>0.977564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017425</td>\n",
       "      <td>0.012379</td>\n",
       "      <td>0.752997</td>\n",
       "      <td>0.160089</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995880</td>\n",
       "      <td>4.908484e-10</td>\n",
       "      <td>5.454513e-09</td>\n",
       "      <td>0.006101</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.012451</td>\n",
       "      <td>0.038462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mean       Var  aCF1     Trend  Linearity  Curvature    Season  \\\n",
       "0    0.004408  0.000060   0.0  0.381939   0.106686   0.756941  0.149136   \n",
       "1    0.024805  0.000351   0.0  0.653582   0.009611   0.758684  0.369945   \n",
       "2    0.002792  0.000036   0.0  0.422729   0.001633   0.753115  0.428258   \n",
       "3    0.003978  0.000183   0.0  0.172377   0.025376   0.753105  0.486565   \n",
       "4    0.002151  0.000014   0.0  0.748523   0.204518   0.756347  0.295175   \n",
       "..        ...       ...   ...       ...        ...        ...       ...   \n",
       "500  0.020653  0.000693   0.0  0.684892   0.010899   0.758536  0.270708   \n",
       "501  0.019596  0.000862   0.0  0.755225   0.037056   0.745460  0.219161   \n",
       "502  0.040307  0.006909   0.0  0.643804   0.084274   0.714898  0.550235   \n",
       "503  0.020193  0.001281   0.0  0.828040   0.111445   0.777930  0.195155   \n",
       "504  0.001079  0.000013   0.0  0.017425   0.012379   0.752997  0.160089   \n",
       "\n",
       "         Peak    Trough   Entropy     Lumpiness     Spikiness    Lshift  \\\n",
       "0    0.666667  1.000000  0.884457  7.897180e-09  4.222889e-09  0.014841   \n",
       "1    0.500000  0.000000  0.815785  1.956661e-07  5.519277e-09  0.025260   \n",
       "2    0.666667  0.000000  0.859943  3.387212e-09  7.932337e-10  0.010383   \n",
       "3    0.000000  0.166667  0.823025  9.059452e-08  1.014692e-07  0.022675   \n",
       "4    0.500000  0.000000  0.799165  1.044218e-09  1.264752e-11  0.006612   \n",
       "..        ...       ...       ...           ...           ...       ...   \n",
       "500  0.500000  1.000000  0.779304  9.122794e-07  3.969225e-08  0.038943   \n",
       "501  0.333333  0.833333  0.770960  3.761736e-06  1.173954e-07  0.067781   \n",
       "502  0.000000  0.833333  0.865502  2.596042e-04  2.806106e-05  0.211526   \n",
       "503  0.000000  0.166667  0.739207  8.099177e-06  7.273377e-08  0.068871   \n",
       "504  0.500000  1.000000  0.995880  4.908484e-10  5.454513e-09  0.006101   \n",
       "\n",
       "      Vchange    Fspots   Cpoints   KlScore  ChangeIdx  \n",
       "0    0.000245  0.448276  0.190476  0.039585   0.445513  \n",
       "1    0.000912  0.931034  0.833333  0.041773   0.323718  \n",
       "2    0.000132  0.448276  0.071429  0.039593   0.009615  \n",
       "3    0.000632  0.275862  0.023810  0.010181   0.153846  \n",
       "4    0.000059  0.827586  0.214286  0.037116   0.846154  \n",
       "..        ...       ...       ...       ...        ...  \n",
       "500  0.001863  0.827586  0.190476  0.044030   0.147436  \n",
       "501  0.004979  1.000000  0.142857  0.099784   0.679487  \n",
       "502  0.045281  0.655172  0.190476  0.255043   0.134615  \n",
       "503  0.002983  1.000000  0.166667  0.087578   0.977564  \n",
       "504  0.000046  0.103448  0.023810  0.012451   0.038462  \n",
       "\n",
       "[505 rows x 18 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.DataFrame(data = normalized, columns=features.columns) \n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones de Distancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import sqrt, log, floor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statistics import mean\n",
    "#from fastdtw import fastdtw\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "#Euclidean\n",
    "def euclidean(x, y):\n",
    "    r=np.linalg.norm(x-y)\n",
    "    if math.isnan(r):\n",
    "        r=1\n",
    "    #print(r)\n",
    "    return r\n",
    "\n",
    "#Fast Dynamic time warping\n",
    "def fast_DTW(x, y):\n",
    "    r, _ = fastdtw(x, y, dist=euclidean)\n",
    "    if math.isnan(r):\n",
    "        r=1\n",
    "    #print(r)\n",
    "    return r\n",
    "\n",
    "#Spearman\n",
    "def scorr(x, y):\n",
    "    r = stats.spearmanr(x, y)[0]\n",
    "    if math.isnan(r):\n",
    "        r=0\n",
    "    #print(r)\n",
    "    return 1 - r\n",
    "\n",
    "#RMSE\n",
    "def rmse(x, y):\n",
    "    r=sqrt(mean_squared_error(x,y))\n",
    "    if math.isnan(r):\n",
    "        r=1\n",
    "    #print(r)\n",
    "    return r\n",
    "\n",
    "def lcs(a, b):  \n",
    "    lengths = [[0 for j in range(len(b)+1)] for i in range(len(a)+1)]\n",
    "    # row 0 and column 0 are initialized to 0 already\n",
    "    for i, x in enumerate(a):\n",
    "        for j, y in enumerate(b):\n",
    "            if x == y:\n",
    "                lengths[i+1][j+1] = lengths[i][j] + 1\n",
    "            else:\n",
    "                lengths[i+1][j+1] = max(lengths[i+1][j], lengths[i][j+1])\n",
    "    x, y = len(a), len(b)\n",
    "    result = lengths[x][y]\n",
    "    return result\n",
    "\n",
    "def discretise(x):\n",
    "    return int(x * 10)\n",
    "\n",
    "def multidim_lcs(a, b):\n",
    "    a = a.applymap(discretise)\n",
    "    b = b.applymap(discretise)\n",
    "    rows, dims = a.shape\n",
    "    lcss = [lcs(a[i+2], b[i+2]) for i in range(dims)]\n",
    "    return 1 - sum(lcss) / (rows * dims)\n",
    "\n",
    "#Correlation\n",
    "def corr(x, y):\n",
    "    r=np.dot(x-mean(x),y-mean(y))/((np.linalg.norm(x-mean(x)))*(np.linalg.norm(y-mean(y))))\n",
    "    if math.isnan(r):\n",
    "        r=0\n",
    "    #print(r)\n",
    "    return 1 - r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from yellowbrick.cluster import KElbowVisualizer\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "import scipy.cluster.hierarchy as hac\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "\n",
    "DIAMETER_METHODS = ['mean_cluster', 'farthest']\n",
    "CLUSTER_DISTANCE_METHODS = ['nearest', 'farthest']\n",
    "\n",
    "def inter_cluster_distances(labels, distances, method='nearest'):\n",
    "    \"\"\"Calculates the distances between the two nearest points of each cluster.\n",
    "    :param labels: a list containing cluster labels for each of the n elements\n",
    "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
    "    :param method: `nearest` for the distances between the two nearest points in each cluster, or `farthest`\n",
    "    \"\"\"\n",
    "    if method not in CLUSTER_DISTANCE_METHODS:\n",
    "        raise ValueError(\n",
    "            'method must be one of {}'.format(CLUSTER_DISTANCE_METHODS))\n",
    "\n",
    "    if method == 'nearest':\n",
    "        return __cluster_distances_by_points(labels, distances)\n",
    "    elif method == 'farthest':\n",
    "        return __cluster_distances_by_points(labels, distances, farthest=True)\n",
    "\n",
    "\n",
    "def __cluster_distances_by_points(labels, distances, farthest=False):\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    cluster_distances = np.full((n_unique_labels, n_unique_labels),\n",
    "                                float('inf') if not farthest else 0)\n",
    "\n",
    "    np.fill_diagonal(cluster_distances, 0)\n",
    "\n",
    "    for i in np.arange(0, len(labels) - 1):\n",
    "        #print(\"i: \", i)\n",
    "        for ii in np.arange(i, len(labels)):\n",
    "            #print(\"ii: \", ii)\n",
    "            if labels[i] != labels[ii] and (\n",
    "                (not farthest and\n",
    "                 distances[i, ii] < cluster_distances[labels[i], labels[ii]])\n",
    "                    or\n",
    "                (farthest and\n",
    "                 distances[i, ii] > cluster_distances[labels[i], labels[ii]])):\n",
    "                cluster_distances[labels[i], labels[ii]] = cluster_distances[\n",
    "                    labels[ii], labels[i]] = distances[i, ii]\n",
    "    return cluster_distances\n",
    "\n",
    "\n",
    "def diameter(labels, distances, method='farthest'):\n",
    "    \"\"\"Calculates cluster diameters\n",
    "    :param labels: a list containing cluster labels for each of the n elements\n",
    "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
    "    :param method: either `mean_cluster` for the mean distance between all elements in each cluster, or `farthest` for the distance between the two points furthest from each other\n",
    "    \"\"\"\n",
    "    if method not in DIAMETER_METHODS:\n",
    "        raise ValueError('method must be one of {}'.format(DIAMETER_METHODS))\n",
    "\n",
    "    n_clusters = len(np.unique(labels))\n",
    "    diameters = np.zeros(n_clusters)\n",
    "\n",
    "    if method == 'mean_cluster':\n",
    "        for i in range(0, len(labels) - 1):\n",
    "            for ii in range(i + 1, len(labels)):\n",
    "                if labels[i] == labels[ii]:\n",
    "                    diameters[labels[i]] += distances[i, ii]\n",
    "\n",
    "        for i in range(len(diameters)):\n",
    "            diameters[i] /= sum(labels == i)\n",
    "\n",
    "    elif method == 'farthest':\n",
    "        for i in range(0, len(labels) - 1):\n",
    "            for ii in range(i + 1, len(labels)):\n",
    "                if labels[i] == labels[ii] and distances[i, ii] > diameters[\n",
    "                        labels[i]]:\n",
    "                    diameters[labels[i]] = distances[i, ii]\n",
    "    return diameters\n",
    "\n",
    "def dunn(labels, distances, diameter_method='farthest',\n",
    "         cdist_method='nearest'):\n",
    "    \"\"\"\n",
    "    Dunn index for cluster validation (larger is better).\n",
    "    \n",
    "    .. math:: D = \\\\min_{i = 1 \\\\ldots n_c; j = i + 1\\ldots n_c} \\\\left\\\\lbrace \\\\frac{d \\\\left( c_i,c_j \\\\right)}{\\\\max_{k = 1 \\\\ldots n_c} \\\\left(diam \\\\left(c_k \\\\right) \\\\right)} \\\\right\\\\rbrace\n",
    "    \n",
    "    where :math:`d(c_i,c_j)` represents the distance between\n",
    "    clusters :math:`c_i` and :math:`c_j`, and :math:`diam(c_k)` is the diameter of cluster :math:`c_k`.\n",
    "    Inter-cluster distance can be defined in many ways, such as the distance between cluster centroids or between their closest elements. Cluster diameter can be defined as the mean distance between all elements in the cluster, between all elements to the cluster centroid, or as the distance between the two furthest elements.\n",
    "    The higher the value of the resulting Dunn index, the better the clustering\n",
    "    result is considered, since higher values indicate that clusters are\n",
    "    compact (small :math:`diam(c_k)`) and far apart (large :math:`d \\\\left( c_i,c_j \\\\right)`).\n",
    "    :param labels: a list containing cluster labels for each of the n elements\n",
    "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
    "    :param diameter_method: see :py:function:`diameter` `method` parameter\n",
    "    :param cdist_method: see :py:function:`diameter` `method` parameter\n",
    "    \n",
    "    .. [Kovacs2005] Kovács, F., Legány, C., & Babos, A. (2005). Cluster validity measurement techniques. 6th International Symposium of Hungarian Researchers on Computational Intelligence.\n",
    "    \"\"\"\n",
    "\n",
    "    labels = LabelEncoder().fit(labels).transform(labels)\n",
    "    \n",
    "    \n",
    "\n",
    "    ic_distances = inter_cluster_distances(labels, distances, cdist_method)\n",
    "    #print(\"IC\",ic_distances)\n",
    "    if len(ic_distances[ic_distances.nonzero()])==0:\n",
    "        min_distance = 0\n",
    "    else:\n",
    "        min_distance = min(ic_distances[ic_distances.nonzero()])\n",
    "    max_diameter = max(diameter(labels, distances, diameter_method))\n",
    "    \n",
    "    \n",
    "\n",
    "    return min_distance / max_diameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n= features.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición de número de clusters K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import sqrt, log, floor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statistics import mean\n",
    "from fastdtw import fastdtw\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrices de distancia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de distancia euclidiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Euclidean\n",
    "f_euclidean_dist = np.zeros((n,n), dtype=float)\n",
    "for i in range(0,n):\n",
    "    #print(\"i\",i)\n",
    "    for j in range(1,n):\n",
    "         f_euclidean_dist[i,j] = euclidean(features.iloc[i].values.flatten(), features.iloc[j].values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_euclidean_distDF = pd.DataFrame(f_euclidean_dist)\n",
    "f_euclidean_distDF.to_csv(my_path_py+'\\\\2_FeatureBased\\\\MatricesDistancia\\\\MatrizEuclidianaNorm_FB.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DTW\n",
    "f_dtw_dist = np.zeros((n,n), dtype=float)\n",
    "for i in range(0,n):\n",
    "    for j in range(0,n):\n",
    "        f_dtw_dist[i,j] = fast_DTW(features.iloc[i].values.flatten(), features.iloc[j].values.flatten())\n",
    "\n",
    "f_dtw_distDF = pd.DataFrame(f_dtw_dist)\n",
    "f_dtw_distDF.to_csv(my_path_py+'\\\\2_FeatureBased\\\\MatricesDistancia\\\\MatrizDTWNorm_FB.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corr\n",
    "corr_dist = np.zeros((n,n), dtype=float)\n",
    "for i in range(0,n):\n",
    "    for j in range(0,n):\n",
    "            corr_dist[i,j] = corr(features.iloc[i].values.flatten(), features.iloc[j].values.flatten())\n",
    "            \n",
    "corr_distDF = pd.DataFrame(corr_dist)\n",
    "corr_distDF.to_csv(my_path_py+'\\\\2_FeatureBased\\\\MatricesDistancia\\\\MatrizPearsonNorm_FB.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de Pearson Spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scorr\n",
    "f_scorr_dist = np.zeros((n,n), dtype=float)\n",
    "for i in range(0,n):\n",
    "    for j in range(0,n):\n",
    "        f_scorr_dist[i,j] = scorr(features.iloc[i].values.flatten(), features.iloc[j].values.flatten())\n",
    "\n",
    "f_scorr_distDF = pd.DataFrame(f_scorr_dist)\n",
    "f_scorr_distDF.to_csv(my_path_py+'\\\\2_FeatureBased\\\\MatricesDistancia\\\\MatrizSpearmanNorm_FB.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering HAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAC + euclidian distance: \n",
      "SC:  0.2143083792177311\n",
      "CHZ:  127.65783543619317\n",
      "DAVIES:  1.3210959264222557\n",
      "HAC + corr distance: \n",
      "SC:  0.2109167596354485\n",
      "CHZ:  129.21063875671064\n",
      "DAVIES:  1.1612255425822546\n",
      "HAC + scorr distance: \n",
      "SC:  0.4751384497945144\n",
      "CHZ:  357.9729945942239\n",
      "DAVIES:  0.8068430906346579\n",
      "HAC + dtw distance: \n",
      "SC:  0.18175473405447864\n",
      "CHZ:  183.4319333805389\n",
      "DAVIES:  1.4885267513823017\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "HAC_EUCLIDEAN=[]\n",
    "HAC_CORRELATION=[]\n",
    "HAC_SPEARMAN=[]\n",
    "HAC_DTW=[]\n",
    "\n",
    "HAC_EUCLIDEAN_CHZ=[]\n",
    "HAC_CORRELATION_CHZ=[]\n",
    "HAC_SPEARMAN_CHZ=[]\n",
    "HAC_DTW_CHZ=[]\n",
    "\n",
    "HAC_EUCLIDEAN_DAVIES=[]\n",
    "HAC_CORRELATION_DAVIES=[]\n",
    "HAC_SPEARMAN_DAVIES=[]\n",
    "HAC_DTW_DAVIES=[]\n",
    "\n",
    "#Experimentos HAC\n",
    "HAC_euc = AgglomerativeClustering(n_clusters=k).fit_predict(f_euclidean_dist)\n",
    "print(\"HAC + euclidian distance: \")\n",
    "sil = silhouette_score(f_euclidean_dist, HAC_euc)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(f_euclidean_dist, HAC_euc)\n",
    "print(\"CHZ: \", chz)\n",
    "davies= davies_bouldin_score(f_euclidean_dist, HAC_euc)\n",
    "print(\"DAVIES: \", davies)\n",
    "HAC_EUCLIDEAN.append(sil)\n",
    "HAC_EUCLIDEAN_CHZ.append(chz)\n",
    "HAC_EUCLIDEAN_DAVIES.append(davies)\n",
    "\n",
    "HAC_corr = AgglomerativeClustering(n_clusters=k).fit_predict(corr_dist)\n",
    "print(\"HAC + corr distance: \")\n",
    "sil = silhouette_score(corr_dist, HAC_corr)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(corr_dist, HAC_corr)\n",
    "print(\"CHZ: \", chz)\n",
    "davies= davies_bouldin_score(corr_dist, HAC_corr)\n",
    "print(\"DAVIES: \", davies)\n",
    "HAC_CORRELATION.append(sil)\n",
    "HAC_CORRELATION_CHZ.append(chz)\n",
    "HAC_CORRELATION_DAVIES.append(davies)\n",
    "\n",
    "HAC_scorr = AgglomerativeClustering(n_clusters=k).fit_predict(f_scorr_dist)\n",
    "print(\"HAC + scorr distance: \")\n",
    "sil = silhouette_score(f_scorr_dist, HAC_scorr)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(f_scorr_dist, HAC_scorr)\n",
    "print(\"CHZ: \", chz)\n",
    "davies= davies_bouldin_score(f_scorr_dist, HAC_scorr)\n",
    "print(\"DAVIES: \", davies)\n",
    "HAC_SPEARMAN.append(sil)\n",
    "HAC_SPEARMAN_CHZ.append(chz)\n",
    "HAC_SPEARMAN_DAVIES.append(davies)\n",
    "\n",
    "HAC_dtw = AgglomerativeClustering(n_clusters=k).fit_predict(f_dtw_dist)\n",
    "print(\"HAC + dtw distance: \")\n",
    "sil = silhouette_score(f_dtw_dist, HAC_dtw)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(f_dtw_dist, HAC_dtw)\n",
    "print(\"CHZ: \", chz)\n",
    "davies= davies_bouldin_score(f_dtw_dist, HAC_dtw)\n",
    "print(\"DAVIES: \", davies)\n",
    "HAC_DTW.append(sil)\n",
    "HAC_DTW_CHZ.append(chz)\n",
    "HAC_DTW_DAVIES.append(davies)\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KM + euclidian distance: \n",
      "SC:  0.2723009789604566\n",
      "CHZ:  153.321106934814\n",
      "DAVIES:  1.0529171324168685\n",
      "KM + corr distance: \n",
      "SC:  0.2644037336926828\n",
      "CHZ:  153.9260890792056\n",
      "DAVIES:  1.0788099064252845\n",
      "KM + scorr distance: \n",
      "SC:  0.4861226260872223\n",
      "CHZ:  380.99416772962127\n",
      "DAVIES:  0.7767903476442793\n",
      "KM + dtw distance: \n",
      "SC:  0.24229907550613553\n",
      "CHZ:  209.03483870456319\n",
      "DAVIES:  1.2541056917481959\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "KM_EUCLIDEAN=[]\n",
    "KM_CORRELATION=[]\n",
    "KM_SPEARMAN=[]\n",
    "KM_DTW=[]\n",
    "\n",
    "KM_EUCLIDEAN_CHZ=[]\n",
    "KM_CORRELATION_CHZ=[]\n",
    "KM_SPEARMAN_CHZ=[]\n",
    "KM_DTW_CHZ=[]\n",
    "\n",
    "KM_EUCLIDEAN_DAVIES=[]\n",
    "KM_CORRELATION_DAVIES=[]\n",
    "KM_SPEARMAN_DAVIES=[]\n",
    "KM_DTW_DAVIES=[]\n",
    "\n",
    "#Experimentos K-Means\n",
    "km_euc = KMeans(n_clusters=k).fit_predict(f_euclidean_dist)\n",
    "print(\"KM + euclidian distance: \")\n",
    "sil = silhouette_score(f_euclidean_dist, km_euc)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(f_euclidean_dist, km_euc)\n",
    "print(\"CHZ: \", chz)\n",
    "davies= davies_bouldin_score(f_euclidean_dist, km_euc)\n",
    "print(\"DAVIES: \", davies)\n",
    "KM_EUCLIDEAN.append(sil)\n",
    "KM_EUCLIDEAN_CHZ.append(chz)\n",
    "KM_EUCLIDEAN_DAVIES.append(davies)\n",
    "\n",
    "km_corr = KMeans(n_clusters=k).fit_predict(corr_dist)\n",
    "print(\"KM + corr distance: \")\n",
    "sil = silhouette_score(corr_dist, km_corr)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(corr_dist, km_corr)\n",
    "print(\"CHZ: \", chz)\n",
    "davies= davies_bouldin_score(corr_dist, km_corr)\n",
    "print(\"DAVIES: \", davies)\n",
    "KM_CORRELATION.append(sil)\n",
    "KM_CORRELATION_CHZ.append(chz)\n",
    "KM_CORRELATION_DAVIES.append(davies)\n",
    "\n",
    "km_scorr = KMeans(n_clusters=k).fit_predict(f_scorr_dist)\n",
    "print(\"KM + scorr distance: \")\n",
    "sil = silhouette_score(f_scorr_dist, km_scorr)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(f_scorr_dist, km_scorr)\n",
    "print(\"CHZ: \", chz)\n",
    "davies= davies_bouldin_score(f_scorr_dist, km_scorr)\n",
    "print(\"DAVIES: \", davies)\n",
    "KM_SPEARMAN.append(sil)\n",
    "KM_SPEARMAN_CHZ.append(chz)\n",
    "KM_SPEARMAN_DAVIES.append(davies)\n",
    "\n",
    "km_dtw = KMeans(n_clusters=k).fit_predict(f_dtw_dist)\n",
    "print(\"KM + dtw distance: \")\n",
    "sil = silhouette_score(f_dtw_dist, km_dtw)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(f_dtw_dist, km_dtw)\n",
    "print(\"CHZ: \", chz)\n",
    "davies= davies_bouldin_score(f_dtw_dist, km_dtw)\n",
    "print(\"DAVIES: \", davies)\n",
    "KM_DTW.append(sil)\n",
    "KM_DTW_CHZ.append(chz)\n",
    "KM_DTW_DAVIES.append(davies)\n",
    "\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epsilon_lista = [0.001, 0.01, 1, 10, 100, 500]\n",
    "sil_list = []\n",
    "for e in epsilon_lista:\n",
    "    try:\n",
    "        DB_euc = DBSCAN(eps=e, min_samples=36).fit_predict(f_euclidean_distNORM)\n",
    "        sil =  silhouette_score(f_euclidean_distNORM, DB_euc)\n",
    "        sil_list.append(sil)\n",
    "    except:\n",
    "        pass\n",
    "plt.plot(sil_list)\n",
    "print('Epsilon máximo: ', epsilon_lista[np.argmax(sil_list)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epsilon_lista = np.arange (0.001, 4, 0.001)\n",
    "sil_list = []\n",
    "for e in epsilon_lista:\n",
    "    try:\n",
    "        DB_corr = DBSCAN(eps=e, min_samples=36).fit_predict(corr_distNORM)\n",
    "        sil =  silhouette_score(corr_distNORM, DB_corr)\n",
    "        sil_list.append(sil)\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.plot(sil_list)\n",
    "plt.axhline(y=0.45, color='r')\n",
    "print(np.interp(0.45, list(range(len(sil_list))), sil_list))\n",
    "print('Epsilon máximo: ', epsilon_lista[np.argmax(sil_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN + euclidian distance: \n",
      "SC:  0.003166897657419427\n",
      "CHZ:  14.063389252549806\n",
      "DAVIES:  0.8242625172308747\n",
      "DBSCAN + corr distance: \n",
      "SC:  0.5747289935645268\n",
      "CHZ:  45.30276848486094\n",
      "DAVIES:  1.0603773972255155\n",
      "DBSCAN + scorr distance: \n",
      "SC:  0.3515116891343668\n",
      "CHZ:  144.3395198574949\n",
      "DAVIES:  1.2842207739070886\n",
      "DBSCAN + dtw distance: \n",
      "SC:  0.019524191329705745\n",
      "CHZ:  6.05847978599786\n",
      "DAVIES:  0.7918151950776809\n"
     ]
    }
   ],
   "source": [
    "DBSCAN_EUCLIDEAN=[]\n",
    "DBSCAN_CORRELATION=[]\n",
    "DBSCAN_SPEARMAN=[]\n",
    "DBSCAN_DTW=[]\n",
    "\n",
    "DBSCAN_EUCLIDEAN_CHZ=[]\n",
    "DBSCAN_CORRELATION_CHZ=[]\n",
    "DBSCAN_SPEARMAN_CHZ=[]\n",
    "DBSCAN_DTW_CHZ=[]\n",
    "\n",
    "DBSCAN_EUCLIDEAN_DAVIES=[]\n",
    "DBSCAN_CORRELATION_DAVIES=[]\n",
    "DBSCAN_SPEARMAN_DAVIES=[]\n",
    "DBSCAN_DTW_DAVIES=[]\n",
    "\n",
    "#CON EUCLIDEAN\n",
    "DB_euc = DBSCAN(eps=0.01, min_samples=3).fit_predict(f_euclidean_dist)\n",
    "print(\"DBSCAN + euclidian distance: \")\n",
    "sil =  silhouette_score(f_euclidean_dist, DB_euc)\n",
    "print(\"SC: \", sil)\n",
    "CHZ_ = calinski_harabasz_score(f_euclidean_dist, DB_euc) \n",
    "print(\"CHZ: \", CHZ_)\n",
    "davies= davies_bouldin_score(f_euclidean_dist, DB_euc)\n",
    "print(\"DAVIES: \", davies)\n",
    "DBSCAN_EUCLIDEAN.append(sil)\n",
    "DBSCAN_EUCLIDEAN_CHZ.append(CHZ_)\n",
    "DBSCAN_EUCLIDEAN_DAVIES.append(davies)\n",
    "\n",
    "#CON CORRELATION\n",
    "DB_corr = DBSCAN(eps=2, min_samples=3).fit_predict(corr_dist)\n",
    "print(\"DBSCAN + corr distance: \")\n",
    "sil =  silhouette_score(corr_dist, DB_corr)\n",
    "print(\"SC: \", sil)\n",
    "CHZ_ = calinski_harabasz_score(corr_dist, DB_corr) \n",
    "print(\"CHZ: \",CHZ_)\n",
    "davies= davies_bouldin_score(corr_dist, DB_corr)\n",
    "print(\"DAVIES: \", davies)\n",
    "DBSCAN_CORRELATION.append(sil)\n",
    "DBSCAN_CORRELATION_CHZ.append(CHZ_)\n",
    "DBSCAN_CORRELATION_DAVIES.append(davies)\n",
    "\n",
    "#CON SPEARMAN\n",
    "DB_scorr = DBSCAN(eps=2, min_samples=3).fit_predict(f_scorr_dist)\n",
    "print(\"DBSCAN + scorr distance: \")\n",
    "sil =  silhouette_score(f_scorr_dist, DB_scorr)\n",
    "print(\"SC: \", sil)\n",
    "CHZ_ = calinski_harabasz_score(f_scorr_dist, DB_scorr) \n",
    "print(\"CHZ: \", CHZ_)\n",
    "davies= davies_bouldin_score(f_scorr_dist, DB_scorr)\n",
    "print(\"DAVIES: \", davies)\n",
    "DBSCAN_SPEARMAN.append(sil)\n",
    "DBSCAN_SPEARMAN_CHZ.append(CHZ_)\n",
    "DBSCAN_SPEARMAN_DAVIES.append(davies)\n",
    "\n",
    "#CON D TIME WARPING\n",
    "DB_dtw = DBSCAN(eps=0.01, min_samples=3).fit_predict(f_dtw_dist)\n",
    "print(\"DBSCAN + dtw distance: \")\n",
    "sil = silhouette_score(f_dtw_dist, DB_dtw)\n",
    "print(\"SC: \", sil)\n",
    "CHZ_ = calinski_harabasz_score(f_dtw_dist, DB_dtw)\n",
    "print(\"CHZ: \", CHZ_)\n",
    "davies= davies_bouldin_score(f_dtw_dist, DB_dtw)\n",
    "print(\"DAVIES: \", davies)\n",
    "DBSCAN_DTW.append(sil)\n",
    "DBSCAN_DTW_CHZ.append(CHZ_)\n",
    "DBSCAN_DTW_DAVIES.append(davies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux2 = pd.DataFrame()\n",
    "aux2['Dep-Prov-Distrito'] = listaDistrito\n",
    "aux2['Cluster KM Eu'] = km_euc\n",
    "aux2['Cluster HAC DTW'] = HAC_dtw\n",
    "aux2['Cluster DB SP'] = DB_scorr\n",
    "aux2.to_csv('ClusterFBNorm_Peru.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1,  2], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(DB_scorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_scores = pd.DataFrame()\n",
    "sil_scores['EUCLIDEAN-HAC'] = np.array(HAC_EUCLIDEAN)\n",
    "sil_scores['CORRELATION-HAC'] = np.array(HAC_CORRELATION)\n",
    "sil_scores['SPEARMAN-HAC'] = np.array(HAC_SPEARMAN)\n",
    "sil_scores['DTW-HAC'] = np.array(HAC_DTW)\n",
    "sil_scores['EUCLIDEAN-KM'] = np.array(KM_EUCLIDEAN)\n",
    "sil_scores['CORRELATION-KM'] = np.array(KM_CORRELATION)\n",
    "sil_scores['SPEARMAN-KM'] = np.array(KM_SPEARMAN)\n",
    "sil_scores['DTW-KM'] = np.array(KM_DTW)\n",
    "sil_scores['EUCLIDEAN-DB'] = np.array(DBSCAN_EUCLIDEAN)\n",
    "sil_scores['CORRELATION-DB'] = np.array(DBSCAN_CORRELATION)\n",
    "sil_scores['SPEARMAN-DB'] = np.array(DBSCAN_SPEARMAN)\n",
    "sil_scores['DTW-DB'] = np.array(DBSCAN_DTW)\n",
    "\n",
    "calinski = pd.DataFrame()\n",
    "calinski['EUCLIDEAN-HAC'] = np.array(HAC_EUCLIDEAN_CHZ)\n",
    "calinski['CORRELATION-HAC'] = np.array(HAC_CORRELATION_CHZ)\n",
    "calinski['SPEARMAN-HAC'] = np.array(HAC_SPEARMAN_CHZ)\n",
    "calinski['DTW-HAC'] = np.array(HAC_DTW_CHZ)\n",
    "calinski['EUCLIDEAN-KM'] = np.array(KM_EUCLIDEAN_CHZ)\n",
    "calinski['CORRELATION-KM'] = np.array(KM_CORRELATION_CHZ)\n",
    "calinski['SPEARMAN-KM'] = np.array(KM_SPEARMAN_CHZ)\n",
    "calinski['DTW-KM'] = np.array(KM_DTW_CHZ)\n",
    "calinski['EUCLIDEAN-DB'] = np.array(DBSCAN_EUCLIDEAN_CHZ)\n",
    "calinski['CORRELATION-DB'] = np.array(DBSCAN_CORRELATION_CHZ)\n",
    "calinski['SPEARMAN-DB'] = np.array(DBSCAN_SPEARMAN_CHZ)\n",
    "calinski['DTW-DB'] = np.array(DBSCAN_DTW_CHZ)\n",
    "\n",
    "davies_df = pd.DataFrame()\n",
    "davies_df['EUCLIDEAN-HAC'] = np.array(HAC_EUCLIDEAN_DAVIES)\n",
    "davies_df['CORRELATION-HAC'] = np.array(HAC_CORRELATION_DAVIES)\n",
    "davies_df['SPEARMAN-HAC'] = np.array(HAC_SPEARMAN_DAVIES)\n",
    "davies_df['DTW-HAC'] = np.array(HAC_DTW_DAVIES)\n",
    "davies_df['EUCLIDEAN-KM'] = np.array(KM_EUCLIDEAN_DAVIES)\n",
    "davies_df['CORRELATION-KM'] = np.array(KM_CORRELATION_DAVIES)\n",
    "davies_df['SPEARMAN-KM'] = np.array(KM_SPEARMAN_DAVIES)\n",
    "davies_df['DTW-KM'] = np.array(KM_DTW_DAVIES)\n",
    "davies_df['EUCLIDEAN-DB'] = np.array(DBSCAN_EUCLIDEAN_DAVIES)\n",
    "davies_df['CORRELATION-DB'] = np.array(DBSCAN_CORRELATION_DAVIES)\n",
    "davies_df['SPEARMAN-DB'] = np.array(DBSCAN_SPEARMAN_DAVIES)\n",
    "davies_df['DTW-DB'] = np.array(DBSCAN_DTW_DAVIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_scores.to_csv(my_path_py+'\\\\2_FeatureBased\\\\Resultados_Scores\\\\SilScore_18FBNorm.csv')\n",
    "calinski.to_csv(my_path_py+'\\\\2_FeatureBased\\\\Resultados_Scores\\\\CHZScore_18FBNorm.csv')\n",
    "#dunn_df.to_csv('DUNN_18FB.csv')\n",
    "davies_df.to_csv(my_path_py+'\\\\2_FeatureBased\\\\Resultados_Scores\\\\DAVIES_18FBNorm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kats]",
   "language": "python",
   "name": "conda-env-kats-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
