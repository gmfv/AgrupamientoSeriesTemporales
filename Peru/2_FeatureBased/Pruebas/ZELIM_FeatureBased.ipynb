{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FeatureBased utilizando funciones de ts_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tsfeature as tsf\n",
    "import entropy as ent\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "my_path = os.path.abspath('')\n",
    "my_path = my_path.split('\\\\')\n",
    "my_path_py = \"\\\\\".join(my_path[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(my_path_py+'\\\\DatosRaw\\\\DEN_2015to2020.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_length_encoding(x):\n",
    "    \"\"\"\n",
    "    :param x: np.array\n",
    "    :return: np.array\n",
    "    \"\"\"\n",
    "    pos, = np.where(np.diff(x) != 0)\n",
    "    pos = np.concatenate(([0], pos+1, [len(x)]))\n",
    "    # rle = [(a,b,x[a]) for (a,b) in zip(pos[:-1],pos[1:])]\n",
    "    rle = [b - a for (a, b) in zip(pos[:-1], pos[1:])]\n",
    "    return rle\n",
    "\n",
    "\n",
    "def hysteresis(x, th_lo, th_hi, initial=False):\n",
    "    \"\"\"\n",
    "    :param x: np.array\n",
    "    :param th_lo: float\n",
    "    :param th_hi: float\n",
    "    :param initial: ???\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    hi = x >= th_hi\n",
    "    lo_or_hi = (x <= th_lo) | hi\n",
    "    ind = np.nonzero(lo_or_hi)[0]\n",
    "    # prevent index error if ind is empty\n",
    "    if not ind.size:\n",
    "        return np.zeros_like(x, dtype=bool) | initial\n",
    "    # from 0 to len(x)\n",
    "    cnt = np.cumsum(lo_or_hi)\n",
    "    return np.where(cnt, hi[ind[cnt-1]], initial)\n",
    "\n",
    "\n",
    "def arg_longest_not_null(x):\n",
    "    # pad with np.nan while finding where null\n",
    "    m = np.concatenate(( [True], np.isnan(x), [True] ))\n",
    "    # Start-stop limits\n",
    "    ss = np.flatnonzero(m[1:] != m[:-1]).reshape(-1,2)\n",
    "    # Get max interval, interval limits\n",
    "    start, stop = ss[(ss[:,1] - ss[:,0]).argmax()]\n",
    "    return start, stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class poly(object):\n",
    "    \"\"\" Orthogonal polynomials\n",
    "\n",
    "    Source:\n",
    "        http://davmre.github.io/python/2013/12/15/orthogonal_poly\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.degree = None\n",
    "        self.z = None\n",
    "        self.norm2 = None\n",
    "        self.alpha = None\n",
    "\n",
    "    def fit(self, x, degree=1):\n",
    "\n",
    "        self.degree = degree\n",
    "\n",
    "        n = degree + 1\n",
    "        x = np.asarray(x).flatten()\n",
    "        if degree >= len(np.unique(x)):\n",
    "            raise ValueError(\"'degree' must be less than number of unique points\")\n",
    "\n",
    "        xbar = np.mean(x)\n",
    "        x = x - xbar\n",
    "        q, r = np.linalg.qr(np.fliplr(np.vander(x, n)))\n",
    "\n",
    "        z = np.diag(np.diag(r))\n",
    "        raw = np.dot(q, z)\n",
    "\n",
    "        norm2 = np.sum(raw**2, axis=0)\n",
    "        alpha = (np.sum((raw**2)*np.reshape(x, (-1, 1)), axis=0)/norm2 + xbar)[:degree]\n",
    "        z = raw / np.sqrt(norm2)\n",
    "\n",
    "        self.z = z\n",
    "        self.norm2 = norm2\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = np.asarray(x).flatten()\n",
    "        n = self.degree + 1\n",
    "        z = np.empty((len(x), n))\n",
    "        z[:, 0] = 1\n",
    "\n",
    "        if self.degree > 0:\n",
    "            z[:, 1] = x - self.alpha[0]\n",
    "\n",
    "        if self.degree > 1:\n",
    "            for i in np.arange(1, self.degree):\n",
    "                z[:, i+1] = (x - self.alpha[i]) * z[:, i] - (self.norm2[i] / self.norm2[i-1]) * z[:, i-1]\n",
    "\n",
    "        z /= np.sqrt(self.norm2)\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale as scale_data\n",
    "\n",
    "\n",
    "def biplot_features(x, robust=False, scale=True,  col=None, **kwargs):\n",
    "    X = x.dropna(axis=1, how='all').dropna(axis=0, how='any')\n",
    "\n",
    "    if col is None:\n",
    "        col = (\"#000000\", \"darkred\")\n",
    "    else:\n",
    "        col = [col] if not isinstance(col, (list, tuple)) else col\n",
    "        col = np.unique(col)\n",
    "\n",
    "        if len(col) == 1:\n",
    "            col = np.repeat(col, 2)\n",
    "        else:\n",
    "            col = np.unique(col)[0:2]\n",
    "\n",
    "    if scale:\n",
    "        X = scale_data(X, with_mean=True, with_std=True)\n",
    "\n",
    "    if robust:\n",
    "        raise NotImplemented('Robust PCA has not been implemented yet')\n",
    "    else:\n",
    "        pca = PCA(n_components=2)\n",
    "        pca.fit(X)\n",
    "        proj_pca = pca.transform(X)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(x=proj_pca[:, 0], y=proj_pca[:, 1], c=col)\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import boxcox_normmax\n",
    "from statsmodels.sandbox.gam import AdditiveModel\n",
    "\n",
    "try:\n",
    "    from entropy import spectral_entropy\n",
    "except ImportError:\n",
    "    ENTROPY_PACKAGE_AVAILABLE = False\n",
    "else:\n",
    "    ENTROPY_PACKAGE_AVAILABLE = True\n",
    "\n",
    "# features_hyndman\n",
    "# https://github.com/robjhyndman/anomalous/blob/master/R/tsmeasures.R\n",
    "\n",
    "_VARIABLE_COUNT = 0\n",
    "\n",
    "\n",
    "def trim(x, trim=0.1):\n",
    "    \"\"\"Trimmed time series eliminating outliers's influence\"\"\"\n",
    "    qtl = x.quantile([trim, 1 - trim])\n",
    "    lo = qtl.iloc[0]\n",
    "    hi = qtl.iloc[1]\n",
    "\n",
    "    trim_x = x.copy()\n",
    "    trim_x[(trim_x < lo) | (trim_x > hi)] = np.nan\n",
    "    return trim_x\n",
    "\n",
    "\n",
    "def first_order_autocorrelation(x):\n",
    "    \"\"\"First order of autocorrelation\"\"\"\n",
    "    return x.autocorr(1)\n",
    "\n",
    "\n",
    "def lumpiness(x, width):\n",
    "    \"\"\"Lumpiness\n",
    "\n",
    "    Note:\n",
    "        Cannot be used for yearly data\n",
    "    \"\"\"\n",
    "    nr = len(x)\n",
    "    start = np.arange(1, nr, step=width, dtype=int)\n",
    "    end = np.arange(width, nr + width, step=width, dtype=int)\n",
    "\n",
    "    nsegs = int(nr / width)\n",
    "\n",
    "    varx = np.zeros(nsegs)\n",
    "\n",
    "    for idx in range(nsegs):\n",
    "        tmp = x[start[idx]:end[idx]]\n",
    "        varx[idx] = tmp[~np.isnan(tmp)].var()\n",
    "\n",
    "    lump = varx[~np.isnan(varx)].var()\n",
    "    return lump\n",
    "\n",
    "\n",
    "def rolling_level_shift(x, width):\n",
    "    \"\"\"Level shift\n",
    "\n",
    "    Using rolling window\n",
    "    \"\"\"\n",
    "\n",
    "    tmp = x.dropna()\n",
    "    roll_mean = tmp.rolling(width).mean()\n",
    "\n",
    "    try:\n",
    "        level_shifts = roll_mean.diff(width).abs().max()\n",
    "    except Exception:\n",
    "        level_shifts = np.nan\n",
    "\n",
    "    return level_shifts\n",
    "\n",
    "\n",
    "def rolling_variance_change(x, width):\n",
    "    \"\"\"Variance change\n",
    "\n",
    "    Using rolling window\n",
    "\n",
    "    \"\"\"\n",
    "    tmp = x.dropna()\n",
    "\n",
    "    roll_var = tmp.rolling(width).var()\n",
    "\n",
    "    try:\n",
    "        variance_change = roll_var.diff(width).abs().max()\n",
    "    except Exception:\n",
    "        variance_change = np.nan\n",
    "\n",
    "    return variance_change\n",
    "\n",
    "\n",
    "def n_crossing_points(x):\n",
    "    \"\"\"Number of crossing points\"\"\"\n",
    "    mid_line = ((x.max() - x.min()) / 2.0)\n",
    "    ab = (x <= mid_line).values\n",
    "    len_x = len(x)\n",
    "    p1 = ab[1:(len_x - 1)]\n",
    "    p2 = ab[2:len_x]\n",
    "    cross = (p1 & ~p2) | (p2 & ~p1)\n",
    "    return cross.sum()\n",
    "\n",
    "\n",
    "def flat_spots(x):\n",
    "    \"\"\"Flat spots using discretization\"\"\"\n",
    "\n",
    "    try:\n",
    "        cut_x = pd.cut(x, bins=10, include_lowest=True, labels=False)\n",
    "        rle_x = run_length_encoding(cut_x)\n",
    "        spots = max(rle_x)\n",
    "    except Exception:\n",
    "        spots = np.nan\n",
    "\n",
    "    #  Any flat spot\n",
    "    return spots\n",
    "\n",
    "\n",
    "def trend_seasonality_spike_strength(x, freq):\n",
    "    \"\"\"Strength of trend and seasonality and spike\"\"\"\n",
    "    cont_x = x.dropna()\n",
    "    length_cont_x = len(cont_x)\n",
    "    season = peak = trough = np.nan\n",
    "\n",
    "    if length_cont_x < (2 * freq):\n",
    "        trend = linearity = curvature = season = spike = peak = trough = np.nan\n",
    "    else:\n",
    "\n",
    "        if freq > 1:\n",
    "            all_stl = sm.tsa.seasonal_decompose(cont_x, period=freq)\n",
    "            trend0 = all_stl.trend\n",
    "            fits = trend0 + all_stl.seasonal\n",
    "            adj_x = cont_x - fits\n",
    "            v_adj = adj_x.var()\n",
    "            detrend = cont_x - trend0\n",
    "            deseason = cont_x - all_stl.seasonal\n",
    "            peak = all_stl.seasonal.max()\n",
    "            trough = all_stl.seasonal.min()\n",
    "            remainder = all_stl.resid\n",
    "            season = 0 if detrend.var() < 1e-10 else max(0, min(1, 1 - v_adj/detrend.var()))\n",
    "\n",
    "        else:  # No seasonal component\n",
    "            tt = np.array([range(length_cont_x)]).T\n",
    "\n",
    "            _trend0_values = AdditiveModel(tt).fit(cont_x.values).mu\n",
    "            trend0=pd.Series(_trend0_values, index=cont_x.index)\n",
    "            remainder = cont_x - trend0\n",
    "            deseason = cont_x - trend0\n",
    "            v_adj = trend0.var()\n",
    "\n",
    "        trend = 0 if deseason.var() < 1e-10 else max(0, min(1, 1 - v_adj/deseason.var()))\n",
    "\n",
    "        n = len(remainder)\n",
    "        v = remainder.var()\n",
    "        d = (remainder - remainder.mean())**2\n",
    "        varloo = (v * (n - 1) - d) / (n - 2)\n",
    "        spike = varloo.var()\n",
    "        pl = poly()\n",
    "        pl.fit(range(length_cont_x), degree=2)\n",
    "        result_pl = pl.predict(range(length_cont_x))  # [:, 2]\n",
    "\n",
    "        X = sm.add_constant(result_pl, has_constant='add')\n",
    "        ols_data = trend0.copy()\n",
    "        ols_data = pd.concat([ols_data.reset_index(drop=True), pd.DataFrame(X)], axis=1, ignore_index=True)\n",
    "        ols_data.columns = ['Y', 'Intercept', 'X1', 'X2', 'X3']\n",
    "        result_ols = ols('Y ~ X1 + X2 + X3', data=ols_data.dropna())\n",
    "\n",
    "        trend_coef = result_ols.fit().params\n",
    "        linearity = trend_coef[1]\n",
    "        curvature = trend_coef[2]\n",
    "\n",
    "    result = dict(trend=trend, spike=spike, peak=peak, trough=trough, linearity=linearity, curvature=curvature)\n",
    "\n",
    "    if freq > 1:\n",
    "        result[\"season\"] = season\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def kullback_leibler_score(x, window, threshold=None):\n",
    "    \"\"\"Kullback-Leibler score\"\"\"\n",
    "\n",
    "    if threshold is None:\n",
    "        threshold = norm.pdf(38)\n",
    "\n",
    "    gw = 100  # grid width\n",
    "    xgrid = np.arange(x.min(), x.max(), step=(x.max() - x.min()) / gw, dtype=float)\n",
    "    grid = xgrid[1] - xgrid[0]\n",
    "    tmpx = x[~x.isnull()]  # Remove NA to calculate bw\n",
    "    bw = gaussian_kde(tmpx).covariance_factor()\n",
    "    len_x = len(x)\n",
    "\n",
    "    if len_x <= (2 * window):\n",
    "        raise ValueError(\"Cannot compute KLscore when the length is too small.\")\n",
    "\n",
    "    dens_mat = np.zeros((len_x, gw))\n",
    "\n",
    "    for i in range(len_x):\n",
    "        dens_mat[i, :] = norm.pdf(xgrid, x[i], bw)\n",
    "\n",
    "    dens_mat = np.clip(dens_mat, threshold, None)\n",
    "\n",
    "    rmean = dens_mat.rolling(window=window).mean()\n",
    "\n",
    "    lo = range(len_x - window + 1)\n",
    "    hi = range(window + 1, len_x)\n",
    "    seqidx = min(len(lo), len(hi))\n",
    "\n",
    "    kl = np.zeros(seqidx)\n",
    "    for i in range(seqidx):\n",
    "        kl[i] = np.sum(rmean[lo[i], ] * (np.log(rmean[lo[i], ]) - np.log(rmean[hi[i], ])) * grid)\n",
    "\n",
    "    diffkl = pd.Series(kl).dropna().diff()\n",
    "    maxidx = np.argmax(diffkl)\n",
    "\n",
    "    return dict(score=np.max(diffkl), change_idx=maxidx)\n",
    "\n",
    "\n",
    "def boxcox_optimal_lambda(x):\n",
    "    y = x + 0.0000001 if np.any(x == 0) else x\n",
    "    return boxcox_normmax(y)\n",
    "\n",
    "\n",
    "# TODO: implement Spectral Entropy\n",
    "def entropy(x, freq=1, normalize=False):\n",
    "    \"\"\"\n",
    "    Spectral Entropy\n",
    "    \"\"\"\n",
    "    try:\n",
    "        start, stop = arg_longest_not_null(x)\n",
    "        result = spectral_entropy(x[start:stop], sf=freq, method='welch', normalize=normalize)\n",
    "    except Exception:\n",
    "        result = np.nan\n",
    "    finally:\n",
    "        return result\n",
    "\n",
    "\n",
    "def ts_measures(x, freq=1, normalize=True, width=None, window=None):\n",
    "    \"\"\"\n",
    "    See `ts_measures_series` doc\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(x, pd.Series):\n",
    "        measures_df = ts_measures_series(x, freq=freq, normalize=normalize, width=width, window=window)\n",
    "    elif isinstance(x, pd.DataFrame):\n",
    "        _buffer = []\n",
    "        for c in x.columns:\n",
    "            _buffer.append(ts_measures_series(x[c], freq=freq, normalize=normalize, width=width, window=window))\n",
    "        measures_df = pd.concat(_buffer, axis=0)\n",
    "\n",
    "    elif issubclass(x.__class__, pd.core.groupby._GroupBy):\n",
    "        _buffer = []\n",
    "        for i in x.groups:\n",
    "            _buffer.append(ts_measures(x.get_group(i), freq=freq, normalize=normalize, width=width, window=window))\n",
    "\n",
    "        measures_df = pd.concat(_buffer, axis=0)\n",
    "    else:\n",
    "        raise TypeError('Unhandled input type')\n",
    "\n",
    "    return measures_df\n",
    "\n",
    "\n",
    "def ts_measures_series(x, freq=1, normalize=True, width=None, window=None):\n",
    "    \"\"\"\n",
    "    :param x: a uni-variate time series\n",
    "    :param freq: number of points to be considered as part of a single period for trend_seasonality_spike_strength\n",
    "    :param normalize: TRUE: scale data to be normally distributed\n",
    "    :param width: a window size for variance change and level shift, lumpiness\n",
    "    :param window: a window size for KLscore\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    name = x.name\n",
    "\n",
    "    if width is None:\n",
    "        width = freq if freq > 1 else 10\n",
    "\n",
    "    if window is None:\n",
    "        window = width\n",
    "\n",
    "    if (width <= 1) | (window <= 1):\n",
    "        raise ValueError(\"Window widths should be greater than 1.\")\n",
    "\n",
    "    # Remove columns containing all NAs\n",
    "    if x.isnull().all():\n",
    "        raise ValueError(\"All values are null\")\n",
    "\n",
    "    if normalize:\n",
    "        x = (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "\n",
    "    trimx = trim(x)\n",
    "\n",
    "    measures = dict()\n",
    "    measures['lumpiness'] = lumpiness(x, width=width)\n",
    "    if ENTROPY_PACKAGE_AVAILABLE:\n",
    "        measures['entropy'] = entropy(x, freq=freq, normalize=False)\n",
    "    measures['ACF1'] = first_order_autocorrelation(x)\n",
    "    measures['lshift'] = rolling_level_shift(trimx, width=width)\n",
    "    measures['vchange'] = rolling_variance_change(trimx, width=width)\n",
    "    measures['cpoints'] = n_crossing_points(x)\n",
    "    measures['fspots'] = flat_spots(x)\n",
    "    #  measures['mean'] = np.mean(x)\n",
    "    #  measures['var'] = np.var(x)\n",
    "\n",
    "    varts = trend_seasonality_spike_strength(x, freq=freq)\n",
    "    measures['trend'] = varts['trend']\n",
    "    measures['linearity'] = varts['linearity']\n",
    "    measures['curvature'] = varts['curvature']\n",
    "    measures['spikiness'] = varts['spike']\n",
    "\n",
    "    if freq > 1:\n",
    "        measures['season'] = varts['season']\n",
    "        measures['peak'] = varts['peak']\n",
    "        measures['trough'] = varts['trough']\n",
    "\n",
    "    threshold = norm.pdf(38)\n",
    "\n",
    "    try:\n",
    "        kl = kullback_leibler_score(x, window=window, threshold=threshold)\n",
    "        measures['KLscore'] = kl['score']\n",
    "        measures['change_idx'] = kl['change_idx']\n",
    "    except Exception:\n",
    "        measures['KLscore'] = np.nan\n",
    "        measures['change_idx'] = np.nan\n",
    "\n",
    "    measures['boxcox'] = boxcox_optimal_lambda(x)\n",
    "\n",
    "    # Build output\n",
    "    measures_df = pd.Series(measures).to_frame().transpose()\n",
    "    measures_df.index = [x.index.min()] if isinstance(x, pd.Series) else [0]\n",
    "    measures_df['variable'] = name if name is not None else generate_name()\n",
    "    return measures_df\n",
    "\n",
    "def generate_name(prefix='var_'):\n",
    "    global _VARIABLE_COUNT\n",
    "    output = \"{}{}\".format(prefix, _VARIABLE_COUNT)\n",
    "    _VARIABLE_COUNT += 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AMAZONAS, BAGUA, ARAMANGO', 'AMAZONAS, BAGUA, BAGUA',\n",
       "       'AMAZONAS, BAGUA, COPALLIN', 'AMAZONAS, BAGUA, EL PARCO',\n",
       "       'AMAZONAS, BAGUA, IMAZA', 'AMAZONAS, BAGUA, LA PECA',\n",
       "       'AMAZONAS, BONGARA, FLORIDA', 'AMAZONAS, BONGARA, JAZAN',\n",
       "       'AMAZONAS, CHACHAPOYAS, CHACHAPOYAS',\n",
       "       'AMAZONAS, CONDORCANQUI, EL CENEPA',\n",
       "       'AMAZONAS, CONDORCANQUI, NIEVA',\n",
       "       'AMAZONAS, CONDORCANQUI, RIO SANTIAGO',\n",
       "       'AMAZONAS, UTCUBAMBA, BAGUA GRANDE',\n",
       "       'AMAZONAS, UTCUBAMBA, CAJARURO', 'AMAZONAS, UTCUBAMBA, CUMBA',\n",
       "       'AMAZONAS, UTCUBAMBA, EL MILAGRO', 'AMAZONAS, UTCUBAMBA, JAMALCA',\n",
       "       'AMAZONAS, UTCUBAMBA, YAMON', 'ANCASH, CASMA, BUENA VISTA ALTA',\n",
       "       'ANCASH, CASMA, CASMA', 'ANCASH, CASMA, COMANDANTE NOEL',\n",
       "       'ANCASH, HUARMEY, HUARMEY', 'ANCASH, SANTA, CHIMBOTE',\n",
       "       'ANCASH, SANTA, COISHCO', 'ANCASH, SANTA, NEPEÑA',\n",
       "       'ANCASH, SANTA, NUEVO CHIMBOTE', 'ANCASH, SANTA, SANTA',\n",
       "       'AREQUIPA, CARAVELI, BELLA UNION', 'AYACUCHO, CANGALLO, CANGALLO',\n",
       "       'AYACUCHO, HUAMANGA, AYACUCHO',\n",
       "       'AYACUCHO, HUAMANGA, JESUS NAZARENO',\n",
       "       'AYACUCHO, HUAMANGA, SAN JUAN BAUTISTA',\n",
       "       'AYACUCHO, HUANTA, CANAYRE', 'AYACUCHO, HUANTA, HUANTA',\n",
       "       'AYACUCHO, HUANTA, LLOCHEGUA', 'AYACUCHO, HUANTA, SANTILLANA',\n",
       "       'AYACUCHO, HUANTA, SIVIA', 'AYACUCHO, LA MAR, ANCHIHUAY',\n",
       "       'AYACUCHO, LA MAR, ANCO', 'AYACUCHO, LA MAR, AYNA',\n",
       "       'AYACUCHO, LA MAR, CHUNGUI', 'AYACUCHO, LA MAR, SAMUGARI',\n",
       "       'AYACUCHO, LA MAR, SAN MIGUEL', 'AYACUCHO, LA MAR, SANTA ROSA',\n",
       "       'AYACUCHO, LUCANAS, LUCANAS',\n",
       "       'AYACUCHO, PAUCAR DEL SARA SARA, SAN JAVIER DE ALPABAMBA',\n",
       "       'AYACUCHO, SUCRE, SAN PEDRO DE LARCAY',\n",
       "       'CAJAMARCA, CAJAMARCA, CAJAMARCA',\n",
       "       'CAJAMARCA, CAJAMARCA, MAGDALENA', 'CAJAMARCA, CHOTA, CHOTA',\n",
       "       'CAJAMARCA, CHOTA, HUAMBOS', 'CAJAMARCA, CONTUMAZA, CHILETE',\n",
       "       'CAJAMARCA, CONTUMAZA, CONTUMAZA',\n",
       "       'CAJAMARCA, CONTUMAZA, TANTARICA', 'CAJAMARCA, CONTUMAZA, YONAN',\n",
       "       'CAJAMARCA, CUTERVO, CALLAYUC', 'CAJAMARCA, CUTERVO, CUTERVO',\n",
       "       'CAJAMARCA, CUTERVO, QUEROCOTILLO',\n",
       "       'CAJAMARCA, CUTERVO, SANTO TOMAS',\n",
       "       'CAJAMARCA, HUALGAYOC, HUALGAYOC', 'CAJAMARCA, JAEN, BELLAVISTA',\n",
       "       'CAJAMARCA, JAEN, COLASAY', 'CAJAMARCA, JAEN, HUABAL',\n",
       "       'CAJAMARCA, JAEN, JAEN', 'CAJAMARCA, JAEN, PUCARA',\n",
       "       'CAJAMARCA, JAEN, SAN JOSE DEL ALTO',\n",
       "       'CAJAMARCA, JAEN, SANTA ROSA', 'CAJAMARCA, SAN IGNACIO, CHIRINOS',\n",
       "       'CAJAMARCA, SAN IGNACIO, HUARANGO',\n",
       "       'CAJAMARCA, SAN IGNACIO, LA COIPA',\n",
       "       'CAJAMARCA, SAN IGNACIO, NAMBALLE',\n",
       "       'CAJAMARCA, SAN IGNACIO, SAN IGNACIO',\n",
       "       'CAJAMARCA, SAN IGNACIO, SAN JOSE DE LOURDES',\n",
       "       'CAJAMARCA, SANTA CRUZ, NINABAMBA', 'CALLAO, CALLAO, VENTANILLA',\n",
       "       'CUSCO, CALCA, YANATILE', 'CUSCO, CUSCO, CUSCO',\n",
       "       'CUSCO, LA CONVENCION, ECHARATE',\n",
       "       'CUSCO, LA CONVENCION, HUAYOPATA', 'CUSCO, LA CONVENCION, KIMBIRI',\n",
       "       'CUSCO, LA CONVENCION, MARANURA',\n",
       "       'CUSCO, LA CONVENCION, MEGANTONI', 'CUSCO, LA CONVENCION, PICHARI',\n",
       "       'CUSCO, LA CONVENCION, QUELLOUNO',\n",
       "       'CUSCO, LA CONVENCION, SANTA ANA',\n",
       "       'CUSCO, LA CONVENCION, SANTA TERESA',\n",
       "       'CUSCO, LA CONVENCION, VILCABAMBA',\n",
       "       'CUSCO, LA CONVENCION, VILLA KINTIARINA',\n",
       "       'CUSCO, LA CONVENCION, VILLA VIRGEN',\n",
       "       'CUSCO, PAUCARTAMBO, KOSÑIPATA', 'CUSCO, QUISPICANCHI, CAMANTI',\n",
       "       'HUANUCO, AMBO, AMBO', 'HUANUCO, HUAMALIES, MONZON',\n",
       "       'HUANUCO, HUANUCO, AMARILIS', 'HUANUCO, HUANUCO, CHINCHAO',\n",
       "       'HUANUCO, HUANUCO, HUANUCO', 'HUANUCO, HUANUCO, PILLCO MARCA',\n",
       "       'HUANUCO, HUANUCO, SANTA MARIA DEL VALLE',\n",
       "       'HUANUCO, LAURICOCHA, JIVIA',\n",
       "       'HUANUCO, LEONCIO PRADO, CASTILLO GRANDE',\n",
       "       'HUANUCO, LEONCIO PRADO, DANIEL ALOMIA ROBLES',\n",
       "       'HUANUCO, LEONCIO PRADO, HERMILIO VALDIZAN',\n",
       "       'HUANUCO, LEONCIO PRADO, JOSE CRESPO Y CASTILLO',\n",
       "       'HUANUCO, LEONCIO PRADO, LUYANDO',\n",
       "       'HUANUCO, LEONCIO PRADO, MARIANO DAMASO BERAUN',\n",
       "       'HUANUCO, LEONCIO PRADO, PUEBLO NUEVO',\n",
       "       'HUANUCO, LEONCIO PRADO, RUPA-RUPA', 'HUANUCO, MARAÑON, CHOLON',\n",
       "       'HUANUCO, PACHITEA, PANAO', 'HUANUCO, PACHITEA, UMARI',\n",
       "       'HUANUCO, PUERTO INCA, CODO DEL POZUZO',\n",
       "       'HUANUCO, PUERTO INCA, HONORIA',\n",
       "       'HUANUCO, PUERTO INCA, PUERTO INCA',\n",
       "       'HUANUCO, PUERTO INCA, TOURNAVISTA',\n",
       "       'HUANUCO, PUERTO INCA, YUYAPICHIS', 'ICA, CHINCHA, ALTO LARAN',\n",
       "       'ICA, CHINCHA, CHINCHA ALTA', 'ICA, CHINCHA, CHINCHA BAJA',\n",
       "       'ICA, CHINCHA, EL CARMEN', 'ICA, CHINCHA, GROCIO PRADO',\n",
       "       'ICA, CHINCHA, PUEBLO NUEVO', 'ICA, CHINCHA, SUNAMPE',\n",
       "       'ICA, CHINCHA, TAMBO DE MORA', 'ICA, ICA, ICA',\n",
       "       'ICA, ICA, LA TINGUIÑA', 'ICA, ICA, LOS AQUIJES',\n",
       "       'ICA, ICA, OCUCAJE', 'ICA, ICA, PACHACUTEC', 'ICA, ICA, PARCONA',\n",
       "       'ICA, ICA, PUEBLO NUEVO', 'ICA, ICA, SALAS',\n",
       "       'ICA, ICA, SAN JOSE DE LOS MOLINOS', 'ICA, ICA, SAN JUAN BAUTISTA',\n",
       "       'ICA, ICA, SANTIAGO', 'ICA, ICA, SUBTANJALLA', 'ICA, ICA, TATE',\n",
       "       'ICA, ICA, YAUCA DEL ROSARIO', 'ICA, NASCA, CHANGUILLO',\n",
       "       'ICA, NASCA, EL INGENIO', 'ICA, NASCA, MARCONA',\n",
       "       'ICA, NASCA, NASCA', 'ICA, NASCA, VISTA ALEGRE',\n",
       "       'ICA, PALPA, LLIPATA', 'ICA, PALPA, PALPA',\n",
       "       'ICA, PALPA, RIO GRANDE', 'ICA, PALPA, SANTA CRUZ',\n",
       "       'ICA, PISCO, HUANCANO', 'ICA, PISCO, HUMAY',\n",
       "       'ICA, PISCO, INDEPENDENCIA', 'ICA, PISCO, PARACAS',\n",
       "       'ICA, PISCO, PISCO', 'ICA, PISCO, SAN ANDRES',\n",
       "       'ICA, PISCO, SAN CLEMENTE', 'ICA, PISCO, TUPAC AMARU INCA',\n",
       "       'JUNIN, CHANCHAMAYO, CHANCHAMAYO', 'JUNIN, CHANCHAMAYO, PERENE',\n",
       "       'JUNIN, CHANCHAMAYO, PICHANAQUI',\n",
       "       'JUNIN, CHANCHAMAYO, SAN LUIS DE SHUARO',\n",
       "       'JUNIN, CHANCHAMAYO, SAN RAMON', 'JUNIN, CHANCHAMAYO, VITOC',\n",
       "       'JUNIN, HUANCAYO, EL TAMBO',\n",
       "       'JUNIN, HUANCAYO, SANTO DOMINGO DE ACOBAMBA',\n",
       "       'JUNIN, HUANCAYO, SAPALLANGA', 'JUNIN, JUNIN, JUNIN',\n",
       "       'JUNIN, SATIPO, COVIRIALI', 'JUNIN, SATIPO, LLAYLLA',\n",
       "       'JUNIN, SATIPO, MAZAMARI', 'JUNIN, SATIPO, PAMPA HERMOSA',\n",
       "       'JUNIN, SATIPO, PANGOA', 'JUNIN, SATIPO, RIO NEGRO',\n",
       "       'JUNIN, SATIPO, RIO TAMBO', 'JUNIN, SATIPO, SATIPO',\n",
       "       'JUNIN, SATIPO, VIZCATAN DEL ENE', 'JUNIN, YAULI, LA OROYA',\n",
       "       'LA LIBERTAD, ASCOPE, ASCOPE', 'LA LIBERTAD, ASCOPE, CASA GRANDE',\n",
       "       'LA LIBERTAD, ASCOPE, CHICAMA', 'LA LIBERTAD, ASCOPE, CHOCOPE',\n",
       "       'LA LIBERTAD, ASCOPE, PAIJAN',\n",
       "       'LA LIBERTAD, ASCOPE, SANTIAGO DE CAO',\n",
       "       'LA LIBERTAD, CHEPEN, CHEPEN', 'LA LIBERTAD, CHEPEN, PACANGA',\n",
       "       'LA LIBERTAD, CHEPEN, PUEBLO NUEVO',\n",
       "       'LA LIBERTAD, GRAN CHIMU, CASCAS',\n",
       "       'LA LIBERTAD, PACASMAYO, GUADALUPE',\n",
       "       'LA LIBERTAD, PACASMAYO, JEQUETEPEQUE',\n",
       "       'LA LIBERTAD, PACASMAYO, PACASMAYO',\n",
       "       'LA LIBERTAD, PACASMAYO, SAN JOSE',\n",
       "       'LA LIBERTAD, PACASMAYO, SAN PEDRO DE LLOC',\n",
       "       'LA LIBERTAD, PATAZ, PATAZ',\n",
       "       'LA LIBERTAD, SANCHEZ CARRION, COCHORCO',\n",
       "       'LA LIBERTAD, TRUJILLO, EL PORVENIR',\n",
       "       'LA LIBERTAD, TRUJILLO, FLORENCIA DE MORA',\n",
       "       'LA LIBERTAD, TRUJILLO, HUANCHACO',\n",
       "       'LA LIBERTAD, TRUJILLO, LA ESPERANZA',\n",
       "       'LA LIBERTAD, TRUJILLO, LAREDO', 'LA LIBERTAD, TRUJILLO, MOCHE',\n",
       "       'LA LIBERTAD, TRUJILLO, SALAVERRY',\n",
       "       'LA LIBERTAD, TRUJILLO, TRUJILLO',\n",
       "       'LA LIBERTAD, TRUJILLO, VICTOR LARCO HERRERA',\n",
       "       'LA LIBERTAD, VIRU, CHAO', 'LA LIBERTAD, VIRU, GUADALUPITO',\n",
       "       'LA LIBERTAD, VIRU, VIRU', 'LAMBAYEQUE, CHICLAYO, CAYALTI',\n",
       "       'LAMBAYEQUE, CHICLAYO, CHICLAYO',\n",
       "       'LAMBAYEQUE, CHICLAYO, CHONGOYAPE',\n",
       "       'LAMBAYEQUE, CHICLAYO, JOSE LEONARDO ORTIZ',\n",
       "       'LAMBAYEQUE, CHICLAYO, LA VICTORIA',\n",
       "       'LAMBAYEQUE, CHICLAYO, LAGUNAS', 'LAMBAYEQUE, CHICLAYO, MONSEFU',\n",
       "       'LAMBAYEQUE, CHICLAYO, OYOTUN', 'LAMBAYEQUE, CHICLAYO, PATAPO',\n",
       "       'LAMBAYEQUE, CHICLAYO, PICSI', 'LAMBAYEQUE, CHICLAYO, PIMENTEL',\n",
       "       'LAMBAYEQUE, CHICLAYO, POMALCA', 'LAMBAYEQUE, CHICLAYO, PUCALA',\n",
       "       'LAMBAYEQUE, CHICLAYO, REQUE', 'LAMBAYEQUE, CHICLAYO, SAÑA',\n",
       "       'LAMBAYEQUE, CHICLAYO, TUMAN', 'LAMBAYEQUE, FERREÑAFE, FERREÑAFE',\n",
       "       'LAMBAYEQUE, FERREÑAFE, MANUEL ANTONIO MESONES MURO',\n",
       "       'LAMBAYEQUE, FERREÑAFE, PITIPO',\n",
       "       'LAMBAYEQUE, FERREÑAFE, PUEBLO NUEVO',\n",
       "       'LAMBAYEQUE, LAMBAYEQUE, CHOCHOPE',\n",
       "       'LAMBAYEQUE, LAMBAYEQUE, ILLIMO',\n",
       "       'LAMBAYEQUE, LAMBAYEQUE, JAYANCA',\n",
       "       'LAMBAYEQUE, LAMBAYEQUE, LAMBAYEQUE',\n",
       "       'LAMBAYEQUE, LAMBAYEQUE, MOCHUMI',\n",
       "       'LAMBAYEQUE, LAMBAYEQUE, MORROPE',\n",
       "       'LAMBAYEQUE, LAMBAYEQUE, MOTUPE', 'LAMBAYEQUE, LAMBAYEQUE, OLMOS',\n",
       "       'LAMBAYEQUE, LAMBAYEQUE, PACORA', 'LAMBAYEQUE, LAMBAYEQUE, SALAS',\n",
       "       'LAMBAYEQUE, LAMBAYEQUE, SAN JOSE',\n",
       "       'LAMBAYEQUE, LAMBAYEQUE, TUCUME', 'LIMA, BARRANCA, BARRANCA',\n",
       "       'LIMA, CAÑETE, CHILCA', 'LIMA, HUAROCHIRI, HUAROCHIRI',\n",
       "       'LIMA, HUAURA, HUALMAY', 'LIMA, LIMA, ATE',\n",
       "       'LIMA, LIMA, CARABAYLLO', 'LIMA, LIMA, CHORRILLOS',\n",
       "       'LIMA, LIMA, COMAS', 'LIMA, LIMA, INDEPENDENCIA',\n",
       "       'LIMA, LIMA, LA MOLINA', 'LIMA, LIMA, LA VICTORIA',\n",
       "       'LIMA, LIMA, LIMA', 'LIMA, LIMA, LOS OLIVOS',\n",
       "       'LIMA, LIMA, LURIGANCHO', 'LIMA, LIMA, MAGDALENA DEL MAR',\n",
       "       'LIMA, LIMA, PUCUSANA', 'LIMA, LIMA, PUEBLO LIBRE',\n",
       "       'LIMA, LIMA, PUENTE PIEDRA', 'LIMA, LIMA, RIMAC',\n",
       "       'LIMA, LIMA, SAN BORJA', 'LIMA, LIMA, SAN ISIDRO',\n",
       "       'LIMA, LIMA, SAN JUAN DE LURIGANCHO',\n",
       "       'LIMA, LIMA, SAN JUAN DE MIRAFLORES', 'LIMA, LIMA, SAN LUIS',\n",
       "       'LIMA, LIMA, SAN MARTIN DE PORRES', 'LIMA, LIMA, SAN MIGUEL',\n",
       "       'LIMA, LIMA, SANTA ANITA', 'LIMA, LIMA, SANTIAGO DE SURCO',\n",
       "       'LIMA, LIMA, VILLA EL SALVADOR',\n",
       "       'LIMA, LIMA, VILLA MARIA DEL TRIUNFO',\n",
       "       'LORETO, ALTO AMAZONAS, BALSAPUERTO',\n",
       "       'LORETO, ALTO AMAZONAS, JEBEROS', 'LORETO, ALTO AMAZONAS, LAGUNAS',\n",
       "       'LORETO, ALTO AMAZONAS, SANTA CRUZ',\n",
       "       'LORETO, ALTO AMAZONAS, TENIENTE CESAR LOPEZ ROJAS',\n",
       "       'LORETO, ALTO AMAZONAS, YURIMAGUAS',\n",
       "       'LORETO, DATEM DEL MARAÑON, ANDOAS',\n",
       "       'LORETO, DATEM DEL MARAÑON, BARRANCA',\n",
       "       'LORETO, DATEM DEL MARAÑON, MANSERICHE',\n",
       "       'LORETO, DATEM DEL MARAÑON, MORONA',\n",
       "       'LORETO, DATEM DEL MARAÑON, PASTAZA', 'LORETO, LORETO, NAUTA',\n",
       "       'LORETO, LORETO, PARINARI', 'LORETO, LORETO, TIGRE',\n",
       "       'LORETO, LORETO, TROMPETEROS', 'LORETO, LORETO, URARINAS',\n",
       "       'LORETO, MARISCAL RAMON CASTILLA, PEBAS',\n",
       "       'LORETO, MARISCAL RAMON CASTILLA, RAMON CASTILLA',\n",
       "       'LORETO, MARISCAL RAMON CASTILLA, SAN PABLO',\n",
       "       'LORETO, MARISCAL RAMON CASTILLA, YAVARI',\n",
       "       'LORETO, MAYNAS, ALTO NANAY', 'LORETO, MAYNAS, BELEN',\n",
       "       'LORETO, MAYNAS, FERNANDO LORES', 'LORETO, MAYNAS, INDIANA',\n",
       "       'LORETO, MAYNAS, IQUITOS', 'LORETO, MAYNAS, LAS AMAZONAS',\n",
       "       'LORETO, MAYNAS, MAZAN', 'LORETO, MAYNAS, NAPO',\n",
       "       'LORETO, MAYNAS, PUNCHANA', 'LORETO, MAYNAS, SAN JUAN BAUTISTA',\n",
       "       'LORETO, MAYNAS, TORRES CAUSANA', 'LORETO, PUTUMAYO, PUTUMAYO',\n",
       "       'LORETO, PUTUMAYO, TENIENTE MANUEL CLAVERO',\n",
       "       'LORETO, PUTUMAYO, YAGUAS', 'LORETO, REQUENA, ALTO TAPICHE',\n",
       "       'LORETO, REQUENA, CAPELO', 'LORETO, REQUENA, EMILIO SAN MARTIN',\n",
       "       'LORETO, REQUENA, JENARO HERRERA', 'LORETO, REQUENA, MAQUIA',\n",
       "       'LORETO, REQUENA, PUINAHUA', 'LORETO, REQUENA, REQUENA',\n",
       "       'LORETO, REQUENA, SAQUENA', 'LORETO, REQUENA, SOPLIN',\n",
       "       'LORETO, REQUENA, TAPICHE', 'LORETO, REQUENA, YAQUERANA',\n",
       "       'LORETO, UCAYALI, CONTAMANA', 'LORETO, UCAYALI, INAHUAYA',\n",
       "       'LORETO, UCAYALI, PADRE MARQUEZ', 'LORETO, UCAYALI, PAMPA HERMOSA',\n",
       "       'LORETO, UCAYALI, SARAYACU', 'LORETO, UCAYALI, VARGAS GUERRA',\n",
       "       'MADRE DE DIOS, MANU, HUEPETUHE',\n",
       "       'MADRE DE DIOS, MANU, MADRE DE DIOS', 'MADRE DE DIOS, MANU, MANU',\n",
       "       'MADRE DE DIOS, TAHUAMANU, IBERIA',\n",
       "       'MADRE DE DIOS, TAHUAMANU, IÑAPARI',\n",
       "       'MADRE DE DIOS, TAHUAMANU, TAHUAMANU',\n",
       "       'MADRE DE DIOS, TAMBOPATA, INAMBARI',\n",
       "       'MADRE DE DIOS, TAMBOPATA, LABERINTO',\n",
       "       'MADRE DE DIOS, TAMBOPATA, LAS PIEDRAS',\n",
       "       'MADRE DE DIOS, TAMBOPATA, TAMBOPATA',\n",
       "       'MOQUEGUA, MARISCAL NIETO, MOQUEGUA',\n",
       "       'PASCO, OXAPAMPA, CONSTITUCION', 'PASCO, OXAPAMPA, OXAPAMPA',\n",
       "       'PASCO, OXAPAMPA, PALCAZU', 'PASCO, OXAPAMPA, POZUZO',\n",
       "       'PASCO, OXAPAMPA, PUERTO BERMUDEZ', 'PASCO, OXAPAMPA, VILLA RICA',\n",
       "       'PIURA, AYABACA, AYABACA', 'PIURA, AYABACA, FRIAS',\n",
       "       'PIURA, AYABACA, JILILI', 'PIURA, AYABACA, PACAIPAMPA',\n",
       "       'PIURA, AYABACA, PAIMAS', 'PIURA, AYABACA, SAPILLICA',\n",
       "       'PIURA, AYABACA, SUYO', 'PIURA, HUANCABAMBA, CANCHAQUE',\n",
       "       'PIURA, HUANCABAMBA, EL CARMEN DE LA FRONTERA',\n",
       "       'PIURA, HUANCABAMBA, HUANCABAMBA', 'PIURA, HUANCABAMBA, HUARMACA',\n",
       "       'PIURA, HUANCABAMBA, LALAQUIZ',\n",
       "       'PIURA, HUANCABAMBA, SAN MIGUEL DE EL FAIQUE',\n",
       "       'PIURA, HUANCABAMBA, SONDOR', 'PIURA, HUANCABAMBA, SONDORILLO',\n",
       "       'PIURA, MORROPON, BUENOS AIRES', 'PIURA, MORROPON, CHALACO',\n",
       "       'PIURA, MORROPON, CHULUCANAS', 'PIURA, MORROPON, LA MATANZA',\n",
       "       'PIURA, MORROPON, MORROPON', 'PIURA, MORROPON, SALITRAL',\n",
       "       'PIURA, MORROPON, SAN JUAN DE BIGOTE',\n",
       "       'PIURA, MORROPON, SANTA CATALINA DE MOSSA',\n",
       "       'PIURA, MORROPON, SANTO DOMINGO', 'PIURA, MORROPON, YAMANGO',\n",
       "       'PIURA, PAITA, AMOTAPE', 'PIURA, PAITA, ARENAL',\n",
       "       'PIURA, PAITA, COLAN', 'PIURA, PAITA, LA HUACA',\n",
       "       'PIURA, PAITA, PAITA', 'PIURA, PAITA, TAMARINDO',\n",
       "       'PIURA, PAITA, VICHAYAL', 'PIURA, PIURA, CASTILLA',\n",
       "       'PIURA, PIURA, CATACAOS', 'PIURA, PIURA, CURA MORI',\n",
       "       'PIURA, PIURA, EL TALLAN', 'PIURA, PIURA, LA ARENA',\n",
       "       'PIURA, PIURA, LA UNION', 'PIURA, PIURA, LAS LOMAS',\n",
       "       'PIURA, PIURA, PIURA', 'PIURA, PIURA, TAMBO GRANDE',\n",
       "       'PIURA, PIURA, VEINTISEIS DE OCTUBRE',\n",
       "       'PIURA, SECHURA, BELLAVISTA DE LA UNION', 'PIURA, SECHURA, BERNAL',\n",
       "       'PIURA, SECHURA, CRISTO NOS VALGA',\n",
       "       'PIURA, SECHURA, RINCONADA LLICUAR', 'PIURA, SECHURA, SECHURA',\n",
       "       'PIURA, SECHURA, VICE', 'PIURA, SULLANA, BELLAVISTA',\n",
       "       'PIURA, SULLANA, IGNACIO ESCUDERO', 'PIURA, SULLANA, LANCONES',\n",
       "       'PIURA, SULLANA, MARCAVELICA', 'PIURA, SULLANA, MIGUEL CHECA',\n",
       "       'PIURA, SULLANA, QUERECOTILLO', 'PIURA, SULLANA, SALITRAL',\n",
       "       'PIURA, SULLANA, SULLANA', 'PIURA, TALARA, EL ALTO',\n",
       "       'PIURA, TALARA, LA BREA', 'PIURA, TALARA, LOBITOS',\n",
       "       'PIURA, TALARA, LOS ORGANOS', 'PIURA, TALARA, MANCORA',\n",
       "       'PIURA, TALARA, PARIÑAS', 'PUNO, CARABAYA, AYAPATA',\n",
       "       'PUNO, CARABAYA, OLLACHEA', 'PUNO, CARABAYA, SAN GABAN',\n",
       "       'SAN MARTIN, BELLAVISTA, ALTO BIAVO',\n",
       "       'SAN MARTIN, BELLAVISTA, BAJO BIAVO',\n",
       "       'SAN MARTIN, BELLAVISTA, BELLAVISTA',\n",
       "       'SAN MARTIN, BELLAVISTA, HUALLAGA',\n",
       "       'SAN MARTIN, BELLAVISTA, SAN PABLO',\n",
       "       'SAN MARTIN, BELLAVISTA, SAN RAFAEL',\n",
       "       'SAN MARTIN, EL DORADO, AGUA BLANCA',\n",
       "       'SAN MARTIN, EL DORADO, SAN JOSE DE SISA',\n",
       "       'SAN MARTIN, EL DORADO, SAN MARTIN',\n",
       "       'SAN MARTIN, EL DORADO, SANTA ROSA',\n",
       "       'SAN MARTIN, EL DORADO, SHATOJA',\n",
       "       'SAN MARTIN, HUALLAGA, ALTO SAPOSOA',\n",
       "       'SAN MARTIN, HUALLAGA, EL ESLABON',\n",
       "       'SAN MARTIN, HUALLAGA, PISCOYACU',\n",
       "       'SAN MARTIN, HUALLAGA, SACANCHE', 'SAN MARTIN, HUALLAGA, SAPOSOA',\n",
       "       'SAN MARTIN, HUALLAGA, TINGO DE SAPOSOA',\n",
       "       'SAN MARTIN, LAMAS, ALONSO DE ALVARADO',\n",
       "       'SAN MARTIN, LAMAS, BARRANQUITA', 'SAN MARTIN, LAMAS, CAYNARACHI',\n",
       "       'SAN MARTIN, LAMAS, CUÑUMBUQUI', 'SAN MARTIN, LAMAS, LAMAS',\n",
       "       'SAN MARTIN, LAMAS, PINTO RECODO', 'SAN MARTIN, LAMAS, RUMISAPA',\n",
       "       'SAN MARTIN, LAMAS, SAN ROQUE DE CUMBAZA',\n",
       "       'SAN MARTIN, LAMAS, SHANAO', 'SAN MARTIN, LAMAS, TABALOSOS',\n",
       "       'SAN MARTIN, LAMAS, ZAPATERO',\n",
       "       'SAN MARTIN, MARISCAL CACERES, CAMPANILLA',\n",
       "       'SAN MARTIN, MARISCAL CACERES, HUICUNGO',\n",
       "       'SAN MARTIN, MARISCAL CACERES, JUANJUI',\n",
       "       'SAN MARTIN, MARISCAL CACERES, PACHIZA',\n",
       "       'SAN MARTIN, MARISCAL CACERES, PAJARILLO',\n",
       "       'SAN MARTIN, MOYOBAMBA, CALZADA', 'SAN MARTIN, MOYOBAMBA, HABANA',\n",
       "       'SAN MARTIN, MOYOBAMBA, JEPELACIO',\n",
       "       'SAN MARTIN, MOYOBAMBA, MOYOBAMBA',\n",
       "       'SAN MARTIN, MOYOBAMBA, SORITOR', 'SAN MARTIN, MOYOBAMBA, YANTALO',\n",
       "       'SAN MARTIN, PICOTA, BUENOS AIRES',\n",
       "       'SAN MARTIN, PICOTA, CASPISAPA', 'SAN MARTIN, PICOTA, PICOTA',\n",
       "       'SAN MARTIN, PICOTA, PILLUANA', 'SAN MARTIN, PICOTA, PUCACACA',\n",
       "       'SAN MARTIN, PICOTA, SAN CRISTOBAL',\n",
       "       'SAN MARTIN, PICOTA, SAN HILARION',\n",
       "       'SAN MARTIN, PICOTA, SHAMBOYACU',\n",
       "       'SAN MARTIN, PICOTA, TINGO DE PONASA',\n",
       "       'SAN MARTIN, PICOTA, TRES UNIDOS', 'SAN MARTIN, RIOJA, AWAJUN',\n",
       "       'SAN MARTIN, RIOJA, ELIAS SOPLIN VARGAS',\n",
       "       'SAN MARTIN, RIOJA, NUEVA CAJAMARCA',\n",
       "       'SAN MARTIN, RIOJA, PARDO MIGUEL', 'SAN MARTIN, RIOJA, POSIC',\n",
       "       'SAN MARTIN, RIOJA, RIOJA', 'SAN MARTIN, RIOJA, SAN FERNANDO',\n",
       "       'SAN MARTIN, RIOJA, YORONGOS', 'SAN MARTIN, RIOJA, YURACYACU',\n",
       "       'SAN MARTIN, SAN MARTIN, ALBERTO LEVEAU',\n",
       "       'SAN MARTIN, SAN MARTIN, CACATACHI',\n",
       "       'SAN MARTIN, SAN MARTIN, CHAZUTA',\n",
       "       'SAN MARTIN, SAN MARTIN, CHIPURANA',\n",
       "       'SAN MARTIN, SAN MARTIN, EL PORVENIR',\n",
       "       'SAN MARTIN, SAN MARTIN, HUIMBAYOC',\n",
       "       'SAN MARTIN, SAN MARTIN, JUAN GUERRA',\n",
       "       'SAN MARTIN, SAN MARTIN, LA BANDA DE SHILCAYO',\n",
       "       'SAN MARTIN, SAN MARTIN, MORALES',\n",
       "       'SAN MARTIN, SAN MARTIN, PAPAPLAYA',\n",
       "       'SAN MARTIN, SAN MARTIN, SAN ANTONIO',\n",
       "       'SAN MARTIN, SAN MARTIN, SAUCE', 'SAN MARTIN, SAN MARTIN, SHAPAJA',\n",
       "       'SAN MARTIN, SAN MARTIN, TARAPOTO',\n",
       "       'SAN MARTIN, TOCACHE, NUEVO PROGRESO',\n",
       "       'SAN MARTIN, TOCACHE, POLVORA', 'SAN MARTIN, TOCACHE, SHUNTE',\n",
       "       'SAN MARTIN, TOCACHE, TOCACHE', 'SAN MARTIN, TOCACHE, UCHIZA',\n",
       "       'TUMBES, CONTRALMIRANTE VILLAR, CANOAS DE PUNTA SAL',\n",
       "       'TUMBES, CONTRALMIRANTE VILLAR, CASITAS',\n",
       "       'TUMBES, CONTRALMIRANTE VILLAR, ZORRITOS',\n",
       "       'TUMBES, TUMBES, CORRALES', 'TUMBES, TUMBES, LA CRUZ',\n",
       "       'TUMBES, TUMBES, PAMPAS DE HOSPITAL',\n",
       "       'TUMBES, TUMBES, SAN JACINTO',\n",
       "       'TUMBES, TUMBES, SAN JUAN DE LA VIRGEN', 'TUMBES, TUMBES, TUMBES',\n",
       "       'TUMBES, ZARUMILLA, AGUAS VERDES', 'TUMBES, ZARUMILLA, MATAPALO',\n",
       "       'TUMBES, ZARUMILLA, PAPAYAL', 'TUMBES, ZARUMILLA, ZARUMILLA',\n",
       "       'UCAYALI, ATALAYA, RAYMONDI', 'UCAYALI, ATALAYA, SEPAHUA',\n",
       "       'UCAYALI, ATALAYA, TAHUANIA', 'UCAYALI, ATALAYA, YURUA',\n",
       "       'UCAYALI, CORONEL PORTILLO, CALLERIA',\n",
       "       'UCAYALI, CORONEL PORTILLO, CAMPOVERDE',\n",
       "       'UCAYALI, CORONEL PORTILLO, IPARIA',\n",
       "       'UCAYALI, CORONEL PORTILLO, MANANTAY',\n",
       "       'UCAYALI, CORONEL PORTILLO, MASISEA',\n",
       "       'UCAYALI, CORONEL PORTILLO, NUEVA REQUENA',\n",
       "       'UCAYALI, CORONEL PORTILLO, YARINACOCHA',\n",
       "       'UCAYALI, PADRE ABAD, ALEXANDER VON HUMBOLDT',\n",
       "       'UCAYALI, PADRE ABAD, CURIMANA', 'UCAYALI, PADRE ABAD, IRAZOLA',\n",
       "       'UCAYALI, PADRE ABAD, NESHUYA', 'UCAYALI, PADRE ABAD, PADRE ABAD',\n",
       "       'UCAYALI, PURUS, PURUS'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.unique(df['Dep-Prov-Distrito'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "listaDistrito = list(np.unique(df['Dep-Prov-Distrito']))\n",
    "df1 = df[['Dep-Prov-Distrito','Semana', 'Incidencia semanal']]\n",
    "for dis in listaDistrito:\n",
    "    df1.loc[df1['Dep-Prov-Distrito']==dis,'ID_distrito']=i\n",
    "    i=i+1\n",
    "df1= df1.fillna(0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dep-Prov-Distrito</th>\n",
       "      <th>Semana</th>\n",
       "      <th>Incidencia semanal</th>\n",
       "      <th>ID_distrito</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAMBAYEQUE, LAMBAYEQUE, LAMBAYEQUE</td>\n",
       "      <td>24</td>\n",
       "      <td>1.248860</td>\n",
       "      <td>226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LAMBAYEQUE, LAMBAYEQUE, LAMBAYEQUE</td>\n",
       "      <td>27</td>\n",
       "      <td>1.248860</td>\n",
       "      <td>226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LAMBAYEQUE, LAMBAYEQUE, LAMBAYEQUE</td>\n",
       "      <td>21</td>\n",
       "      <td>1.248860</td>\n",
       "      <td>226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAMBAYEQUE, LAMBAYEQUE, LAMBAYEQUE</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LAMBAYEQUE, LAMBAYEQUE, LAMBAYEQUE</td>\n",
       "      <td>52</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85272</th>\n",
       "      <td>HUANUCO, LEONCIO PRADO, CASTILLO GRANDE</td>\n",
       "      <td>283</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85273</th>\n",
       "      <td>HUANUCO, LEONCIO PRADO, CASTILLO GRANDE</td>\n",
       "      <td>284</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85274</th>\n",
       "      <td>HUANUCO, LEONCIO PRADO, CASTILLO GRANDE</td>\n",
       "      <td>285</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85275</th>\n",
       "      <td>HUANUCO, LEONCIO PRADO, CASTILLO GRANDE</td>\n",
       "      <td>286</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85276</th>\n",
       "      <td>HUANUCO, LEONCIO PRADO, CASTILLO GRANDE</td>\n",
       "      <td>287</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85277 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Dep-Prov-Distrito  Semana  Incidencia semanal  \\\n",
       "0           LAMBAYEQUE, LAMBAYEQUE, LAMBAYEQUE      24            1.248860   \n",
       "1           LAMBAYEQUE, LAMBAYEQUE, LAMBAYEQUE      27            1.248860   \n",
       "2           LAMBAYEQUE, LAMBAYEQUE, LAMBAYEQUE      21            1.248860   \n",
       "3           LAMBAYEQUE, LAMBAYEQUE, LAMBAYEQUE      53            0.000000   \n",
       "4           LAMBAYEQUE, LAMBAYEQUE, LAMBAYEQUE      52            0.000000   \n",
       "...                                        ...     ...                 ...   \n",
       "85272  HUANUCO, LEONCIO PRADO, CASTILLO GRANDE     283            0.000001   \n",
       "85273  HUANUCO, LEONCIO PRADO, CASTILLO GRANDE     284            0.000001   \n",
       "85274  HUANUCO, LEONCIO PRADO, CASTILLO GRANDE     285            0.000001   \n",
       "85275  HUANUCO, LEONCIO PRADO, CASTILLO GRANDE     286            0.000001   \n",
       "85276  HUANUCO, LEONCIO PRADO, CASTILLO GRANDE     287            0.000001   \n",
       "\n",
       "       ID_distrito  \n",
       "0            226.0  \n",
       "1            226.0  \n",
       "2            226.0  \n",
       "3            226.0  \n",
       "4            226.0  \n",
       "...            ...  \n",
       "85272         99.0  \n",
       "85273         99.0  \n",
       "85274         99.0  \n",
       "85275         99.0  \n",
       "85276         99.0  \n",
       "\n",
       "[85277 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeSeries = pd.read_csv(my_path_py+'\\\\DatosRaw\\\\SerieTemporal_2015to2020.csv', sep=',')\n",
    "timeSeries = timeSeries.fillna(0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████| 20/20 [00:24<00:00,  1.20s/it]\n"
     ]
    }
   ],
   "source": [
    "import tsfresh\n",
    "from tsfresh import extract_features\n",
    "\n",
    "#features extraction\n",
    "extracted_features = extract_features(df1, column_id='ID_distrito', column_sort='Semana', column_value='Incidencia semanal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeSeries.replace(to_replace = 0, value = np.nan, inplace=True)\n",
    "timeSeries = timeSeries.replace('nan', np.nan).fillna(0.00001)\n",
    "timeSeries = timeSeries.replace([np.inf, -np.inf], np.nan).fillna(0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay valores nan en TimeSeries?  False\n",
      "Cantidad de valores infinititos:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Hay valores nan en TimeSeries? \", timeSeries.isnull().values.any())\n",
    "print(\"Cantidad de valores infinititos: \", np.isinf(timeSeries).values.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-312cbda33206>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mts_measures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeSeries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Dep-Prov-Distrito\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlistaDistrito\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_duplicates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-bca9eb9762b0>\u001b[0m in \u001b[0;36mts_measures\u001b[1;34m(x, freq, normalize, width, window)\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[0m_buffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m             \u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts_measures_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m         \u001b[0mmeasures_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-bca9eb9762b0>\u001b[0m in \u001b[0;36mts_measures_series\u001b[1;34m(x, freq, normalize, width, window)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[0mmeasures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'change_idx'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m     \u001b[0mmeasures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'boxcox'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mboxcox_optimal_lambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;31m# Build output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-bca9eb9762b0>\u001b[0m in \u001b[0;36mboxcox_optimal_lambda\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mboxcox_optimal_lambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.0000001\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mboxcox_normmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py\u001b[0m in \u001b[0;36mboxcox_normmax\u001b[1;34m(x, brack, method)\u001b[0m\n\u001b[0;32m   1161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m     \u001b[0moptimfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethods\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1163\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0moptimfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py\u001b[0m in \u001b[0;36m_pearsonr\u001b[1;34m(x, brack)\u001b[0m\n\u001b[0;32m   1139\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1141\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbrent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_eval_pearsonr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbrack\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_mle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36mbrent\u001b[1;34m(func, args, brack, tol, full_output, maxiter)\u001b[0m\n\u001b[0;32m   2263\u001b[0m     options = {'xtol': tol,\n\u001b[0;32m   2264\u001b[0m                'maxiter': maxiter}\n\u001b[1;32m-> 2265\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_minimize_scalar_brent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbrack\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2266\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fun'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'nit'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'nfev'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_minimize_scalar_brent\u001b[1;34m(func, brack, args, xtol, maxiter, **unknown_options)\u001b[0m\n\u001b[0;32m   2295\u001b[0m                   full_output=True, maxiter=maxiter)\n\u001b[0;32m   2296\u001b[0m     \u001b[0mbrent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_bracket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2297\u001b[1;33m     \u001b[0mbrent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2298\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnfev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2079\u001b[0m         \u001b[1;31m# set up for optimization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2080\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2081\u001b[1;33m         \u001b[0mxa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfuncalls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_bracket_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2082\u001b[0m         \u001b[0m_mintol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mintol\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2083\u001b[0m         \u001b[0m_cg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36mget_bracket_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2055\u001b[0m             \u001b[0mxa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfuncalls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbracket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2056\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbrack\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2057\u001b[1;33m             xa, xb, xc, fa, fb, fc, funcalls = bracket(func, xa=brack[0],\n\u001b[0m\u001b[0;32m   2058\u001b[0m                                                        xb=brack[1], args=args)\n\u001b[0;32m   2059\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbrack\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36mbracket\u001b[1;34m(func, xa, xb, args, grow_limit, maxiter)\u001b[0m\n\u001b[0;32m   2503\u001b[0m     \u001b[0m_gold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.618034\u001b[0m  \u001b[1;31m# golden ratio: (1.0+sqrt(5.0))/2.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2504\u001b[0m     \u001b[0m_verysmall_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-21\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2505\u001b[1;33m     \u001b[0mfa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxa\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2506\u001b[0m     \u001b[0mfb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2507\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfa\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mfb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m                      \u001b[1;31m# Switch so fa > fb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py\u001b[0m in \u001b[0;36m_eval_pearsonr\u001b[1;34m(lmbda, xvals, samps)\u001b[0m\n\u001b[0;32m   1136\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mboxcox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[0myvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1138\u001b[1;33m             \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpearsonr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1139\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py\u001b[0m in \u001b[0;36mpearsonr\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   3866\u001b[0m     \u001b[1;31m# [-5e210, 5e210, 3e200, -3e200]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3867\u001b[0m     \u001b[0mnormxm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3868\u001b[1;33m     \u001b[0mnormym\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mym\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3870\u001b[0m     \u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-13\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\linalg\\misc.py\u001b[0m in \u001b[0;36mnorm\u001b[1;34m(a, ord, axis, keepdims, check_finite)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[1;31m# Differs from numpy only in non-finite handling and the use of blas.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcheck_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray_chkfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36masarray_chkfinite\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    483\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtypecodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'AllFloat'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 485\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    486\u001b[0m             \"array must not contain infs or NaNs\")\n\u001b[0;32m    487\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "y = ts_measures(timeSeries.T, freq=4)\n",
    "y.insert(0, \"Dep-Prov-Distrito\", listaDistrito, allow_duplicates=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.fillna(0.0000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame()\n",
    "Mean=[]\n",
    "Var=[]\n",
    "aCF1=[]\n",
    "Trend=[]\n",
    "Linearity=[]\n",
    "Curvature=[]\n",
    "Season=[]\n",
    "Peak=[]\n",
    "Trough=[]\n",
    "Entropy=[]\n",
    "Lumpiness=[]\n",
    "Spikiness=[]\n",
    "Lshift=[]\n",
    "Vchange=[]\n",
    "Fspots=[]\n",
    "Cpoints_=[]\n",
    "Klscore=[]\n",
    "ChangeIdx=[]\n",
    "\n",
    "for dis in listaDistrito:\n",
    "    distrito_1=df['Dep-Prov-Distrito']==dis\n",
    "    casos_distrito1=df[distrito_1]\n",
    "    casos_distrito1 = casos_distrito1.reset_index(drop=True)\n",
    "    casos_distrito1 = casos_distrito1['Incidencia Semanal']\n",
    "    casos_distrito1 = casos_distrito1.replace('nan', np.nan).fillna(0.00000000001)\n",
    "    casos_distrito1 = casos_distrito1.replace(0, np.nan).fillna(0.00000000001)\n",
    "    casos_distrito1 = casos_distrito1.replace([np.inf, -np.inf], np.nan).fillna(0.00000000001)\n",
    "    \n",
    "    #Features\n",
    "    mean= tsfresh.feature_extraction.feature_calculators.mean(casos_distrito1)\n",
    "    var=tsfresh.feature_extraction.feature_calculators.variance(casos_distrito1)\n",
    "    ACF1=tsfresh.feature_extraction.feature_calculators.autocorrelation(casos_distrito1,1)\n",
    "    trend = y[y[\"Distrito\"] == dis].trend\n",
    "    linear = y[y[\"Distrito\"] == dis].linearity\n",
    "    curv = y[y[\"Distrito\"] == dis].curvature\n",
    "    season = y[y[\"Distrito\"] == dis].season\n",
    "    peak = tsfresh.feature_extraction.feature_calculators.number_peaks(casos_distrito1, int(mean))\n",
    "    trough_ = y[y[\"Distrito\"] == dis].trough\n",
    "    entropy = tsfresh.feature_extraction.feature_calculators.sample_entropy(casos_distrito1)\n",
    "    lump = y[y[\"Distrito\"] == dis].lumpiness\n",
    "    spik = y[y[\"Distrito\"] == dis].spikiness\n",
    "    lshift = y[y[\"Distrito\"] == dis].lshift\n",
    "    vchange = y[y[\"Distrito\"] == dis].vchange\n",
    "    fspots = y[y[\"Distrito\"] == dis].fspots\n",
    "    cpoints_ = y[y[\"Distrito\"] == dis].cpoints\n",
    "    klscore = y[y[\"Distrito\"] == dis].KLscore\n",
    "    changeidx = y[y[\"Distrito\"] == dis].change_idx\n",
    "    \n",
    "    Mean.append(mean)\n",
    "    Var.append(var)\n",
    "    aCF1.append(ACF1)\n",
    "    Trend.append(trend[0])\n",
    "    Linearity.append(linear[0])\n",
    "    Curvature.append(curv[0])\n",
    "    Season.append(season[0])\n",
    "    Peak.append(peak)\n",
    "    Trough.append(trough_[0])\n",
    "    Entropy.append(entropy)\n",
    "    Lumpiness.append(lump[0])\n",
    "    Spikiness.append(spik[0])\n",
    "    Lshift.append(lshift[0])\n",
    "    Vchange.append(vchange[0])\n",
    "    Fspots.append(fspots[0])\n",
    "    Cpoints_.append(cpoints_)\n",
    "    Klscore.append(klscore[0])\n",
    "    ChangeIdx.append(changeidx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tuples = list(zip(Mean, Var, aCF1, Trend, Linearity, Curvature, Season, Peak, Trough, Entropy, Lumpiness, Spikiness, Lshift, Vchange, Fspots, Cpoints_, Klscore, ChangeIdx))\n",
    "features = pd.DataFrame(data_tuples, columns =['Mean', 'Var', 'ACF1','Trend', 'Linearity', 'Curvature', 'Season', 'Peak', 'Trough', 'Entropy', 'Lumpiness','Spikiness','Lshift', 'Vchange','Fspots', 'Cpoints', 'KlScore', 'ChangeIdx']) \n",
    "\n",
    "# print the data \n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.replace('nan', np.nan).fillna(0.00000001)\n",
    "features = features.replace(0, np.nan).fillna(0.0000001)\n",
    "features = features.replace([np.inf, -np.inf], np.nan).fillna(0.00000001)\n",
    "for col in features.columns:\n",
    "    features[col] = features[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.insert(0, 'Distrito', y.Distrito.values)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv('FB2_2009al2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n= timeSeries.shape[0]\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones de Distancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import sqrt, log, floor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statistics import mean\n",
    "from fastdtw import fastdtw\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "#Euclidean\n",
    "def euclidean(x, y):\n",
    "    r=np.linalg.norm(x-y)\n",
    "    if math.isnan(r):\n",
    "        r=1\n",
    "    #print(r)\n",
    "    return r\n",
    "\n",
    "#Fast Dynamic time warping\n",
    "def fast_DTW(x, y):\n",
    "    r, _ = fastdtw(x, y, dist=euclidean)\n",
    "    if math.isnan(r):\n",
    "        r=1\n",
    "    #print(r)\n",
    "    return r\n",
    "\n",
    "#Spearman\n",
    "def scorr(x, y):\n",
    "    r = stats.spearmanr(x, y)[0]\n",
    "    if math.isnan(r):\n",
    "        r=0\n",
    "    #print(r)\n",
    "    return 1 - r\n",
    "\n",
    "#RMSE\n",
    "def rmse(x, y):\n",
    "    r=sqrt(mean_squared_error(x,y))\n",
    "    if math.isnan(r):\n",
    "        r=1\n",
    "    #print(r)\n",
    "    return r\n",
    "\n",
    "def lcs(a, b):  \n",
    "    lengths = [[0 for j in range(len(b)+1)] for i in range(len(a)+1)]\n",
    "    # row 0 and column 0 are initialized to 0 already\n",
    "    for i, x in enumerate(a):\n",
    "        for j, y in enumerate(b):\n",
    "            if x == y:\n",
    "                lengths[i+1][j+1] = lengths[i][j] + 1\n",
    "            else:\n",
    "                lengths[i+1][j+1] = max(lengths[i+1][j], lengths[i][j+1])\n",
    "    x, y = len(a), len(b)\n",
    "    result = lengths[x][y]\n",
    "    return result\n",
    "\n",
    "def discretise(x):\n",
    "    return int(x * 10)\n",
    "\n",
    "def multidim_lcs(a, b):\n",
    "    a = a.applymap(discretise)\n",
    "    b = b.applymap(discretise)\n",
    "    rows, dims = a.shape\n",
    "    lcss = [lcs(a[i+2], b[i+2]) for i in range(dims)]\n",
    "    return 1 - sum(lcss) / (rows * dims)\n",
    "\n",
    "#Correlation\n",
    "def corr(x, y):\n",
    "    r=np.dot(x-mean(x),y-mean(y))/((np.linalg.norm(x-mean(x)))*(np.linalg.norm(y-mean(y))))\n",
    "    if math.isnan(r):\n",
    "        r=0\n",
    "    #print(r)\n",
    "    return 1 - r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "import scipy.cluster.hierarchy as hac\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "\n",
    "DIAMETER_METHODS = ['mean_cluster', 'farthest']\n",
    "CLUSTER_DISTANCE_METHODS = ['nearest', 'farthest']\n",
    "\n",
    "def inter_cluster_distances(labels, distances, method='nearest'):\n",
    "    \"\"\"Calculates the distances between the two nearest points of each cluster.\n",
    "    :param labels: a list containing cluster labels for each of the n elements\n",
    "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
    "    :param method: `nearest` for the distances between the two nearest points in each cluster, or `farthest`\n",
    "    \"\"\"\n",
    "    if method not in CLUSTER_DISTANCE_METHODS:\n",
    "        raise ValueError(\n",
    "            'method must be one of {}'.format(CLUSTER_DISTANCE_METHODS))\n",
    "\n",
    "    if method == 'nearest':\n",
    "        return __cluster_distances_by_points(labels, distances)\n",
    "    elif method == 'farthest':\n",
    "        return __cluster_distances_by_points(labels, distances, farthest=True)\n",
    "\n",
    "\n",
    "def __cluster_distances_by_points(labels, distances, farthest=False):\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    cluster_distances = np.full((n_unique_labels, n_unique_labels),\n",
    "                                float('inf') if not farthest else 0)\n",
    "\n",
    "    np.fill_diagonal(cluster_distances, 0)\n",
    "\n",
    "    for i in np.arange(0, len(labels) - 1):\n",
    "        for ii in np.arange(i, len(labels)):\n",
    "            if labels[i] != labels[ii] and (\n",
    "                (not farthest and\n",
    "                 distances[i, ii] < cluster_distances[labels[i], labels[ii]])\n",
    "                    or\n",
    "                (farthest and\n",
    "                 distances[i, ii] > cluster_distances[labels[i], labels[ii]])):\n",
    "                cluster_distances[labels[i], labels[ii]] = cluster_distances[\n",
    "                    labels[ii], labels[i]] = distances[i, ii]\n",
    "    return cluster_distances\n",
    "\n",
    "\n",
    "def diameter(labels, distances, method='farthest'):\n",
    "    \"\"\"Calculates cluster diameters\n",
    "    :param labels: a list containing cluster labels for each of the n elements\n",
    "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
    "    :param method: either `mean_cluster` for the mean distance between all elements in each cluster, or `farthest` for the distance between the two points furthest from each other\n",
    "    \"\"\"\n",
    "    if method not in DIAMETER_METHODS:\n",
    "        raise ValueError('method must be one of {}'.format(DIAMETER_METHODS))\n",
    "\n",
    "    n_clusters = len(np.unique(labels))\n",
    "    diameters = np.zeros(n_clusters)\n",
    "\n",
    "    if method == 'mean_cluster':\n",
    "        for i in range(0, len(labels) - 1):\n",
    "            for ii in range(i + 1, len(labels)):\n",
    "                if labels[i] == labels[ii]:\n",
    "                    diameters[labels[i]] += distances[i, ii]\n",
    "\n",
    "        for i in range(len(diameters)):\n",
    "            diameters[i] /= sum(labels == i)\n",
    "\n",
    "    elif method == 'farthest':\n",
    "        for i in range(0, len(labels) - 1):\n",
    "            for ii in range(i + 1, len(labels)):\n",
    "                if labels[i] == labels[ii] and distances[i, ii] > diameters[\n",
    "                        labels[i]]:\n",
    "                    diameters[labels[i]] = distances[i, ii]\n",
    "    return diameters\n",
    "\n",
    "def dunn(labels, distances, diameter_method='farthest',\n",
    "         cdist_method='nearest'):\n",
    "    \"\"\"\n",
    "    Dunn index for cluster validation (larger is better).\n",
    "    \n",
    "    .. math:: D = \\\\min_{i = 1 \\\\ldots n_c; j = i + 1\\ldots n_c} \\\\left\\\\lbrace \\\\frac{d \\\\left( c_i,c_j \\\\right)}{\\\\max_{k = 1 \\\\ldots n_c} \\\\left(diam \\\\left(c_k \\\\right) \\\\right)} \\\\right\\\\rbrace\n",
    "    \n",
    "    where :math:`d(c_i,c_j)` represents the distance between\n",
    "    clusters :math:`c_i` and :math:`c_j`, and :math:`diam(c_k)` is the diameter of cluster :math:`c_k`.\n",
    "    Inter-cluster distance can be defined in many ways, such as the distance between cluster centroids or between their closest elements. Cluster diameter can be defined as the mean distance between all elements in the cluster, between all elements to the cluster centroid, or as the distance between the two furthest elements.\n",
    "    The higher the value of the resulting Dunn index, the better the clustering\n",
    "    result is considered, since higher values indicate that clusters are\n",
    "    compact (small :math:`diam(c_k)`) and far apart (large :math:`d \\\\left( c_i,c_j \\\\right)`).\n",
    "    :param labels: a list containing cluster labels for each of the n elements\n",
    "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
    "    :param diameter_method: see :py:function:`diameter` `method` parameter\n",
    "    :param cdist_method: see :py:function:`diameter` `method` parameter\n",
    "    \n",
    "    .. [Kovacs2005] Kovács, F., Legány, C., & Babos, A. (2005). Cluster validity measurement techniques. 6th International Symposium of Hungarian Researchers on Computational Intelligence.\n",
    "    \"\"\"\n",
    "\n",
    "    labels = LabelEncoder().fit(labels).transform(labels)\n",
    "    \n",
    "    \n",
    "\n",
    "    ic_distances = inter_cluster_distances(labels, distances, cdist_method)\n",
    "    #print(\"IC\",ic_distances)\n",
    "    if len(ic_distances[ic_distances.nonzero()])==0:\n",
    "        min_distance = 0\n",
    "    else:\n",
    "        min_distance = min(ic_distances[ic_distances.nonzero()])\n",
    "    max_diameter = max(diameter(labels, distances, diameter_method))\n",
    "    \n",
    "    \n",
    "\n",
    "    return min_distance / max_diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.replace('nan', np.nan).fillna(0.00001)\n",
    "features = features.drop('Distrito', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cantidad de nan: ', features.isnull().values.any()) \n",
    "#print('Cantidad de inf: ', np.isinf(features).values.sum() ) \n",
    "#print(features.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "k=6\n",
    "\n",
    "#Euclidean\n",
    "f_euclidean_dist = np.zeros((n,n))\n",
    "for i in range(0,n):\n",
    "    #print(\"i\",i)\n",
    "    for j in range(1,n):\n",
    "         f_euclidean_dist[i,j] = euclidean(features.iloc[i].values.flatten(), features.iloc[j].values.flatten())\n",
    "\n",
    "#Corr\n",
    "corr_dist = np.zeros((n,n))\n",
    "for i in range(0,n):\n",
    "    for j in range(0,n):\n",
    "            corr_dist[i,j] = corr(features.iloc[i].values.flatten(), features.iloc[j].values.flatten())\n",
    "\n",
    "#scorr\n",
    "f_scorr_dist = np.zeros((n,n))\n",
    "for i in range(0,n):\n",
    "    for j in range(0,n):\n",
    "        f_scorr_dist[i,j] = scorr(features.iloc[i].values.flatten(), features.iloc[j].values.flatten())\n",
    "#DTW\n",
    "f_dtw_dist = np.zeros((n,n))\n",
    "for i in range(0,n):\n",
    "    for j in range(0,n):\n",
    "        f_dtw_dist[i,j] = fast_DTW(features.iloc[i].values.flatten(), features.iloc[j].values.flatten())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experimentos HAC\n",
    "HAC_EUCLIDEAN=[]\n",
    "HAC_CORRELATION=[]\n",
    "HAC_SPEARMAN=[]\n",
    "HAC_DTW=[]\n",
    "\n",
    "HAC_EUCLIDEAN_CHZ=[]\n",
    "HAC_CORRELATION_CHZ=[]\n",
    "HAC_SPEARMAN_CHZ=[]\n",
    "HAC_DTW_CHZ=[]\n",
    "\n",
    "HAC_EUCLIDEAN_DUNN=[]\n",
    "HAC_CORRELATION_DUNN=[]\n",
    "HAC_SPEARMAN_DUNN=[]\n",
    "HAC_DTW_DUNN=[]\n",
    "\n",
    "HAC_EUCLIDEAN_DAVID=[]\n",
    "HAC_CORRELATION_DAVID=[]\n",
    "HAC_SPEARMAN_DAVID=[]\n",
    "HAC_DTW_DAVID=[]\n",
    "\n",
    "HAC_euc = AgglomerativeClustering(n_clusters=k).fit_predict(f_euclidean_dist)\n",
    "print(\"HAC + euclidian distance: \")\n",
    "sil = silhouette_score(f_euclidean_dist, HAC_euc)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(f_euclidean_dist, HAC_euc)\n",
    "print(\"CHZ: \", chz)\n",
    "dunn_= dunn(HAC_euc, f_euclidean_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_= davies_bouldin_score(f_euclidean_dist, HAC_euc)\n",
    "print(\"DAV-BOUD: \", david_)\n",
    "HAC_EUCLIDEAN.append(sil)\n",
    "HAC_EUCLIDEAN_CHZ.append(chz)\n",
    "HAC_EUCLIDEAN_DUNN.append(dunn_)\n",
    "HAC_EUCLIDEAN_DAVID.append(david_)\n",
    "\n",
    "HAC_corr = AgglomerativeClustering(n_clusters=k).fit_predict(corr_dist)\n",
    "print(\"HAC + corr distance: \")\n",
    "sil = silhouette_score(corr_dist, HAC_corr)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(corr_dist, HAC_corr)\n",
    "print(\"CHZ: \", chz)\n",
    "dunn_ = dunn(HAC_corr, corr_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_= davies_bouldin_score(corr_dist, HAC_corr)\n",
    "print(\"DAV-BOUD: \", david_)\n",
    "HAC_CORRELATION.append(sil)\n",
    "HAC_CORRELATION_CHZ.append(chz)\n",
    "HAC_CORRELATION_DUNN.append(dunn_)\n",
    "HAC_CORRELATION_DAVID.append(david_)\n",
    "\n",
    "HAC_scorr = AgglomerativeClustering(n_clusters=k).fit_predict(f_scorr_dist)\n",
    "print(\"HAC + scorr distance: \")\n",
    "sil = silhouette_score(f_scorr_dist, HAC_scorr)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(f_scorr_dist, HAC_scorr)\n",
    "print(\"CHZ: \", chz)\n",
    "dunn_ = dunn(HAC_scorr, f_scorr_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_= davies_bouldin_score(f_scorr_dist, HAC_scorr)\n",
    "print(\"DAV-BOUD: \", david_)\n",
    "HAC_SPEARMAN.append(sil)\n",
    "HAC_SPEARMAN_CHZ.append(chz)\n",
    "HAC_SPEARMAN_DUNN.append(dunn_)\n",
    "HAC_SPEARMAN_DAVID.append(david_)\n",
    "\n",
    "HAC_dtw = AgglomerativeClustering(n_clusters=k).fit_predict(f_dtw_dist)\n",
    "print(\"HAC + dtw distance: \")\n",
    "sil = silhouette_score(f_dtw_dist, HAC_dtw)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(f_dtw_dist, HAC_dtw)\n",
    "print(\"CHZ: \", chz)\n",
    "dunn_ = dunn(HAC_dtw, f_dtw_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_= davies_bouldin_score(f_dtw_dist, HAC_dtw)\n",
    "print(\"DAV-BOUD: \", david_)\n",
    "HAC_DTW.append(sil)\n",
    "HAC_DTW_CHZ.append(chz)\n",
    "HAC_DTW_DUNN.append(dunn_)\n",
    "HAC_DTW_DAVID.append(david_)\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KM_EUCLIDEAN=[]\n",
    "KM_CORRELATION=[]\n",
    "KM_SPEARMAN=[]\n",
    "KM_DTW=[]\n",
    "\n",
    "KM_EUCLIDEAN_CHZ=[]\n",
    "KM_CORRELATION_CHZ=[]\n",
    "KM_SPEARMAN_CHZ=[]\n",
    "KM_DTW_CHZ=[]\n",
    "\n",
    "KM_EUCLIDEAN_DUNN=[]\n",
    "KM_CORRELATION_DUNN=[]\n",
    "KM_SPEARMAN_DUNN=[]\n",
    "KM_DTW_DUNN=[]\n",
    "\n",
    "KM_EUCLIDEAN_DAVID=[]\n",
    "KM_CORRELATION_DAVID=[]\n",
    "KM_SPEARMAN_DAVID=[]\n",
    "KM_DTW_DAVID=[]\n",
    "#Experimentos K-Means\n",
    "km_euc = KMeans(n_clusters=k).fit_predict(f_euclidean_dist)\n",
    "print(\"KM + euclidian distance: \")\n",
    "sil = silhouette_score(f_euclidean_dist, km_euc)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(f_euclidean_dist, km_euc)\n",
    "print(\"CHZ: \", chz)\n",
    "dunn_ = dunn(km_euc, f_euclidean_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_ = davies_bouldin_score(f_euclidean_dist, km_euc)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "KM_EUCLIDEAN.append(sil)\n",
    "KM_EUCLIDEAN_CHZ.append(chz)\n",
    "KM_EUCLIDEAN_DUNN.append(dunn_)\n",
    "KM_EUCLIDEAN_DAVID.append(david_)\n",
    "\n",
    "km_corr = KMeans(n_clusters=k).fit_predict(corr_dist)\n",
    "print(\"KM + corr distance: \")\n",
    "sil = silhouette_score(corr_dist, km_corr)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(corr_dist, km_corr)\n",
    "print(\"CHZ: \", chz)\n",
    "dunn_ = dunn(km_corr, corr_dist, 'farthest', 'farthest') \n",
    "print(\"DUNN: \", dunn_)\n",
    "david_ = davies_bouldin_score(corr_dist, km_corr)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "KM_CORRELATION.append(sil)\n",
    "KM_CORRELATION_CHZ.append(chz)\n",
    "KM_CORRELATION_DUNN.append(dunn_)\n",
    "KM_CORRELATION_DAVID.append(david_)\n",
    "\n",
    "km_scorr = KMeans(n_clusters=k).fit_predict(f_scorr_dist)\n",
    "print(\"KM + scorr distance: \")\n",
    "sil = silhouette_score(f_scorr_dist, km_scorr)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(f_scorr_dist, km_scorr)\n",
    "print(\"CHZ: \", chz)\n",
    "dunn_ = dunn(km_scorr, f_scorr_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_ = davies_bouldin_score(f_scorr_dist, km_scorr)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "KM_SPEARMAN.append(sil)\n",
    "KM_SPEARMAN_CHZ.append(chz)\n",
    "KM_SPEARMAN_DUNN.append(dunn_)\n",
    "KM_SPEARMAN_DAVID.append(david_)\n",
    "\n",
    "km_dtw = KMeans(n_clusters=k).fit_predict(f_dtw_dist)\n",
    "print(\"KM + dtw distance: \")\n",
    "sil = silhouette_score(f_dtw_dist, km_dtw)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(f_dtw_dist, km_dtw)\n",
    "print(\"CHZ: \", chz)\n",
    "dunn_ = dunn(km_dtw, f_dtw_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_ = davies_bouldin_score(f_dtw_dist, km_dtw)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "KM_DTW.append(sil)\n",
    "KM_DTW_CHZ.append(chz)\n",
    "KM_DTW_DUNN.append(dunn_)\n",
    "KM_DTW_DAVID.append(david_)\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBSCAN_EUCLIDEAN=[]\n",
    "DBSCAN_CORRELATION=[]\n",
    "DBSCAN_SPEARMAN=[]\n",
    "DBSCAN_DTW=[]\n",
    "\n",
    "DBSCAN_EUCLIDEAN_CHZ=[]\n",
    "DBSCAN_CORRELATION_CHZ=[]\n",
    "DBSCAN_SPEARMAN_CHZ=[]\n",
    "DBSCAN_DTW_CHZ=[]\n",
    "\n",
    "DBSCAN_EUCLIDEAN_DUNN=[]\n",
    "DBSCAN_CORRELATION_DUNN=[]\n",
    "DBSCAN_SPEARMAN_DUNN=[]\n",
    "DBSCAN_DTW_DUNN=[]\n",
    "\n",
    "DBSCAN_EUCLIDEAN_DAVID=[]\n",
    "DBSCAN_CORRELATION_DAVID=[]\n",
    "DBSCAN_SPEARMAN_DAVID=[]\n",
    "DBSCAN_DTW_DAVID=[]\n",
    "\n",
    "#CON EUCLIDEAN\n",
    "DB_euc = DBSCAN(eps=500, min_samples=4).fit_predict(f_euclidean_dist)\n",
    "print(\"DBSCAN + euclidian distance: \")\n",
    "sil =  silhouette_score(f_euclidean_dist, DB_euc)\n",
    "print(\"SC: \", sil)\n",
    "CHZ_ = calinski_harabasz_score(f_euclidean_dist, DB_euc) \n",
    "print(\"CHZ: \", CHZ_)\n",
    "dunn_ = dunn(DB_euc, f_euclidean_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_ = davies_bouldin_score(f_euclidean_dist, DB_euc)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "DBSCAN_EUCLIDEAN.append(sil)\n",
    "DBSCAN_EUCLIDEAN_CHZ.append(CHZ_)\n",
    "DBSCAN_EUCLIDEAN_DUNN.append(dunn_)\n",
    "DBSCAN_EUCLIDEAN_DAVID.append(david_)\n",
    "\n",
    "#CON CORRELATION\n",
    "DB_corr = DBSCAN(eps=0.45, min_samples=4).fit_predict(corr_dist)\n",
    "print(\"DBSCAN + corr distance: \")\n",
    "sil = silhouette_score(corr_dist, DB_corr)\n",
    "print(\"SC: \", sil)\n",
    "CHZ_ = calinski_harabasz_score(corr_dist, DB_corr)\n",
    "print(\"CHZ: \", CHZ_)\n",
    "dunn_ = dunn(DB_corr, corr_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \",)\n",
    "david_ = davies_bouldin_score(corr_dist, DB_corr)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "DBSCAN_CORRELATION.append(sil)\n",
    "DBSCAN_CORRELATION_CHZ.append(CHZ_)\n",
    "DBSCAN_CORRELATION_DUNN.append(dunn_)\n",
    "DBSCAN_CORRELATION_DAVID.append(david_)\n",
    "\n",
    "#CON SPEARMAN\n",
    "DB_scorr = DBSCAN(eps=0.45, min_samples=4).fit_predict(f_scorr_dist)\n",
    "print(\"DBSCAN + scorr distance: \")\n",
    "sil = silhouette_score(f_scorr_dist, DB_scorr)\n",
    "print(\"SC: \", sil)\n",
    "CHZ_ = calinski_harabasz_score(f_scorr_dist, DB_scorr)\n",
    "print(\"CHZ: \", CHZ_)\n",
    "dunn_ = dunn(DB_scorr, f_scorr_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_ = davies_bouldin_score(f_scorr_dist, DB_scorr)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "DBSCAN_SPEARMAN.append(sil)\n",
    "DBSCAN_SPEARMAN_CHZ.append(CHZ_)\n",
    "DBSCAN_SPEARMAN_DUNN.append(dunn_)\n",
    "DBSCAN_SPEARMAN_DAVID.append(david_)\n",
    "\n",
    "#CON D TIME WARPING\n",
    "DB_dtw = DBSCAN(eps=500, min_samples=4).fit_predict(f_dtw_dist)\n",
    "print(\"DBSCAN + dtw distance: \")\n",
    "sil = silhouette_score(f_dtw_dist, DB_dtw)\n",
    "print(\"SC: \", sil)\n",
    "CHZ_ = calinski_harabasz_score(f_dtw_dist, DB_dtw)\n",
    "print(\"CHZ: \", CHZ_)\n",
    "dunn_ = dunn(DB_dtw, f_dtw_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_ = davies_bouldin_score(f_dtw_dist, DB_dtw)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "DBSCAN_DTW.append(sil)\n",
    "DBSCAN_DTW_CHZ.append(CHZ_)\n",
    "DBSCAN_DTW_DUNN.append(dunn_)\n",
    "DBSCAN_DTW_DAVID.append(david_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KM1 = KM_EUCLIDEAN + KM_CORRELATION + KM_SPEARMAN + KM_DTW\n",
    "KM2 = KM_EUCLIDEAN_CHZ + KM_CORRELATION_CHZ + KM_SPEARMAN_CHZ + KM_DTW_CHZ\n",
    "KM3 = KM_EUCLIDEAN_DUNN + KM_CORRELATION_DUNN + KM_SPEARMAN_DUNN + KM_DTW_DUNN\n",
    "KM4 = KM_EUCLIDEAN_DAVID + KM_CORRELATION_DAVID + KM_SPEARMAN_DAVID + KM_DTW_DAVID\n",
    "HAC1 = HAC_EUCLIDEAN + HAC_CORRELATION + HAC_SPEARMAN + HAC_DTW\n",
    "HAC2 = HAC_EUCLIDEAN_CHZ + HAC_CORRELATION_CHZ + HAC_SPEARMAN_CHZ + HAC_DTW_CHZ\n",
    "HAC3 = HAC_EUCLIDEAN_DUNN + HAC_CORRELATION_DUNN + HAC_SPEARMAN_DUNN + HAC_DTW_DUNN\n",
    "HAC4 = HAC_EUCLIDEAN_DAVID + HAC_CORRELATION_DAVID + HAC_SPEARMAN_DAVID + HAC_DTW_DAVID\n",
    "DBS1 = DBSCAN_EUCLIDEAN + DBSCAN_CORRELATION + DBSCAN_SPEARMAN + DBSCAN_DTW\n",
    "DBS2 = DBSCAN_EUCLIDEAN_CHZ + DBSCAN_CORRELATION_CHZ + DBSCAN_SPEARMAN_CHZ + DBSCAN_DTW_CHZ\n",
    "DBS3 = DBSCAN_EUCLIDEAN_DUNN + DBSCAN_CORRELATION_DUNN + DBSCAN_SPEARMAN_DUNN + DBSCAN_DTW_DUNN\n",
    "DBS4 = DBSCAN_EUCLIDEAN_DAVID + DBSCAN_CORRELATION_DAVID + DBSCAN_SPEARMAN_DAVID + DBSCAN_DTW_DAVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_scores = pd.DataFrame()\n",
    "sil_scores['METRICA'] = ['Euclidean Distance', 'Pearson Correlation', 'Spearman Correlation', 'Dynamic Time Warping'] \n",
    "sil_scores['SIL - HAC'] = np.array(HAC1)\n",
    "sil_scores['SIL - KM'] = np.array(KM1)\n",
    "sil_scores['SIL - DB'] = np.array(DBS1)\n",
    "sil_scores['CHZ - HAC'] = np.array(HAC2)\n",
    "sil_scores['CHZ - KM'] = np.array(KM2)\n",
    "sil_scores['CHZ - DB'] = np.array(DBS2)\n",
    "sil_scores['DUNN - HAC'] = np.array(HAC3)\n",
    "sil_scores['DUNN - KM'] = np.array(KM3)\n",
    "sil_scores['DUNN - DB'] = np.array(DBS3)\n",
    "sil_scores['DAVID - HAC'] = np.array(HAC4)\n",
    "sil_scores['DAVID - KM'] = np.array(KM4)\n",
    "sil_scores['DAVID - DB'] = np.array(DBS4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_scores.to_csv('Scores1_FeatureBased.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux2 = pd.DataFrame()\n",
    "aux2['Distrito'] = y.Distrito.values\n",
    "aux2['Cluster KM'] = km_euc\n",
    "aux2['Cluster HAC '] = HAC_euc\n",
    "aux2['Cluster DB SP'] = DB_corr\n",
    "aux2.to_csv('ClusterFB1_2015al2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(DB_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(HAC_euc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(km_euc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
