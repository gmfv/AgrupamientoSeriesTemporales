{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELECCION DE ATRIBUTOS\n",
    "\n",
    "## METODO DEL FILTRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "my_path = os.path.abspath('')\n",
    "my_path = my_path.split('\\\\')\n",
    "my_path_py = \"\\\\\".join(my_path[:-1])\n",
    "\n",
    "features = pd.read_csv(my_path_py+'\\\\2_FeatureBased\\\\FB2_2009al2013.csv', sep=',')\n",
    "Puntajes_allf = pd.read_csv(my_path_py+'\\\\2_FeatureBased\\\\Scores1_FeatureBased.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Var</th>\n",
       "      <th>ACF1</th>\n",
       "      <th>Trend</th>\n",
       "      <th>Linearity</th>\n",
       "      <th>Curvature</th>\n",
       "      <th>Season</th>\n",
       "      <th>Peak</th>\n",
       "      <th>Trough</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Lumpiness</th>\n",
       "      <th>Spikiness</th>\n",
       "      <th>Lshift</th>\n",
       "      <th>Vchange</th>\n",
       "      <th>Fspots</th>\n",
       "      <th>Cpoints</th>\n",
       "      <th>KlScore</th>\n",
       "      <th>ChangeIdx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.904494</td>\n",
       "      <td>5.239362e+01</td>\n",
       "      <td>8.135193e-01</td>\n",
       "      <td>0.922999</td>\n",
       "      <td>0.003082</td>\n",
       "      <td>-0.863262</td>\n",
       "      <td>0.025780</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-0.010495</td>\n",
       "      <td>5.978370e-01</td>\n",
       "      <td>1.772715e-04</td>\n",
       "      <td>2.497263e-09</td>\n",
       "      <td>1.086957e-02</td>\n",
       "      <td>5.250998e-05</td>\n",
       "      <td>172.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.781615</td>\n",
       "      <td>4.841265e+03</td>\n",
       "      <td>9.371226e-01</td>\n",
       "      <td>0.958335</td>\n",
       "      <td>0.007501</td>\n",
       "      <td>0.391511</td>\n",
       "      <td>0.046909</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>-0.010903</td>\n",
       "      <td>1.698908e-01</td>\n",
       "      <td>7.906015e-05</td>\n",
       "      <td>5.201407e-10</td>\n",
       "      <td>1.813156e-01</td>\n",
       "      <td>1.006363e-02</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.819130</td>\n",
       "      <td>1.042302e+04</td>\n",
       "      <td>9.285754e-01</td>\n",
       "      <td>0.962853</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>-0.361289</td>\n",
       "      <td>0.010942</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>-0.004989</td>\n",
       "      <td>1.317796e-01</td>\n",
       "      <td>3.606045e-04</td>\n",
       "      <td>5.397936e-10</td>\n",
       "      <td>6.596210e-02</td>\n",
       "      <td>3.044544e-03</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.306891</td>\n",
       "      <td>8.273701e+02</td>\n",
       "      <td>7.051710e-01</td>\n",
       "      <td>0.879186</td>\n",
       "      <td>0.003470</td>\n",
       "      <td>-0.677443</td>\n",
       "      <td>0.049205</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-0.018949</td>\n",
       "      <td>5.381565e-01</td>\n",
       "      <td>3.756719e-04</td>\n",
       "      <td>3.576345e-09</td>\n",
       "      <td>5.000000e-02</td>\n",
       "      <td>2.083333e-03</td>\n",
       "      <td>120.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.676847</td>\n",
       "      <td>1.191727e+04</td>\n",
       "      <td>9.103049e-01</td>\n",
       "      <td>0.940326</td>\n",
       "      <td>0.005569</td>\n",
       "      <td>-0.154082</td>\n",
       "      <td>0.019642</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>-0.005024</td>\n",
       "      <td>1.524750e-01</td>\n",
       "      <td>8.255672e-05</td>\n",
       "      <td>1.405710e-09</td>\n",
       "      <td>1.234592e-01</td>\n",
       "      <td>7.082626e-03</td>\n",
       "      <td>84.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>33.333333</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.984279</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>-0.016121</td>\n",
       "      <td>0.015653</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>3.203435e-11</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>27.129680</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.984279</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>-0.016121</td>\n",
       "      <td>0.015653</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>3.203435e-11</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>23.540490</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.899220</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>-0.144232</td>\n",
       "      <td>0.020585</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>-0.007148</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>2.266590e-03</td>\n",
       "      <td>5.186532e-09</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>191.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>56.497175</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.984279</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>-0.016121</td>\n",
       "      <td>0.015653</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>3.203435e-11</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>10.999890</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.984279</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>-0.016121</td>\n",
       "      <td>0.015653</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>3.203435e-11</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Mean           Var          ACF1     Trend  Linearity  Curvature  \\\n",
       "0     6.904494  5.239362e+01  8.135193e-01  0.922999   0.003082  -0.863262   \n",
       "1    44.781615  4.841265e+03  9.371226e-01  0.958335   0.007501   0.391511   \n",
       "2    44.819130  1.042302e+04  9.285754e-01  0.962853   0.004186  -0.361289   \n",
       "3    18.306891  8.273701e+02  7.051710e-01  0.879186   0.003470  -0.677443   \n",
       "4    59.676847  1.191727e+04  9.103049e-01  0.940326   0.005569  -0.154082   \n",
       "..         ...           ...           ...       ...        ...        ...   \n",
       "195  33.333333  1.000000e-07  1.000000e-08  0.984279   0.000052  -0.016121   \n",
       "196  27.129680  1.000000e-07  1.000000e-08  0.984279   0.000052  -0.016121   \n",
       "197  23.540490  1.000000e-07  1.000000e-08  0.899220   0.000466  -0.144232   \n",
       "198  56.497175  1.000000e-07  1.000000e-08  0.984279   0.000052  -0.016121   \n",
       "199  10.999890  1.000000e-07  1.000000e-08  0.984279   0.000052  -0.016121   \n",
       "\n",
       "       Season          Peak    Trough       Entropy     Lumpiness  \\\n",
       "0    0.025780  1.000000e+00 -0.010495  5.978370e-01  1.772715e-04   \n",
       "1    0.046909  1.000000e-07 -0.010903  1.698908e-01  7.906015e-05   \n",
       "2    0.010942  1.000000e-07 -0.004989  1.317796e-01  3.606045e-04   \n",
       "3    0.049205  1.000000e+00 -0.018949  5.381565e-01  3.756719e-04   \n",
       "4    0.019642  1.000000e-07 -0.005024  1.524750e-01  8.255672e-05   \n",
       "..        ...           ...       ...           ...           ...   \n",
       "195  0.015653  1.000000e-07 -0.001953  1.000000e-08  1.000000e-07   \n",
       "196  0.015653  1.000000e-07 -0.001953  1.000000e-08  1.000000e-07   \n",
       "197  0.020585  1.000000e-07 -0.007148  1.000000e-08  2.266590e-03   \n",
       "198  0.015653  1.000000e-07 -0.001953  1.000000e-08  1.000000e-07   \n",
       "199  0.015653  1.000000e-07 -0.001953  1.000000e-08  1.000000e-07   \n",
       "\n",
       "        Spikiness        Lshift       Vchange  Fspots  Cpoints       KlScore  \\\n",
       "0    2.497263e-09  1.086957e-02  5.250998e-05   172.0      6.0  1.000000e-10   \n",
       "1    5.201407e-10  1.813156e-01  1.006363e-02    49.0     10.0  1.000000e-10   \n",
       "2    5.397936e-10  6.596210e-02  3.044544e-03    58.0      2.0  1.000000e-10   \n",
       "3    3.576345e-09  5.000000e-02  2.083333e-03   120.0      3.0  1.000000e-10   \n",
       "4    1.405710e-09  1.234592e-01  7.082626e-03    84.0      4.0  1.000000e-10   \n",
       "..            ...           ...           ...     ...      ...           ...   \n",
       "195  3.203435e-11  1.000000e-07  1.000000e-07   193.0      0.0  1.000000e-10   \n",
       "196  3.203435e-11  1.000000e-07  1.000000e-07   193.0      0.0  1.000000e-10   \n",
       "197  5.186532e-09  1.000000e-07  1.000000e-07   191.0      1.0  1.000000e-10   \n",
       "198  3.203435e-11  1.000000e-07  1.000000e-07   193.0      0.0  1.000000e-10   \n",
       "199  3.203435e-11  1.000000e-07  1.000000e-07   193.0      0.0  1.000000e-10   \n",
       "\n",
       "        ChangeIdx  \n",
       "0    1.000000e-10  \n",
       "1    1.000000e-10  \n",
       "2    1.000000e-10  \n",
       "3    1.000000e-10  \n",
       "4    1.000000e-10  \n",
       "..            ...  \n",
       "195  1.000000e-10  \n",
       "196  1.000000e-10  \n",
       "197  1.000000e-10  \n",
       "198  1.000000e-10  \n",
       "199  1.000000e-10  \n",
       "\n",
       "[200 rows x 18 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = features.iloc[:, 1:]\n",
    "listadistrito = features.Distrito.values\n",
    "features = features.drop('Distrito', axis=1)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las dimensiones de nuestros datos son:  (200, 18)\n"
     ]
    }
   ],
   "source": [
    "print(\"Las dimensiones de nuestros datos son: \", features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminar features varianza casi nula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "sel = VarianceThreshold(threshold=0.05)\n",
    "f_selection = sel.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las dimensiones de nuestros datos seleccionados son:  (200, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"Las dimensiones de nuestros datos seleccionados son: \", f_selection.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Var</th>\n",
       "      <th>ACF1</th>\n",
       "      <th>Curvature</th>\n",
       "      <th>Peak</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Fspots</th>\n",
       "      <th>Cpoints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.904494</td>\n",
       "      <td>5.239362e+01</td>\n",
       "      <td>8.135193e-01</td>\n",
       "      <td>-0.863262</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.978370e-01</td>\n",
       "      <td>172.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.781615</td>\n",
       "      <td>4.841265e+03</td>\n",
       "      <td>9.371226e-01</td>\n",
       "      <td>0.391511</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.698908e-01</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.819130</td>\n",
       "      <td>1.042302e+04</td>\n",
       "      <td>9.285754e-01</td>\n",
       "      <td>-0.361289</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.317796e-01</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.306891</td>\n",
       "      <td>8.273701e+02</td>\n",
       "      <td>7.051710e-01</td>\n",
       "      <td>-0.677443</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.381565e-01</td>\n",
       "      <td>120.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.676847</td>\n",
       "      <td>1.191727e+04</td>\n",
       "      <td>9.103049e-01</td>\n",
       "      <td>-0.154082</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.524750e-01</td>\n",
       "      <td>84.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>33.333333</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>-0.016121</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>27.129680</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>-0.016121</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>23.540490</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>-0.144232</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>191.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>56.497175</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>-0.016121</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>10.999890</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>-0.016121</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Mean           Var          ACF1  Curvature          Peak  \\\n",
       "0     6.904494  5.239362e+01  8.135193e-01  -0.863262  1.000000e+00   \n",
       "1    44.781615  4.841265e+03  9.371226e-01   0.391511  1.000000e-07   \n",
       "2    44.819130  1.042302e+04  9.285754e-01  -0.361289  1.000000e-07   \n",
       "3    18.306891  8.273701e+02  7.051710e-01  -0.677443  1.000000e+00   \n",
       "4    59.676847  1.191727e+04  9.103049e-01  -0.154082  1.000000e-07   \n",
       "..         ...           ...           ...        ...           ...   \n",
       "195  33.333333  1.000000e-07  1.000000e-08  -0.016121  1.000000e-07   \n",
       "196  27.129680  1.000000e-07  1.000000e-08  -0.016121  1.000000e-07   \n",
       "197  23.540490  1.000000e-07  1.000000e-08  -0.144232  1.000000e-07   \n",
       "198  56.497175  1.000000e-07  1.000000e-08  -0.016121  1.000000e-07   \n",
       "199  10.999890  1.000000e-07  1.000000e-08  -0.016121  1.000000e-07   \n",
       "\n",
       "          Entropy  Fspots  Cpoints  \n",
       "0    5.978370e-01   172.0      6.0  \n",
       "1    1.698908e-01    49.0     10.0  \n",
       "2    1.317796e-01    58.0      2.0  \n",
       "3    5.381565e-01   120.0      3.0  \n",
       "4    1.524750e-01    84.0      4.0  \n",
       "..            ...     ...      ...  \n",
       "195  1.000000e-08   193.0      0.0  \n",
       "196  1.000000e-08   193.0      0.0  \n",
       "197  1.000000e-08   191.0      1.0  \n",
       "198  1.000000e-08   193.0      0.0  \n",
       "199  1.000000e-08   193.0      0.0  \n",
       "\n",
       "[200 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(f_selection, columns = ['Mean','Var','ACF1', 'Curvature', 'Peak', 'Entropy', 'Fspots','Cpoints'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminar features con alta correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Por convención valores mayores a 10 se consideran redundantes\n",
      " \n",
      "Mean tiene  4.334528673330563\n",
      "Var tiene  2.0680184912107658\n",
      "ACF1 tiene  1.7323441944891393\n",
      "Curvature tiene  5.496643123441954\n",
      "Peak tiene  1.4353048404590578\n",
      "Entropy tiene  3.2943105671607453\n",
      "Fspots tiene  5.175466091923836\n",
      "Cpoints tiene  3.9092467382937897\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif_scores = [variance_inflation_factor(df.values, feature) for feature in range(len(df.columns))]\n",
    "print(\"Por convención valores mayores a 10 se consideran redundantes\")\n",
    "print(\" \")\n",
    "i=0\n",
    "for c in df.columns:\n",
    "    print(c, \"tiene \", vif_scores[i])\n",
    "    i = i +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('FeaturesUnsupervised.csv', 'w') as f:\n",
    "    write = csv.writer(f)  \n",
    "    write.writerow(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo de distancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import sqrt, log, floor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statistics import mean\n",
    "from fastdtw import fastdtw\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import pdist\n",
    " \n",
    "#Euclidean\n",
    "def euclidean(x, y):\n",
    "    r=np.linalg.norm(x-y)\n",
    "    if math.isnan(r):\n",
    "        r=1\n",
    "    #print(r)\n",
    "    return r\n",
    "\n",
    "#Fast Dynamic time warping\n",
    "def fast_DTW(x, y):\n",
    "    r, _ = fastdtw(x, y, dist=euclidean)\n",
    "    if math.isnan(r):\n",
    "        r=1\n",
    "    #print(r)\n",
    "    return r\n",
    "\n",
    "#Spearman\n",
    "def scorr(x, y):\n",
    "    r = stats.spearmanr(x, y)[0]\n",
    "    if math.isnan(r):\n",
    "        r=0\n",
    "    #print(r)\n",
    "    return 1 - r\n",
    "\n",
    "#RMSE\n",
    "def rmse(x, y):\n",
    "    r=sqrt(mean_squared_error(x,y))\n",
    "    if math.isnan(r):\n",
    "        r=1\n",
    "    #print(r)\n",
    "    return r\n",
    "\n",
    "def lcs(a, b):  \n",
    "    lengths = [[0 for j in range(len(b)+1)] for i in range(len(a)+1)]\n",
    "    # row 0 and column 0 are initialized to 0 already\n",
    "    for i, x in enumerate(a):\n",
    "        for j, y in enumerate(b):\n",
    "            if x == y:\n",
    "                lengths[i+1][j+1] = lengths[i][j] + 1\n",
    "            else:\n",
    "                lengths[i+1][j+1] = max(lengths[i+1][j], lengths[i][j+1])\n",
    "    x, y = len(a), len(b)\n",
    "    result = lengths[x][y]\n",
    "    return result\n",
    "\n",
    "def discretise(x):\n",
    "    return int(x * 10)\n",
    "\n",
    "def multidim_lcs(a, b):\n",
    "    a = a.applymap(discretise)\n",
    "    b = b.applymap(discretise)\n",
    "    rows, dims = a.shape\n",
    "    lcss = [lcs(a[i+2], b[i+2]) for i in range(dims)]\n",
    "    return 1 - sum(lcss) / (rows * dims)\n",
    "\n",
    "#Correlation\n",
    "def corr(x, y):\n",
    "    r=np.dot(x-mean(x),y-mean(y))/((np.linalg.norm(x-mean(x)))*(np.linalg.norm(y-mean(y))))\n",
    "    if math.isnan(r):\n",
    "        r=0\n",
    "    #print(r)\n",
    "    return 1 - r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from yellowbrick.cluster import KElbowVisualizer\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "import scipy.cluster.hierarchy as hac\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "\n",
    "DIAMETER_METHODS = ['mean_cluster', 'farthest']\n",
    "CLUSTER_DISTANCE_METHODS = ['nearest', 'farthest']\n",
    "\n",
    "def inter_cluster_distances(labels, distances, method='nearest'):\n",
    "    \"\"\"Calculates the distances between the two nearest points of each cluster.\n",
    "    :param labels: a list containing cluster labels for each of the n elements\n",
    "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
    "    :param method: `nearest` for the distances between the two nearest points in each cluster, or `farthest`\n",
    "    \"\"\"\n",
    "    if method not in CLUSTER_DISTANCE_METHODS:\n",
    "        raise ValueError(\n",
    "            'method must be one of {}'.format(CLUSTER_DISTANCE_METHODS))\n",
    "\n",
    "    if method == 'nearest':\n",
    "        return __cluster_distances_by_points(labels, distances)\n",
    "    elif method == 'farthest':\n",
    "        return __cluster_distances_by_points(labels, distances, farthest=True)\n",
    "\n",
    "\n",
    "def __cluster_distances_by_points(labels, distances, farthest=False):\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    cluster_distances = np.full((n_unique_labels, n_unique_labels),\n",
    "                                float('inf') if not farthest else 0)\n",
    "\n",
    "    np.fill_diagonal(cluster_distances, 0)\n",
    "\n",
    "    for i in np.arange(0, len(labels) - 1):\n",
    "        for ii in np.arange(i, len(labels)):\n",
    "            if labels[i] != labels[ii] and (\n",
    "                (not farthest and\n",
    "                 distances[i, ii] < cluster_distances[labels[i], labels[ii]])\n",
    "                    or\n",
    "                (farthest and\n",
    "                 distances[i, ii] > cluster_distances[labels[i], labels[ii]])):\n",
    "                cluster_distances[labels[i], labels[ii]] = cluster_distances[\n",
    "                    labels[ii], labels[i]] = distances[i, ii]\n",
    "    return cluster_distances\n",
    "\n",
    "\n",
    "def diameter(labels, distances, method='farthest'):\n",
    "    \"\"\"Calculates cluster diameters\n",
    "    :param labels: a list containing cluster labels for each of the n elements\n",
    "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
    "    :param method: either `mean_cluster` for the mean distance between all elements in each cluster, or `farthest` for the distance between the two points furthest from each other\n",
    "    \"\"\"\n",
    "    if method not in DIAMETER_METHODS:\n",
    "        raise ValueError('method must be one of {}'.format(DIAMETER_METHODS))\n",
    "\n",
    "    n_clusters = len(np.unique(labels))\n",
    "    diameters = np.zeros(n_clusters)\n",
    "\n",
    "    if method == 'mean_cluster':\n",
    "        for i in range(0, len(labels) - 1):\n",
    "            for ii in range(i + 1, len(labels)):\n",
    "                if labels[i] == labels[ii]:\n",
    "                    diameters[labels[i]] += distances[i, ii]\n",
    "\n",
    "        for i in range(len(diameters)):\n",
    "            diameters[i] /= sum(labels == i)\n",
    "\n",
    "    elif method == 'farthest':\n",
    "        for i in range(0, len(labels) - 1):\n",
    "            for ii in range(i + 1, len(labels)):\n",
    "                if labels[i] == labels[ii] and distances[i, ii] > diameters[\n",
    "                        labels[i]]:\n",
    "                    diameters[labels[i]] = distances[i, ii]\n",
    "    return diameters\n",
    "\n",
    "def dunn(labels, distances, diameter_method='farthest',\n",
    "         cdist_method='nearest'):\n",
    "    \"\"\"\n",
    "    Dunn index for cluster validation (larger is better).\n",
    "    \n",
    "    .. math:: D = \\\\min_{i = 1 \\\\ldots n_c; j = i + 1\\ldots n_c} \\\\left\\\\lbrace \\\\frac{d \\\\left( c_i,c_j \\\\right)}{\\\\max_{k = 1 \\\\ldots n_c} \\\\left(diam \\\\left(c_k \\\\right) \\\\right)} \\\\right\\\\rbrace\n",
    "    \n",
    "    where :math:`d(c_i,c_j)` represents the distance between\n",
    "    clusters :math:`c_i` and :math:`c_j`, and :math:`diam(c_k)` is the diameter of cluster :math:`c_k`.\n",
    "    Inter-cluster distance can be defined in many ways, such as the distance between cluster centroids or between their closest elements. Cluster diameter can be defined as the mean distance between all elements in the cluster, between all elements to the cluster centroid, or as the distance between the two furthest elements.\n",
    "    The higher the value of the resulting Dunn index, the better the clustering\n",
    "    result is considered, since higher values indicate that clusters are\n",
    "    compact (small :math:`diam(c_k)`) and far apart (large :math:`d \\\\left( c_i,c_j \\\\right)`).\n",
    "    :param labels: a list containing cluster labels for each of the n elements\n",
    "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
    "    :param diameter_method: see :py:function:`diameter` `method` parameter\n",
    "    :param cdist_method: see :py:function:`diameter` `method` parameter\n",
    "    \n",
    "    .. [Kovacs2005] Kovács, F., Legány, C., & Babos, A. (2005). Cluster validity measurement techniques. 6th International Symposium of Hungarian Researchers on Computational Intelligence.\n",
    "    \"\"\"\n",
    "\n",
    "    labels = LabelEncoder().fit(labels).transform(labels)\n",
    "    \n",
    "    \n",
    "\n",
    "    ic_distances = inter_cluster_distances(labels, distances, cdist_method)\n",
    "    #print(\"IC\",ic_distances)\n",
    "    if len(ic_distances[ic_distances.nonzero()])==0:\n",
    "        min_distance = 0\n",
    "    else:\n",
    "        min_distance = min(ic_distances[ic_distances.nonzero()])\n",
    "    max_diameter = max(diameter(labels, distances, diameter_method))\n",
    "    \n",
    "    \n",
    "\n",
    "    return min_distance / max_diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "k=7\n",
    "n = df.shape[0]\n",
    "\n",
    "#Euclidean\n",
    "f_euclidean_dist = np.zeros((n,n))\n",
    "for i in range(0,n):\n",
    "    #print(\"i\",i)\n",
    "    for j in range(1,n):\n",
    "         f_euclidean_dist[i,j] = euclidean(df.iloc[i].values.flatten(), df.iloc[j].values.flatten())\n",
    "\n",
    "#Corr\n",
    "corr_dist = np.zeros((n,n))\n",
    "for i in range(0,n):\n",
    "    for j in range(0,n):\n",
    "            corr_dist[i,j] = corr(df.iloc[i].values.flatten(), df.iloc[j].values.flatten())\n",
    "\n",
    "#scorr\n",
    "f_scorr_dist = np.zeros((n,n))\n",
    "for i in range(0,n):\n",
    "    for j in range(0,n):\n",
    "        f_scorr_dist[i,j] = scorr(df.iloc[i].values.flatten(), df.iloc[j].values.flatten())\n",
    "#DTW\n",
    "f_dtw_dist = np.zeros((n,n))\n",
    "for i in range(0,n):\n",
    "    for j in range(0,n):\n",
    "        f_dtw_dist[i,j] = fast_DTW(df.iloc[i].values.flatten(), df.iloc[j].values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAC + euclidian distance: \n",
      "SC:  0.8319207549392479\n",
      "CHZ:  4832.653364103001\n",
      "DUNN:  0.7838787127673288\n",
      "DAV-BOUD:  0.35810448223179286\n",
      "HAC + corr distance: \n",
      "SC:  0.6526463830821754\n",
      "CHZ:  2311.981986100565\n",
      "DUNN:  4.398782736275968\n",
      "DAV-BOUD:  0.4607619093013353\n",
      "HAC + scorr distance: \n",
      "SC:  0.45519592887293925\n",
      "CHZ:  154.4179885778777\n",
      "DUNN:  0.0\n",
      "DAV-BOUD:  0.851820676107282\n",
      "HAC + dtw distance: \n",
      "SC:  0.8276300187725087\n",
      "CHZ:  4751.661926793881\n",
      "DUNN:  0.8143388836312776\n",
      "DAV-BOUD:  0.3562309219762447\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\cluster\\hierarchy.py:826: ClusterWarning: scipy.cluster: The symmetric non-negative hollow observation matrix looks suspiciously like an uncondensed distance matrix\n",
      "  return linkage(y, method='ward', metric='euclidean')\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\cluster\\hierarchy.py:826: ClusterWarning: scipy.cluster: The symmetric non-negative hollow observation matrix looks suspiciously like an uncondensed distance matrix\n",
      "  return linkage(y, method='ward', metric='euclidean')\n"
     ]
    }
   ],
   "source": [
    "#Experimentos HAC\n",
    "HAC_EUCLIDEAN=[]\n",
    "HAC_CORRELATION=[]\n",
    "HAC_SPEARMAN=[]\n",
    "HAC_DTW=[]\n",
    "\n",
    "HAC_EUCLIDEAN_CHZ=[]\n",
    "HAC_CORRELATION_CHZ=[]\n",
    "HAC_SPEARMAN_CHZ=[]\n",
    "HAC_DTW_CHZ=[]\n",
    "\n",
    "HAC_EUCLIDEAN_DUNN=[]\n",
    "HAC_CORRELATION_DUNN=[]\n",
    "HAC_SPEARMAN_DUNN=[]\n",
    "HAC_DTW_DUNN=[]\n",
    "\n",
    "HAC_EUCLIDEAN_DAVID=[]\n",
    "HAC_CORRELATION_DAVID=[]\n",
    "HAC_SPEARMAN_DAVID=[]\n",
    "HAC_DTW_DAVID=[]\n",
    "\n",
    "HAC_euc = AgglomerativeClustering(n_clusters=k).fit_predict(f_euclidean_dist)\n",
    "print(\"HAC + euclidian distance: \")\n",
    "sil = silhouette_score(f_euclidean_dist, HAC_euc)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(f_euclidean_dist, HAC_euc)\n",
    "print(\"CHZ: \", chz)\n",
    "dunn_= dunn(HAC_euc, f_euclidean_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_= davies_bouldin_score(f_euclidean_dist, HAC_euc)\n",
    "print(\"DAV-BOUD: \", david_)\n",
    "HAC_EUCLIDEAN.append(sil)\n",
    "HAC_EUCLIDEAN_CHZ.append(chz)\n",
    "HAC_EUCLIDEAN_DUNN.append(dunn_)\n",
    "HAC_EUCLIDEAN_DAVID.append(david_)\n",
    "\n",
    "HAC_corr = AgglomerativeClustering(n_clusters=k).fit_predict(corr_dist)\n",
    "print(\"HAC + corr distance: \")\n",
    "sil = silhouette_score(corr_dist, HAC_corr)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(corr_dist, HAC_corr)\n",
    "print(\"CHZ: \", chz)\n",
    "dunn_ = dunn(HAC_corr, corr_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_= davies_bouldin_score(corr_dist, HAC_corr)\n",
    "print(\"DAV-BOUD: \", david_)\n",
    "HAC_CORRELATION.append(sil)\n",
    "HAC_CORRELATION_CHZ.append(chz)\n",
    "HAC_CORRELATION_DUNN.append(dunn_)\n",
    "HAC_CORRELATION_DAVID.append(david_)\n",
    "\n",
    "HAC_scorr = AgglomerativeClustering(n_clusters=k).fit_predict(f_scorr_dist)\n",
    "print(\"HAC + scorr distance: \")\n",
    "sil = silhouette_score(f_scorr_dist, HAC_scorr)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(f_scorr_dist, HAC_scorr)\n",
    "print(\"CHZ: \", chz)\n",
    "dunn_ = dunn(HAC_scorr, f_scorr_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_= davies_bouldin_score(f_scorr_dist, HAC_scorr)\n",
    "print(\"DAV-BOUD: \", david_)\n",
    "HAC_SPEARMAN.append(sil)\n",
    "HAC_SPEARMAN_CHZ.append(chz)\n",
    "HAC_SPEARMAN_DUNN.append(dunn_)\n",
    "HAC_SPEARMAN_DAVID.append(david_)\n",
    "\n",
    "HAC_dtw = AgglomerativeClustering(n_clusters=k).fit_predict(f_dtw_dist)\n",
    "print(\"HAC + dtw distance: \")\n",
    "sil = silhouette_score(f_dtw_dist, HAC_dtw)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(f_dtw_dist, HAC_dtw)\n",
    "print(\"CHZ: \", chz)\n",
    "dunn_ = dunn(HAC_dtw, f_dtw_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_= davies_bouldin_score(f_dtw_dist, HAC_dtw)\n",
    "print(\"DAV-BOUD: \", david_)\n",
    "HAC_DTW.append(sil)\n",
    "HAC_DTW_CHZ.append(chz)\n",
    "HAC_DTW_DUNN.append(dunn_)\n",
    "HAC_DTW_DAVID.append(david_)\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KM + euclidian distance: \n",
      "SC:  0.8319207549392479\n",
      "CHZ:  4832.653364103003\n",
      "DUNN:  0.7838787127673288\n",
      "DAV-BOULD:  0.35810448223179286\n",
      "KM + corr distance: \n",
      "SC:  0.6279590715318004\n",
      "CHZ:  2508.3658167098474\n",
      "DUNN:  4.461302707197484\n",
      "DAV-BOULD:  0.45972804676856693\n",
      "KM + scorr distance: \n",
      "SC:  0.47559310395100846\n",
      "CHZ:  159.84112512583968\n",
      "DUNN:  0.0\n",
      "DAV-BOULD:  0.7853048102674135\n",
      "KM + dtw distance: \n",
      "SC:  0.8276300187725087\n",
      "CHZ:  4751.661926793881\n",
      "DUNN:  0.8143388836312776\n",
      "DAV-BOULD:  0.3562309219762446\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "KM_EUCLIDEAN=[]\n",
    "KM_CORRELATION=[]\n",
    "KM_SPEARMAN=[]\n",
    "KM_DTW=[]\n",
    "\n",
    "KM_EUCLIDEAN_CHZ=[]\n",
    "KM_CORRELATION_CHZ=[]\n",
    "KM_SPEARMAN_CHZ=[]\n",
    "KM_DTW_CHZ=[]\n",
    "\n",
    "KM_EUCLIDEAN_DUNN=[]\n",
    "KM_CORRELATION_DUNN=[]\n",
    "KM_SPEARMAN_DUNN=[]\n",
    "KM_DTW_DUNN=[]\n",
    "\n",
    "KM_EUCLIDEAN_DAVID=[]\n",
    "KM_CORRELATION_DAVID=[]\n",
    "KM_SPEARMAN_DAVID=[]\n",
    "KM_DTW_DAVID=[]\n",
    "#Experimentos K-Means\n",
    "km_euc = KMeans(n_clusters=k).fit_predict(f_euclidean_dist)\n",
    "print(\"KM + euclidian distance: \")\n",
    "sil = silhouette_score(f_euclidean_dist, km_euc)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(f_euclidean_dist, km_euc)\n",
    "print(\"CHZ: \", chz)\n",
    "dunn_ = dunn(km_euc, f_euclidean_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_ = davies_bouldin_score(f_euclidean_dist, km_euc)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "KM_EUCLIDEAN.append(sil)\n",
    "KM_EUCLIDEAN_CHZ.append(chz)\n",
    "KM_EUCLIDEAN_DUNN.append(dunn_)\n",
    "KM_EUCLIDEAN_DAVID.append(david_)\n",
    "\n",
    "km_corr = KMeans(n_clusters=k).fit_predict(corr_dist)\n",
    "print(\"KM + corr distance: \")\n",
    "sil = silhouette_score(corr_dist, km_corr)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(corr_dist, km_corr)\n",
    "print(\"CHZ: \", chz)\n",
    "dunn_ = dunn(km_corr, corr_dist, 'farthest', 'farthest') \n",
    "print(\"DUNN: \", dunn_)\n",
    "david_ = davies_bouldin_score(corr_dist, km_corr)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "KM_CORRELATION.append(sil)\n",
    "KM_CORRELATION_CHZ.append(chz)\n",
    "KM_CORRELATION_DUNN.append(dunn_)\n",
    "KM_CORRELATION_DAVID.append(david_)\n",
    "\n",
    "km_scorr = KMeans(n_clusters=k).fit_predict(f_scorr_dist)\n",
    "print(\"KM + scorr distance: \")\n",
    "sil = silhouette_score(f_scorr_dist, km_scorr)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(f_scorr_dist, km_scorr)\n",
    "print(\"CHZ: \", chz)\n",
    "dunn_ = dunn(km_scorr, f_scorr_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_ = davies_bouldin_score(f_scorr_dist, km_scorr)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "KM_SPEARMAN.append(sil)\n",
    "KM_SPEARMAN_CHZ.append(chz)\n",
    "KM_SPEARMAN_DUNN.append(dunn_)\n",
    "KM_SPEARMAN_DAVID.append(david_)\n",
    "\n",
    "km_dtw = KMeans(n_clusters=k).fit_predict(f_dtw_dist)\n",
    "print(\"KM + dtw distance: \")\n",
    "sil = silhouette_score(f_dtw_dist, km_dtw)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(f_dtw_dist, km_dtw)\n",
    "print(\"CHZ: \", chz)\n",
    "dunn_ = dunn(km_dtw, f_dtw_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_ = davies_bouldin_score(f_dtw_dist, km_dtw)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "KM_DTW.append(sil)\n",
    "KM_DTW_CHZ.append(chz)\n",
    "KM_DTW_DUNN.append(dunn_)\n",
    "KM_DTW_DAVID.append(david_)\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN + euclidian distance: \n",
      "SC:  0.13173910318139814\n",
      "CHZ:  9.652856308330737\n",
      "DUNN:  0.003152175270140244\n",
      "DAV-BOULD:  1.3381556776155534\n",
      "DBSCAN + corr distance: \n",
      "SC:  0.3776484047793511\n",
      "CHZ:  485.21250628087097\n",
      "DUNN:  3.314028817355511\n",
      "DAV-BOULD:  0.484932541025244\n",
      "DBSCAN + scorr distance: \n",
      "SC:  0.6497509020751286\n",
      "CHZ:  42.635387843339544\n",
      "DUNN:  0.0\n",
      "DAV-BOULD:  1.0154328333912\n",
      "DBSCAN + dtw distance: \n",
      "SC:  -0.1343781705312182\n",
      "CHZ:  5.176964795201058\n",
      "DUNN:  0.0016401563242398015\n",
      "DAV-BOULD:  1.452475550786027\n"
     ]
    }
   ],
   "source": [
    "DBSCAN_EUCLIDEAN=[]\n",
    "DBSCAN_CORRELATION=[]\n",
    "DBSCAN_SPEARMAN=[]\n",
    "DBSCAN_DTW=[]\n",
    "\n",
    "DBSCAN_EUCLIDEAN_CHZ=[]\n",
    "DBSCAN_CORRELATION_CHZ=[]\n",
    "DBSCAN_SPEARMAN_CHZ=[]\n",
    "DBSCAN_DTW_CHZ=[]\n",
    "\n",
    "DBSCAN_EUCLIDEAN_DUNN=[]\n",
    "DBSCAN_CORRELATION_DUNN=[]\n",
    "DBSCAN_SPEARMAN_DUNN=[]\n",
    "DBSCAN_DTW_DUNN=[]\n",
    "\n",
    "DBSCAN_EUCLIDEAN_DAVID=[]\n",
    "DBSCAN_CORRELATION_DAVID=[]\n",
    "DBSCAN_SPEARMAN_DAVID=[]\n",
    "DBSCAN_DTW_DAVID=[]\n",
    "\n",
    "#CON EUCLIDEAN\n",
    "DB_euc = DBSCAN(eps=170, min_samples=4).fit_predict(f_euclidean_dist)\n",
    "print(\"DBSCAN + euclidian distance: \")\n",
    "sil =  silhouette_score(f_euclidean_dist, DB_euc)\n",
    "print(\"SC: \", sil)\n",
    "CHZ_ = calinski_harabasz_score(f_euclidean_dist, DB_euc) \n",
    "print(\"CHZ: \", CHZ_)\n",
    "dunn_ = dunn(DB_euc, f_euclidean_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_ = davies_bouldin_score(f_euclidean_dist, DB_euc)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "DBSCAN_EUCLIDEAN.append(sil)\n",
    "DBSCAN_EUCLIDEAN_CHZ.append(CHZ_)\n",
    "DBSCAN_EUCLIDEAN_DUNN.append(dunn_)\n",
    "DBSCAN_EUCLIDEAN_DAVID.append(david_)\n",
    "\n",
    "#CON CORRELATION\n",
    "DB_corr = DBSCAN(eps=0.45, min_samples=4).fit_predict(corr_dist)\n",
    "print(\"DBSCAN + corr distance: \")\n",
    "sil = silhouette_score(corr_dist, DB_corr)\n",
    "print(\"SC: \", sil)\n",
    "CHZ_ = calinski_harabasz_score(corr_dist, DB_corr)\n",
    "print(\"CHZ: \", CHZ_)\n",
    "dunn_ = dunn(DB_corr, corr_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_ = davies_bouldin_score(corr_dist, DB_corr)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "DBSCAN_CORRELATION.append(sil)\n",
    "DBSCAN_CORRELATION_CHZ.append(CHZ_)\n",
    "DBSCAN_CORRELATION_DUNN.append(dunn_)\n",
    "DBSCAN_CORRELATION_DAVID.append(david_)\n",
    "\n",
    "#CON SPEARMAN\n",
    "DB_scorr = DBSCAN(eps=0.45, min_samples=4).fit_predict(f_scorr_dist)\n",
    "print(\"DBSCAN + scorr distance: \")\n",
    "sil = silhouette_score(f_scorr_dist, DB_scorr)\n",
    "print(\"SC: \", sil)\n",
    "CHZ_ = calinski_harabasz_score(f_scorr_dist, DB_scorr)\n",
    "print(\"CHZ: \", CHZ_)\n",
    "dunn_ = dunn(DB_scorr, f_scorr_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_ = davies_bouldin_score(f_scorr_dist, DB_scorr)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "DBSCAN_SPEARMAN.append(sil)\n",
    "DBSCAN_SPEARMAN_CHZ.append(CHZ_)\n",
    "DBSCAN_SPEARMAN_DUNN.append(dunn_)\n",
    "DBSCAN_SPEARMAN_DAVID.append(david_)\n",
    "\n",
    "#CON D TIME WARPING\n",
    "DB_dtw = DBSCAN(eps=170, min_samples=4).fit_predict(f_dtw_dist)\n",
    "print(\"DBSCAN + dtw distance: \")\n",
    "sil = silhouette_score(f_dtw_dist, DB_dtw)\n",
    "print(\"SC: \", sil)\n",
    "CHZ_ = calinski_harabasz_score(f_dtw_dist, DB_dtw)\n",
    "print(\"CHZ: \", CHZ_)\n",
    "dunn_ = dunn(DB_dtw, f_dtw_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_ = davies_bouldin_score(f_dtw_dist, DB_dtw)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "DBSCAN_DTW.append(sil)\n",
    "DBSCAN_DTW_CHZ.append(CHZ_)\n",
    "DBSCAN_DTW_DUNN.append(dunn_)\n",
    "DBSCAN_DTW_DAVID.append(david_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Puntajes_allf = Puntajes_allf.drop('Unnamed: 0', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['METRICA', 'SIL - HAC', 'SIL - KM', 'SIL - DB', 'CHZ - HAC', 'CHZ - KM',\n",
       "       'CHZ - DB', 'DUNN - HAC', 'DUNN - KM', 'DUNN - DB', 'DAVID - HAC',\n",
       "       'DAVID - KM', 'DAVID - DB'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Puntajes_allf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIL_f = Puntajes_allf[['METRICA', 'SIL - HAC', 'SIL - KM', 'SIL - DB']]\n",
    "CHZ_f = Puntajes_allf[['METRICA', 'CHZ - HAC', 'CHZ - KM', 'CHZ - DB']]\n",
    "DUNN_f = Puntajes_allf[['METRICA','DUNN - HAC', 'DUNN - KM', 'DUNN - DB']]\n",
    "DAVIES_f = Puntajes_allf[['METRICA', 'DAVID - HAC', 'DAVID - KM', 'DAVID - DB']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-a1b7a3e4e810>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SIL_f['SIL HAC 8'] = [ HAC_EUCLIDEAN[0], HAC_CORRELATION[0], HAC_SPEARMAN[0], HAC_DTW[0]]\n",
      "<ipython-input-18-a1b7a3e4e810>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SIL_f['SIL KM 8'] = [ KM_EUCLIDEAN[0], KM_CORRELATION[0], KM_SPEARMAN[0], KM_DTW[0]]\n",
      "<ipython-input-18-a1b7a3e4e810>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SIL_f['SIL DB 8'] = [ DBSCAN_EUCLIDEAN[0], DBSCAN_CORRELATION[0], DBSCAN_SPEARMAN[0], DBSCAN_DTW[0]]\n"
     ]
    }
   ],
   "source": [
    "SIL_f['SIL HAC 8'] = [ HAC_EUCLIDEAN[0], HAC_CORRELATION[0], HAC_SPEARMAN[0], HAC_DTW[0]]\n",
    "SIL_f['SIL KM 8'] = [ KM_EUCLIDEAN[0], KM_CORRELATION[0], KM_SPEARMAN[0], KM_DTW[0]]\n",
    "SIL_f['SIL DB 8'] = [ DBSCAN_EUCLIDEAN[0], DBSCAN_CORRELATION[0], DBSCAN_SPEARMAN[0], DBSCAN_DTW[0]]\n",
    "\n",
    "SIL_f = SIL_f.rename(columns={\"SIL - HAC\": \"SIL HAC 18\", \"SIL - KM\": \"SIL KM 18\", \"SIL - DB\": \"SIL DB 18\"})\n",
    "SIL_f = SIL_f[['METRICA', 'SIL HAC 18', 'SIL HAC 8', 'SIL KM 18', 'SIL KM 8', 'SIL DB 18','SIL DB 8']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SILHOUETTE SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>METRICA</th>\n",
       "      <th>SIL HAC 18</th>\n",
       "      <th>SIL HAC 8</th>\n",
       "      <th>SIL KM 18</th>\n",
       "      <th>SIL KM 8</th>\n",
       "      <th>SIL DB 18</th>\n",
       "      <th>SIL DB 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Euclidean Distance</td>\n",
       "      <td>0.836977</td>\n",
       "      <td>0.831921</td>\n",
       "      <td>0.863019</td>\n",
       "      <td>0.831921</td>\n",
       "      <td>0.381371</td>\n",
       "      <td>0.131739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pearson Correlation</td>\n",
       "      <td>0.614693</td>\n",
       "      <td>0.652646</td>\n",
       "      <td>0.658074</td>\n",
       "      <td>0.627959</td>\n",
       "      <td>0.402963</td>\n",
       "      <td>0.377648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spearman Correlation</td>\n",
       "      <td>0.571987</td>\n",
       "      <td>0.455196</td>\n",
       "      <td>0.601930</td>\n",
       "      <td>0.475593</td>\n",
       "      <td>0.603897</td>\n",
       "      <td>0.649751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dynamic Time Warping</td>\n",
       "      <td>0.827022</td>\n",
       "      <td>0.827630</td>\n",
       "      <td>0.861052</td>\n",
       "      <td>0.827630</td>\n",
       "      <td>0.517592</td>\n",
       "      <td>-0.134378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                METRICA  SIL HAC 18  SIL HAC 8  SIL KM 18  SIL KM 8  \\\n",
       "0    Euclidean Distance    0.836977   0.831921   0.863019  0.831921   \n",
       "1   Pearson Correlation    0.614693   0.652646   0.658074  0.627959   \n",
       "2  Spearman Correlation    0.571987   0.455196   0.601930  0.475593   \n",
       "3  Dynamic Time Warping    0.827022   0.827630   0.861052  0.827630   \n",
       "\n",
       "   SIL DB 18  SIL DB 8  \n",
       "0   0.381371  0.131739  \n",
       "1   0.402963  0.377648  \n",
       "2   0.603897  0.649751  \n",
       "3   0.517592 -0.134378  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIL_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHZ SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>METRICA</th>\n",
       "      <th>CHZ - HAC</th>\n",
       "      <th>CHZ - KM</th>\n",
       "      <th>CHZ - DB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Euclidean Distance</td>\n",
       "      <td>2742.276633</td>\n",
       "      <td>3238.982031</td>\n",
       "      <td>14.568195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pearson Correlation</td>\n",
       "      <td>1807.267371</td>\n",
       "      <td>2187.546418</td>\n",
       "      <td>441.524050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spearman Correlation</td>\n",
       "      <td>386.430859</td>\n",
       "      <td>396.536422</td>\n",
       "      <td>167.059548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dynamic Time Warping</td>\n",
       "      <td>2699.310719</td>\n",
       "      <td>3164.737066</td>\n",
       "      <td>31.070024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                METRICA    CHZ - HAC     CHZ - KM    CHZ - DB\n",
       "0    Euclidean Distance  2742.276633  3238.982031   14.568195\n",
       "1   Pearson Correlation  1807.267371  2187.546418  441.524050\n",
       "2  Spearman Correlation   386.430859   396.536422  167.059548\n",
       "3  Dynamic Time Warping  2699.310719  3164.737066   31.070024"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHZ_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-0d83fa437da1>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CHZ_f['CHZ HAC 8'] = [ HAC_EUCLIDEAN_CHZ[0], HAC_CORRELATION_CHZ[0], HAC_SPEARMAN_CHZ[0], HAC_DTW_CHZ[0]]\n",
      "<ipython-input-21-0d83fa437da1>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CHZ_f['CHZ KM 8'] = [ KM_EUCLIDEAN_CHZ[0], KM_CORRELATION_CHZ[0], KM_SPEARMAN_CHZ[0], KM_DTW_CHZ[0]]\n",
      "<ipython-input-21-0d83fa437da1>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  CHZ_f['CHZ DB 8'] = [ DBSCAN_EUCLIDEAN_CHZ[0], DBSCAN_CORRELATION_CHZ[0], DBSCAN_SPEARMAN_CHZ[0], DBSCAN_DTW_CHZ[0]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>METRICA</th>\n",
       "      <th>CHZ HAC 18</th>\n",
       "      <th>CHZ HAC 8</th>\n",
       "      <th>CHZ KM 18</th>\n",
       "      <th>CHZ KM 8</th>\n",
       "      <th>CHZ DB 18</th>\n",
       "      <th>CHZ DB 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Euclidean Distance</td>\n",
       "      <td>2742.276633</td>\n",
       "      <td>4832.653364</td>\n",
       "      <td>3238.982031</td>\n",
       "      <td>4832.653364</td>\n",
       "      <td>14.568195</td>\n",
       "      <td>9.652856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pearson Correlation</td>\n",
       "      <td>1807.267371</td>\n",
       "      <td>2311.981986</td>\n",
       "      <td>2187.546418</td>\n",
       "      <td>2508.365817</td>\n",
       "      <td>441.524050</td>\n",
       "      <td>485.212506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spearman Correlation</td>\n",
       "      <td>386.430859</td>\n",
       "      <td>154.417989</td>\n",
       "      <td>396.536422</td>\n",
       "      <td>159.841125</td>\n",
       "      <td>167.059548</td>\n",
       "      <td>42.635388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dynamic Time Warping</td>\n",
       "      <td>2699.310719</td>\n",
       "      <td>4751.661927</td>\n",
       "      <td>3164.737066</td>\n",
       "      <td>4751.661927</td>\n",
       "      <td>31.070024</td>\n",
       "      <td>5.176965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                METRICA   CHZ HAC 18    CHZ HAC 8    CHZ KM 18     CHZ KM 8  \\\n",
       "0    Euclidean Distance  2742.276633  4832.653364  3238.982031  4832.653364   \n",
       "1   Pearson Correlation  1807.267371  2311.981986  2187.546418  2508.365817   \n",
       "2  Spearman Correlation   386.430859   154.417989   396.536422   159.841125   \n",
       "3  Dynamic Time Warping  2699.310719  4751.661927  3164.737066  4751.661927   \n",
       "\n",
       "    CHZ DB 18    CHZ DB 8  \n",
       "0   14.568195    9.652856  \n",
       "1  441.524050  485.212506  \n",
       "2  167.059548   42.635388  \n",
       "3   31.070024    5.176965  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHZ_f['CHZ HAC 8'] = [ HAC_EUCLIDEAN_CHZ[0], HAC_CORRELATION_CHZ[0], HAC_SPEARMAN_CHZ[0], HAC_DTW_CHZ[0]]\n",
    "CHZ_f['CHZ KM 8'] = [ KM_EUCLIDEAN_CHZ[0], KM_CORRELATION_CHZ[0], KM_SPEARMAN_CHZ[0], KM_DTW_CHZ[0]]\n",
    "CHZ_f['CHZ DB 8'] = [ DBSCAN_EUCLIDEAN_CHZ[0], DBSCAN_CORRELATION_CHZ[0], DBSCAN_SPEARMAN_CHZ[0], DBSCAN_DTW_CHZ[0]]\n",
    "\n",
    "CHZ_f = CHZ_f.rename(columns={\"CHZ - HAC\": \"CHZ HAC 18\", \"CHZ - KM\": \"CHZ KM 18\", \"CHZ - DB\": \"CHZ DB 18\"})\n",
    "CHZ_f = CHZ_f[['METRICA', 'CHZ HAC 18', 'CHZ HAC 8', 'CHZ KM 18', 'CHZ KM 8', 'CHZ DB 18','CHZ DB 8']]\n",
    "\n",
    "CHZ_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-f5cfe30bf94a>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  DAVIES_f['DAVIES HAC 8'] = [ HAC_EUCLIDEAN_DAVID[0], HAC_CORRELATION_DAVID[0], HAC_SPEARMAN_DAVID[0], HAC_DTW_DAVID[0]]\n",
      "<ipython-input-22-f5cfe30bf94a>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  DAVIES_f['DAVIES KM 8'] = [ KM_EUCLIDEAN_DAVID[0], KM_CORRELATION_DAVID[0], KM_SPEARMAN_DAVID[0], KM_DTW_DAVID[0]]\n",
      "<ipython-input-22-f5cfe30bf94a>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  DAVIES_f['DAVIES DB 8'] = [ DBSCAN_EUCLIDEAN_DAVID[0], DBSCAN_CORRELATION_DAVID[0], DBSCAN_SPEARMAN_DAVID[0], DBSCAN_DTW_DAVID[0]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>METRICA</th>\n",
       "      <th>DAVIES HAC 18</th>\n",
       "      <th>DAVIES HAC 8</th>\n",
       "      <th>DAVIES KM 18</th>\n",
       "      <th>DAVIES KM 8</th>\n",
       "      <th>DAVIES DB 18</th>\n",
       "      <th>DAVIES DB 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Euclidean Distance</td>\n",
       "      <td>0.395113</td>\n",
       "      <td>0.358104</td>\n",
       "      <td>0.331150</td>\n",
       "      <td>0.358104</td>\n",
       "      <td>1.129731</td>\n",
       "      <td>1.338156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pearson Correlation</td>\n",
       "      <td>0.456257</td>\n",
       "      <td>0.460762</td>\n",
       "      <td>0.461560</td>\n",
       "      <td>0.459728</td>\n",
       "      <td>0.569509</td>\n",
       "      <td>0.484933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spearman Correlation</td>\n",
       "      <td>0.715892</td>\n",
       "      <td>0.851821</td>\n",
       "      <td>0.694827</td>\n",
       "      <td>0.785305</td>\n",
       "      <td>1.098502</td>\n",
       "      <td>1.015433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dynamic Time Warping</td>\n",
       "      <td>0.348792</td>\n",
       "      <td>0.356231</td>\n",
       "      <td>0.329847</td>\n",
       "      <td>0.356231</td>\n",
       "      <td>1.213330</td>\n",
       "      <td>1.452476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                METRICA  DAVIES HAC 18  DAVIES HAC 8  DAVIES KM 18  \\\n",
       "0    Euclidean Distance       0.395113      0.358104      0.331150   \n",
       "1   Pearson Correlation       0.456257      0.460762      0.461560   \n",
       "2  Spearman Correlation       0.715892      0.851821      0.694827   \n",
       "3  Dynamic Time Warping       0.348792      0.356231      0.329847   \n",
       "\n",
       "   DAVIES KM 8  DAVIES DB 18  DAVIES DB 8  \n",
       "0     0.358104      1.129731     1.338156  \n",
       "1     0.459728      0.569509     0.484933  \n",
       "2     0.785305      1.098502     1.015433  \n",
       "3     0.356231      1.213330     1.452476  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DAVIES_f['DAVIES HAC 8'] = [ HAC_EUCLIDEAN_DAVID[0], HAC_CORRELATION_DAVID[0], HAC_SPEARMAN_DAVID[0], HAC_DTW_DAVID[0]]\n",
    "DAVIES_f['DAVIES KM 8'] = [ KM_EUCLIDEAN_DAVID[0], KM_CORRELATION_DAVID[0], KM_SPEARMAN_DAVID[0], KM_DTW_DAVID[0]]\n",
    "DAVIES_f['DAVIES DB 8'] = [ DBSCAN_EUCLIDEAN_DAVID[0], DBSCAN_CORRELATION_DAVID[0], DBSCAN_SPEARMAN_DAVID[0], DBSCAN_DTW_DAVID[0]]\n",
    "\n",
    "DAVIES_f = DAVIES_f.rename(columns={\"DAVID - HAC\": \"DAVIES HAC 18\", \"DAVID - KM\": \"DAVIES KM 18\", \"DAVID - DB\": \"DAVIES DB 18\"})\n",
    "DAVIES_f = DAVIES_f[['METRICA', 'DAVIES HAC 18', 'DAVIES HAC 8', 'DAVIES KM 18', 'DAVIES KM 8', 'DAVIES DB 18','DAVIES DB 8']]\n",
    "\n",
    "DAVIES_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Euclidean Distance\n",
       "1     Pearson Correlation\n",
       "2    Spearman Correlation\n",
       "3    Dynamic Time Warping\n",
       "Name: METRICA, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIL_f['METRICA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>METRICA</th>\n",
       "      <th>SIL HAC 8</th>\n",
       "      <th>SIL KM 8</th>\n",
       "      <th>SIL DB 8</th>\n",
       "      <th>CHZ HAC 8</th>\n",
       "      <th>CHZ KM 8</th>\n",
       "      <th>CHZ DB 8</th>\n",
       "      <th>DAVIES HAC 8</th>\n",
       "      <th>DAVIES KM 8</th>\n",
       "      <th>DAVIES DB 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Euclidean Distance</td>\n",
       "      <td>0.831921</td>\n",
       "      <td>0.831921</td>\n",
       "      <td>0.131739</td>\n",
       "      <td>4832.653364</td>\n",
       "      <td>4832.653364</td>\n",
       "      <td>9.652856</td>\n",
       "      <td>0.358104</td>\n",
       "      <td>0.358104</td>\n",
       "      <td>1.338156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pearson Correlation</td>\n",
       "      <td>0.652646</td>\n",
       "      <td>0.627959</td>\n",
       "      <td>0.377648</td>\n",
       "      <td>2311.981986</td>\n",
       "      <td>2508.365817</td>\n",
       "      <td>485.212506</td>\n",
       "      <td>0.460762</td>\n",
       "      <td>0.459728</td>\n",
       "      <td>0.484933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spearman Correlation</td>\n",
       "      <td>0.455196</td>\n",
       "      <td>0.475593</td>\n",
       "      <td>0.649751</td>\n",
       "      <td>154.417989</td>\n",
       "      <td>159.841125</td>\n",
       "      <td>42.635388</td>\n",
       "      <td>0.851821</td>\n",
       "      <td>0.785305</td>\n",
       "      <td>1.015433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dynamic Time Warping</td>\n",
       "      <td>0.827630</td>\n",
       "      <td>0.827630</td>\n",
       "      <td>-0.134378</td>\n",
       "      <td>4751.661927</td>\n",
       "      <td>4751.661927</td>\n",
       "      <td>5.176965</td>\n",
       "      <td>0.356231</td>\n",
       "      <td>0.356231</td>\n",
       "      <td>1.452476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                METRICA  SIL HAC 8  SIL KM 8  SIL DB 8    CHZ HAC 8  \\\n",
       "0    Euclidean Distance   0.831921  0.831921  0.131739  4832.653364   \n",
       "1   Pearson Correlation   0.652646  0.627959  0.377648  2311.981986   \n",
       "2  Spearman Correlation   0.455196  0.475593  0.649751   154.417989   \n",
       "3  Dynamic Time Warping   0.827630  0.827630 -0.134378  4751.661927   \n",
       "\n",
       "      CHZ KM 8    CHZ DB 8  DAVIES HAC 8  DAVIES KM 8  DAVIES DB 8  \n",
       "0  4832.653364    9.652856      0.358104     0.358104     1.338156  \n",
       "1  2508.365817  485.212506      0.460762     0.459728     0.484933  \n",
       "2   159.841125   42.635388      0.851821     0.785305     1.015433  \n",
       "3  4751.661927    5.176965      0.356231     0.356231     1.452476  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOTAL = pd.concat([SIL_f.drop(['SIL HAC 18', 'SIL KM 18', 'SIL DB 18'], axis=1), CHZ_f.drop(['METRICA', 'CHZ HAC 18', 'CHZ KM 18', 'CHZ DB 18'], axis=1), DAVIES_f.drop(['METRICA', 'DAVIES HAC 18', 'DAVIES KM 18', 'DAVIES DB 18'], axis=1)], axis=1)\n",
    "TOTAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL.to_csv('Scores8F_Based.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux2 = pd.DataFrame()\n",
    "aux2['Distrito'] = listadistrito\n",
    "aux2['Cluster KM'] = km_euc\n",
    "aux2['Cluster HAC '] = HAC_euc\n",
    "aux2['Cluster DB SP'] = DB_scorr\n",
    "aux2.to_csv('ClusterFBFS_2009al2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
