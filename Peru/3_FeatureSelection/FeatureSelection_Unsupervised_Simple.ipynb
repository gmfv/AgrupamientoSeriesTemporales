{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELECCION DE ATRIBUTOS\n",
    "\n",
    "## METODO DEL FILTRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "my_path = os.path.abspath('')\n",
    "my_path = my_path.split('\\\\')\n",
    "my_path_py = \"\\\\\".join(my_path[:-1])\n",
    "\n",
    "features = pd.read_csv(my_path_py+'\\\\2_FeatureBased\\\\MatrizFeatures\\\\18Features_Kats.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Var</th>\n",
       "      <th>aCF1</th>\n",
       "      <th>Trend</th>\n",
       "      <th>Linearity</th>\n",
       "      <th>Curvature</th>\n",
       "      <th>Season</th>\n",
       "      <th>Peak</th>\n",
       "      <th>Trough</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Lumpiness</th>\n",
       "      <th>Spikiness</th>\n",
       "      <th>Lshift</th>\n",
       "      <th>Vchange</th>\n",
       "      <th>Fspots</th>\n",
       "      <th>Cpoints</th>\n",
       "      <th>KlScore</th>\n",
       "      <th>ChangeIdx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.416142</td>\n",
       "      <td>28.037741</td>\n",
       "      <td>-0.019594</td>\n",
       "      <td>0.478521</td>\n",
       "      <td>0.057369</td>\n",
       "      <td>16.105723</td>\n",
       "      <td>0.259515</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>0.877947</td>\n",
       "      <td>1.123065e+03</td>\n",
       "      <td>0.131363</td>\n",
       "      <td>2.235336</td>\n",
       "      <td>453.036663</td>\n",
       "      <td>15</td>\n",
       "      <td>8.0</td>\n",
       "      <td>722.122511</td>\n",
       "      <td>139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.968925</td>\n",
       "      <td>162.793719</td>\n",
       "      <td>-0.019594</td>\n",
       "      <td>0.698416</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>24.055788</td>\n",
       "      <td>0.408785</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.000000e-11</td>\n",
       "      <td>0.809780</td>\n",
       "      <td>2.782585e+04</td>\n",
       "      <td>0.171691</td>\n",
       "      <td>3.804760</td>\n",
       "      <td>1683.966820</td>\n",
       "      <td>29</td>\n",
       "      <td>35.0</td>\n",
       "      <td>762.034875</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.896803</td>\n",
       "      <td>16.483865</td>\n",
       "      <td>-0.019594</td>\n",
       "      <td>0.511541</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>-1.342372</td>\n",
       "      <td>0.448205</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.000000e-11</td>\n",
       "      <td>0.853613</td>\n",
       "      <td>4.816986e+02</td>\n",
       "      <td>0.024675</td>\n",
       "      <td>1.563966</td>\n",
       "      <td>244.599033</td>\n",
       "      <td>15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>722.257988</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.277973</td>\n",
       "      <td>84.933434</td>\n",
       "      <td>-0.019594</td>\n",
       "      <td>0.308881</td>\n",
       "      <td>0.013646</td>\n",
       "      <td>-1.388677</td>\n",
       "      <td>0.487622</td>\n",
       "      <td>1.000000e-11</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.816967</td>\n",
       "      <td>1.288353e+04</td>\n",
       "      <td>3.156452</td>\n",
       "      <td>3.415301</td>\n",
       "      <td>1166.427782</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>185.725861</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.691190</td>\n",
       "      <td>6.586993</td>\n",
       "      <td>-0.019594</td>\n",
       "      <td>0.775271</td>\n",
       "      <td>0.109978</td>\n",
       "      <td>13.397455</td>\n",
       "      <td>0.358239</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.000000e-11</td>\n",
       "      <td>0.793282</td>\n",
       "      <td>1.484992e+02</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.995897</td>\n",
       "      <td>109.760378</td>\n",
       "      <td>26</td>\n",
       "      <td>9.0</td>\n",
       "      <td>677.073513</td>\n",
       "      <td>264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>6.635039</td>\n",
       "      <td>321.295085</td>\n",
       "      <td>-0.019594</td>\n",
       "      <td>0.723762</td>\n",
       "      <td>0.005861</td>\n",
       "      <td>23.381332</td>\n",
       "      <td>0.341699</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>0.773567</td>\n",
       "      <td>1.297361e+05</td>\n",
       "      <td>1.234726</td>\n",
       "      <td>5.865676</td>\n",
       "      <td>3440.615516</td>\n",
       "      <td>26</td>\n",
       "      <td>8.0</td>\n",
       "      <td>803.206199</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>6.295408</td>\n",
       "      <td>399.615990</td>\n",
       "      <td>-0.019594</td>\n",
       "      <td>0.780696</td>\n",
       "      <td>0.019926</td>\n",
       "      <td>-36.253978</td>\n",
       "      <td>0.306853</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>0.765285</td>\n",
       "      <td>5.349600e+05</td>\n",
       "      <td>3.651875</td>\n",
       "      <td>10.209300</td>\n",
       "      <td>9195.444576</td>\n",
       "      <td>31</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1820.287731</td>\n",
       "      <td>212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>12.949082</td>\n",
       "      <td>3202.673627</td>\n",
       "      <td>-0.019594</td>\n",
       "      <td>0.690501</td>\n",
       "      <td>0.045318</td>\n",
       "      <td>-175.632538</td>\n",
       "      <td>0.530664</td>\n",
       "      <td>1.000000e-11</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>0.859131</td>\n",
       "      <td>3.691856e+07</td>\n",
       "      <td>872.908533</td>\n",
       "      <td>31.860500</td>\n",
       "      <td>83632.763411</td>\n",
       "      <td>21</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4652.544429</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>6.487195</td>\n",
       "      <td>593.850800</td>\n",
       "      <td>-0.019594</td>\n",
       "      <td>0.839640</td>\n",
       "      <td>0.059928</td>\n",
       "      <td>111.830241</td>\n",
       "      <td>0.290624</td>\n",
       "      <td>1.000000e-11</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.733766</td>\n",
       "      <td>1.151792e+06</td>\n",
       "      <td>2.262564</td>\n",
       "      <td>10.373444</td>\n",
       "      <td>5509.147684</td>\n",
       "      <td>31</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1597.619581</td>\n",
       "      <td>305.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.346773</td>\n",
       "      <td>6.253082</td>\n",
       "      <td>-0.019594</td>\n",
       "      <td>0.183448</td>\n",
       "      <td>0.006657</td>\n",
       "      <td>-1.879678</td>\n",
       "      <td>0.266920</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>0.988549</td>\n",
       "      <td>6.980402e+01</td>\n",
       "      <td>0.169676</td>\n",
       "      <td>0.918949</td>\n",
       "      <td>84.446675</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>227.132294</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Mean          Var      aCF1     Trend  Linearity   Curvature  \\\n",
       "0     1.416142    28.037741 -0.019594  0.478521   0.057369   16.105723   \n",
       "1     7.968925   162.793719 -0.019594  0.698416   0.005168   24.055788   \n",
       "2     0.896803    16.483865 -0.019594  0.511541   0.000878   -1.342372   \n",
       "3     1.277973    84.933434 -0.019594  0.308881   0.013646   -1.388677   \n",
       "4     0.691190     6.586993 -0.019594  0.775271   0.109978   13.397455   \n",
       "..         ...          ...       ...       ...        ...         ...   \n",
       "500   6.635039   321.295085 -0.019594  0.723762   0.005861   23.381332   \n",
       "501   6.295408   399.615990 -0.019594  0.780696   0.019926  -36.253978   \n",
       "502  12.949082  3202.673627 -0.019594  0.690501   0.045318 -175.632538   \n",
       "503   6.487195   593.850800 -0.019594  0.839640   0.059928  111.830241   \n",
       "504   0.346773     6.253082 -0.019594  0.183448   0.006657   -1.879678   \n",
       "\n",
       "       Season          Peak        Trough   Entropy     Lumpiness   Spikiness  \\\n",
       "0    0.259515  4.000000e+00  6.000000e+00  0.877947  1.123065e+03    0.131363   \n",
       "1    0.408785  3.000000e+00  1.000000e-11  0.809780  2.782585e+04    0.171691   \n",
       "2    0.448205  4.000000e+00  1.000000e-11  0.853613  4.816986e+02    0.024675   \n",
       "3    0.487622  1.000000e-11  1.000000e+00  0.816967  1.288353e+04    3.156452   \n",
       "4    0.358239  3.000000e+00  1.000000e-11  0.793282  1.484992e+02    0.000393   \n",
       "..        ...           ...           ...       ...           ...         ...   \n",
       "500  0.341699  3.000000e+00  6.000000e+00  0.773567  1.297361e+05    1.234726   \n",
       "501  0.306853  2.000000e+00  5.000000e+00  0.765285  5.349600e+05    3.651875   \n",
       "502  0.530664  1.000000e-11  5.000000e+00  0.859131  3.691856e+07  872.908533   \n",
       "503  0.290624  1.000000e-11  1.000000e+00  0.733766  1.151792e+06    2.262564   \n",
       "504  0.266920  3.000000e+00  6.000000e+00  0.988549  6.980402e+01    0.169676   \n",
       "\n",
       "        Lshift       Vchange  Fspots  Cpoints      KlScore  ChangeIdx  \n",
       "0     2.235336    453.036663      15      8.0   722.122511      139.0  \n",
       "1     3.804760   1683.966820      29     35.0   762.034875      101.0  \n",
       "2     1.563966    244.599033      15      3.0   722.257988        3.0  \n",
       "3     3.415301   1166.427782      10      1.0   185.725861       48.0  \n",
       "4     0.995897    109.760378      26      9.0   677.073513      264.0  \n",
       "..         ...           ...     ...      ...          ...        ...  \n",
       "500   5.865676   3440.615516      26      8.0   803.206199       46.0  \n",
       "501  10.209300   9195.444576      31      6.0  1820.287731      212.0  \n",
       "502  31.860500  83632.763411      21      8.0  4652.544429       42.0  \n",
       "503  10.373444   5509.147684      31      7.0  1597.619581      305.0  \n",
       "504   0.918949     84.446675       5      1.0   227.132294       12.0  \n",
       "\n",
       "[505 rows x 18 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#features = features.iloc[:, 1:]\n",
    "listadistrito = features['Dep-Prov-Distrito'].values\n",
    "features = features.drop('Dep-Prov-Distrito', axis=1)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las dimensiones de nuestros datos son:  (505, 18)\n"
     ]
    }
   ],
   "source": [
    "print(\"Las dimensiones de nuestros datos son: \", features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminar features varianza casi nula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "#sel = VarianceThreshold(threshold = 0.3)\n",
    "#f_selection = sel.fit_transform(features)\n",
    "\n",
    "sel = VarianceThreshold(threshold = 0.3)\n",
    "\n",
    "# Fit\n",
    "_ = sel.fit(features)\n",
    "\n",
    "# Get the boolean mask\n",
    "mask = sel.get_support()\n",
    "\n",
    "features_reduced = features.loc[:, mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las dimensiones de nuestros datos seleccionados son:  (505, 13)\n"
     ]
    }
   ],
   "source": [
    "print(\"Las dimensiones de nuestros datos seleccionados son: \", features_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = features_reduced.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminar features con alta correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Por convención valores mayores a 10 se consideran redundantes\n",
      " \n",
      "Mean tiene  24.050179079785458\n",
      "Var tiene  210.76089029539582\n",
      "Curvature tiene  3.304225302331793\n",
      "Peak tiene  1.709436727762797\n",
      "Trough tiene  1.9997282844043356\n",
      "Lumpiness tiene  202.94057822703883\n",
      "Spikiness tiene  70.72951721607414\n",
      "Lshift tiene  25.98611440314274\n",
      "Vchange tiene  15.742873437990614\n",
      "Fspots tiene  8.463429048566388\n",
      "Cpoints tiene  2.9145871526096125\n",
      "KlScore tiene  6.659861938208996\n",
      "ChangeIdx tiene  3.605480211746351\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif_scores = [variance_inflation_factor(df.values, feature) for feature in range(len(df.columns))]\n",
    "print(\"Por convención valores mayores a 10 se consideran redundantes\")\n",
    "print(\" \")\n",
    "i=0\n",
    "listafiltrada = []\n",
    "listaeliminados = []\n",
    "for c in df.columns:\n",
    "    print(c, \"tiene \", vif_scores[i])\n",
    "    if (vif_scores[i]<30):\n",
    "        listafiltrada.append(c)\n",
    "    else:\n",
    "        listaeliminados.append(c)\n",
    "    i = i +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('FeaturesUnsupervised.csv', 'w') as f:\n",
    "    write = csv.writer(f)  \n",
    "    write.writerow(listafiltrada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Var', 'Lumpiness', 'Spikiness']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listaeliminados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo de distancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import sqrt, log, floor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statistics import mean\n",
    "from fastdtw import fastdtw\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import pdist\n",
    " \n",
    "#Euclidean\n",
    "def euclidean(x, y):\n",
    "    r=np.linalg.norm(x-y)\n",
    "    if math.isnan(r):\n",
    "        r=1\n",
    "    #print(r)\n",
    "    return r\n",
    "\n",
    "#Fast Dynamic time warping\n",
    "def fast_DTW(x, y):\n",
    "    r, _ = fastdtw(x, y, dist=euclidean)\n",
    "    if math.isnan(r):\n",
    "        r=1\n",
    "    #print(r)\n",
    "    return r\n",
    "\n",
    "#Spearman\n",
    "def scorr(x, y):\n",
    "    r = stats.spearmanr(x, y)[0]\n",
    "    if math.isnan(r):\n",
    "        r=0\n",
    "    #print(r)\n",
    "    return 1 - r\n",
    "\n",
    "#RMSE\n",
    "def rmse(x, y):\n",
    "    r=sqrt(mean_squared_error(x,y))\n",
    "    if math.isnan(r):\n",
    "        r=1\n",
    "    #print(r)\n",
    "    return r\n",
    "\n",
    "def lcs(a, b):  \n",
    "    lengths = [[0 for j in range(len(b)+1)] for i in range(len(a)+1)]\n",
    "    # row 0 and column 0 are initialized to 0 already\n",
    "    for i, x in enumerate(a):\n",
    "        for j, y in enumerate(b):\n",
    "            if x == y:\n",
    "                lengths[i+1][j+1] = lengths[i][j] + 1\n",
    "            else:\n",
    "                lengths[i+1][j+1] = max(lengths[i+1][j], lengths[i][j+1])\n",
    "    x, y = len(a), len(b)\n",
    "    result = lengths[x][y]\n",
    "    return result\n",
    "\n",
    "def discretise(x):\n",
    "    return int(x * 10)\n",
    "\n",
    "def multidim_lcs(a, b):\n",
    "    a = a.applymap(discretise)\n",
    "    b = b.applymap(discretise)\n",
    "    rows, dims = a.shape\n",
    "    lcss = [lcs(a[i+2], b[i+2]) for i in range(dims)]\n",
    "    return 1 - sum(lcss) / (rows * dims)\n",
    "\n",
    "#Correlation\n",
    "def corr(x, y):\n",
    "    r=np.dot(x-mean(x),y-mean(y))/((np.linalg.norm(x-mean(x)))*(np.linalg.norm(y-mean(y))))\n",
    "    if math.isnan(r):\n",
    "        r=0\n",
    "    #print(r)\n",
    "    return 1 - r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from yellowbrick.cluster import KElbowVisualizer\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "import scipy.cluster.hierarchy as hac\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "\n",
    "DIAMETER_METHODS = ['mean_cluster', 'farthest']\n",
    "CLUSTER_DISTANCE_METHODS = ['nearest', 'farthest']\n",
    "\n",
    "def inter_cluster_distances(labels, distances, method='nearest'):\n",
    "    \"\"\"Calculates the distances between the two nearest points of each cluster.\n",
    "    :param labels: a list containing cluster labels for each of the n elements\n",
    "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
    "    :param method: `nearest` for the distances between the two nearest points in each cluster, or `farthest`\n",
    "    \"\"\"\n",
    "    if method not in CLUSTER_DISTANCE_METHODS:\n",
    "        raise ValueError(\n",
    "            'method must be one of {}'.format(CLUSTER_DISTANCE_METHODS))\n",
    "\n",
    "    if method == 'nearest':\n",
    "        return __cluster_distances_by_points(labels, distances)\n",
    "    elif method == 'farthest':\n",
    "        return __cluster_distances_by_points(labels, distances, farthest=True)\n",
    "\n",
    "\n",
    "def __cluster_distances_by_points(labels, distances, farthest=False):\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    cluster_distances = np.full((n_unique_labels, n_unique_labels),\n",
    "                                float('inf') if not farthest else 0)\n",
    "\n",
    "    np.fill_diagonal(cluster_distances, 0)\n",
    "\n",
    "    for i in np.arange(0, len(labels) - 1):\n",
    "        for ii in np.arange(i, len(labels)):\n",
    "            if labels[i] != labels[ii] and (\n",
    "                (not farthest and\n",
    "                 distances[i, ii] < cluster_distances[labels[i], labels[ii]])\n",
    "                    or\n",
    "                (farthest and\n",
    "                 distances[i, ii] > cluster_distances[labels[i], labels[ii]])):\n",
    "                cluster_distances[labels[i], labels[ii]] = cluster_distances[\n",
    "                    labels[ii], labels[i]] = distances[i, ii]\n",
    "    return cluster_distances\n",
    "\n",
    "\n",
    "def diameter(labels, distances, method='farthest'):\n",
    "    \"\"\"Calculates cluster diameters\n",
    "    :param labels: a list containing cluster labels for each of the n elements\n",
    "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
    "    :param method: either `mean_cluster` for the mean distance between all elements in each cluster, or `farthest` for the distance between the two points furthest from each other\n",
    "    \"\"\"\n",
    "    if method not in DIAMETER_METHODS:\n",
    "        raise ValueError('method must be one of {}'.format(DIAMETER_METHODS))\n",
    "\n",
    "    n_clusters = len(np.unique(labels))\n",
    "    diameters = np.zeros(n_clusters)\n",
    "\n",
    "    if method == 'mean_cluster':\n",
    "        for i in range(0, len(labels) - 1):\n",
    "            for ii in range(i + 1, len(labels)):\n",
    "                if labels[i] == labels[ii]:\n",
    "                    diameters[labels[i]] += distances[i, ii]\n",
    "\n",
    "        for i in range(len(diameters)):\n",
    "            diameters[i] /= sum(labels == i)\n",
    "\n",
    "    elif method == 'farthest':\n",
    "        for i in range(0, len(labels) - 1):\n",
    "            for ii in range(i + 1, len(labels)):\n",
    "                if labels[i] == labels[ii] and distances[i, ii] > diameters[\n",
    "                        labels[i]]:\n",
    "                    diameters[labels[i]] = distances[i, ii]\n",
    "    return diameters\n",
    "\n",
    "def dunn(labels, distances, diameter_method='farthest',\n",
    "         cdist_method='nearest'):\n",
    "    \"\"\"\n",
    "    Dunn index for cluster validation (larger is better).\n",
    "    \n",
    "    .. math:: D = \\\\min_{i = 1 \\\\ldots n_c; j = i + 1\\ldots n_c} \\\\left\\\\lbrace \\\\frac{d \\\\left( c_i,c_j \\\\right)}{\\\\max_{k = 1 \\\\ldots n_c} \\\\left(diam \\\\left(c_k \\\\right) \\\\right)} \\\\right\\\\rbrace\n",
    "    \n",
    "    where :math:`d(c_i,c_j)` represents the distance between\n",
    "    clusters :math:`c_i` and :math:`c_j`, and :math:`diam(c_k)` is the diameter of cluster :math:`c_k`.\n",
    "    Inter-cluster distance can be defined in many ways, such as the distance between cluster centroids or between their closest elements. Cluster diameter can be defined as the mean distance between all elements in the cluster, between all elements to the cluster centroid, or as the distance between the two furthest elements.\n",
    "    The higher the value of the resulting Dunn index, the better the clustering\n",
    "    result is considered, since higher values indicate that clusters are\n",
    "    compact (small :math:`diam(c_k)`) and far apart (large :math:`d \\\\left( c_i,c_j \\\\right)`).\n",
    "    :param labels: a list containing cluster labels for each of the n elements\n",
    "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
    "    :param diameter_method: see :py:function:`diameter` `method` parameter\n",
    "    :param cdist_method: see :py:function:`diameter` `method` parameter\n",
    "    \n",
    "    .. [Kovacs2005] Kovács, F., Legány, C., & Babos, A. (2005). Cluster validity measurement techniques. 6th International Symposium of Hungarian Researchers on Computational Intelligence.\n",
    "    \"\"\"\n",
    "\n",
    "    labels = LabelEncoder().fit(labels).transform(labels)\n",
    "    \n",
    "    \n",
    "\n",
    "    ic_distances = inter_cluster_distances(labels, distances, cdist_method)\n",
    "    #print(\"IC\",ic_distances)\n",
    "    if len(ic_distances[ic_distances.nonzero()])==0:\n",
    "        min_distance = 0\n",
    "    else:\n",
    "        min_distance = min(ic_distances[ic_distances.nonzero()])\n",
    "    max_diameter = max(diameter(labels, distances, diameter_method))\n",
    "    \n",
    "    \n",
    "\n",
    "    return min_distance / max_diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición de número de grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CÁLCULO DE MATRICES DE DISTANCIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Var</th>\n",
       "      <th>Curvature</th>\n",
       "      <th>Peak</th>\n",
       "      <th>Trough</th>\n",
       "      <th>Lumpiness</th>\n",
       "      <th>Spikiness</th>\n",
       "      <th>Lshift</th>\n",
       "      <th>Vchange</th>\n",
       "      <th>Fspots</th>\n",
       "      <th>Cpoints</th>\n",
       "      <th>KlScore</th>\n",
       "      <th>ChangeIdx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.416142</td>\n",
       "      <td>28.037741</td>\n",
       "      <td>16.105723</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.123065e+03</td>\n",
       "      <td>0.131363</td>\n",
       "      <td>2.235336</td>\n",
       "      <td>453.036663</td>\n",
       "      <td>15</td>\n",
       "      <td>8.0</td>\n",
       "      <td>722.122511</td>\n",
       "      <td>139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.968925</td>\n",
       "      <td>162.793719</td>\n",
       "      <td>24.055788</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.000000e-11</td>\n",
       "      <td>2.782585e+04</td>\n",
       "      <td>0.171691</td>\n",
       "      <td>3.804760</td>\n",
       "      <td>1683.966820</td>\n",
       "      <td>29</td>\n",
       "      <td>35.0</td>\n",
       "      <td>762.034875</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.896803</td>\n",
       "      <td>16.483865</td>\n",
       "      <td>-1.342372</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.000000e-11</td>\n",
       "      <td>4.816986e+02</td>\n",
       "      <td>0.024675</td>\n",
       "      <td>1.563966</td>\n",
       "      <td>244.599033</td>\n",
       "      <td>15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>722.257988</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.277973</td>\n",
       "      <td>84.933434</td>\n",
       "      <td>-1.388677</td>\n",
       "      <td>1.000000e-11</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.288353e+04</td>\n",
       "      <td>3.156452</td>\n",
       "      <td>3.415301</td>\n",
       "      <td>1166.427782</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>185.725861</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.691190</td>\n",
       "      <td>6.586993</td>\n",
       "      <td>13.397455</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.000000e-11</td>\n",
       "      <td>1.484992e+02</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.995897</td>\n",
       "      <td>109.760378</td>\n",
       "      <td>26</td>\n",
       "      <td>9.0</td>\n",
       "      <td>677.073513</td>\n",
       "      <td>264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>6.635039</td>\n",
       "      <td>321.295085</td>\n",
       "      <td>23.381332</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.297361e+05</td>\n",
       "      <td>1.234726</td>\n",
       "      <td>5.865676</td>\n",
       "      <td>3440.615516</td>\n",
       "      <td>26</td>\n",
       "      <td>8.0</td>\n",
       "      <td>803.206199</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>6.295408</td>\n",
       "      <td>399.615990</td>\n",
       "      <td>-36.253978</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>5.349600e+05</td>\n",
       "      <td>3.651875</td>\n",
       "      <td>10.209300</td>\n",
       "      <td>9195.444576</td>\n",
       "      <td>31</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1820.287731</td>\n",
       "      <td>212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>12.949082</td>\n",
       "      <td>3202.673627</td>\n",
       "      <td>-175.632538</td>\n",
       "      <td>1.000000e-11</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>3.691856e+07</td>\n",
       "      <td>872.908533</td>\n",
       "      <td>31.860500</td>\n",
       "      <td>83632.763411</td>\n",
       "      <td>21</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4652.544429</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>6.487195</td>\n",
       "      <td>593.850800</td>\n",
       "      <td>111.830241</td>\n",
       "      <td>1.000000e-11</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.151792e+06</td>\n",
       "      <td>2.262564</td>\n",
       "      <td>10.373444</td>\n",
       "      <td>5509.147684</td>\n",
       "      <td>31</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1597.619581</td>\n",
       "      <td>305.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.346773</td>\n",
       "      <td>6.253082</td>\n",
       "      <td>-1.879678</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>6.980402e+01</td>\n",
       "      <td>0.169676</td>\n",
       "      <td>0.918949</td>\n",
       "      <td>84.446675</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>227.132294</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Mean          Var   Curvature          Peak        Trough  \\\n",
       "0     1.416142    28.037741   16.105723  4.000000e+00  6.000000e+00   \n",
       "1     7.968925   162.793719   24.055788  3.000000e+00  1.000000e-11   \n",
       "2     0.896803    16.483865   -1.342372  4.000000e+00  1.000000e-11   \n",
       "3     1.277973    84.933434   -1.388677  1.000000e-11  1.000000e+00   \n",
       "4     0.691190     6.586993   13.397455  3.000000e+00  1.000000e-11   \n",
       "..         ...          ...         ...           ...           ...   \n",
       "500   6.635039   321.295085   23.381332  3.000000e+00  6.000000e+00   \n",
       "501   6.295408   399.615990  -36.253978  2.000000e+00  5.000000e+00   \n",
       "502  12.949082  3202.673627 -175.632538  1.000000e-11  5.000000e+00   \n",
       "503   6.487195   593.850800  111.830241  1.000000e-11  1.000000e+00   \n",
       "504   0.346773     6.253082   -1.879678  3.000000e+00  6.000000e+00   \n",
       "\n",
       "        Lumpiness   Spikiness     Lshift       Vchange  Fspots  Cpoints  \\\n",
       "0    1.123065e+03    0.131363   2.235336    453.036663      15      8.0   \n",
       "1    2.782585e+04    0.171691   3.804760   1683.966820      29     35.0   \n",
       "2    4.816986e+02    0.024675   1.563966    244.599033      15      3.0   \n",
       "3    1.288353e+04    3.156452   3.415301   1166.427782      10      1.0   \n",
       "4    1.484992e+02    0.000393   0.995897    109.760378      26      9.0   \n",
       "..            ...         ...        ...           ...     ...      ...   \n",
       "500  1.297361e+05    1.234726   5.865676   3440.615516      26      8.0   \n",
       "501  5.349600e+05    3.651875  10.209300   9195.444576      31      6.0   \n",
       "502  3.691856e+07  872.908533  31.860500  83632.763411      21      8.0   \n",
       "503  1.151792e+06    2.262564  10.373444   5509.147684      31      7.0   \n",
       "504  6.980402e+01    0.169676   0.918949     84.446675       5      1.0   \n",
       "\n",
       "         KlScore  ChangeIdx  \n",
       "0     722.122511      139.0  \n",
       "1     762.034875      101.0  \n",
       "2     722.257988        3.0  \n",
       "3     185.725861       48.0  \n",
       "4     677.073513      264.0  \n",
       "..           ...        ...  \n",
       "500   803.206199       46.0  \n",
       "501  1820.287731      212.0  \n",
       "502  4652.544429       42.0  \n",
       "503  1597.619581      305.0  \n",
       "504   227.132294       12.0  \n",
       "\n",
       "[505 rows x 13 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(listaeliminados, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MATRIZ DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DTW\n",
    "f_dtw_dist = np.zeros((n,n))\n",
    "for i in range(0,n):\n",
    "    for j in range(0,n):\n",
    "        f_dtw_dist[i,j] = fast_DTW(df.iloc[i].values.flatten(), df.iloc[j].values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_dtw_distDF = pd.DataFrame(f_dtw_dist)\n",
    "f_dtw_distDF.to_csv(my_path_py+'\\\\3_FeatureSelection\\\\MatricesDistancia\\\\MatrizDTW_FBFS.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MATRIZ EUCLIDIANA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Euclidean\n",
    "f_euclidean_dist = np.zeros((n,n))\n",
    "for i in range(0,n):\n",
    "    #print(\"i\",i)\n",
    "    for j in range(1,n):\n",
    "         f_euclidean_dist[i,j] = euclidean(df.iloc[i].values.flatten(), df.iloc[j].values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_euclidean_distDF = pd.DataFrame(f_euclidean_dist)\n",
    "f_euclidean_distDF.to_csv(my_path_py+'\\\\3_FeatureSelection\\\\MatricesDistancia\\\\MatrizEuclidiana_FBFS.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MATRIZ CORRELACIÓN PEARSON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corr\n",
    "corr_dist = np.zeros((n,n))\n",
    "for i in range(0,n):\n",
    "    for j in range(0,n):\n",
    "            corr_dist[i,j] = corr(df.iloc[i].values.flatten(), df.iloc[j].values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_distDF = pd.DataFrame(corr_dist)\n",
    "corr_distDF.to_csv(my_path_py+'\\\\3_FeatureSelection\\\\MatricesDistancia\\\\MatrizPearson_FBFS.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MATRIZ CORRELACIÓN SPEARMAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scorr\n",
    "f_scorr_dist = np.zeros((n,n))\n",
    "for i in range(0,n):\n",
    "    for j in range(0,n):\n",
    "        f_scorr_dist[i,j] = scorr(df.iloc[i].values.flatten(), df.iloc[j].values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_scorr_distDF = pd.DataFrame(f_scorr_dist)\n",
    "f_scorr_distDF.to_csv(my_path_py+'\\\\3_FeatureSelection\\\\MatricesDistancia\\\\MatrizSpearman_FBFS.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAC + euclidian distance: \n",
      "SC:  0.8785265047829188\n",
      "CHZ:  6338.754832377213\n",
      "DUNN:  1.0823177407045927\n",
      "DAV-BOUD:  0.25587212362993556\n",
      "----------------------------------\n",
      "HAC + corr distance: \n",
      "SC:  0.5875777137491371\n",
      "CHZ:  1366.4267369809547\n",
      "DUNN:  0.851326622977221\n",
      "DAV-BOUD:  0.5980819998302872\n",
      "----------------------------------\n",
      "HAC + scorr distance: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\cluster\\hierarchy.py:826: ClusterWarning: scipy.cluster: The symmetric non-negative hollow observation matrix looks suspiciously like an uncondensed distance matrix\n",
      "  return linkage(y, method='ward', metric='euclidean')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SC:  0.39150265115246163\n",
      "CHZ:  349.0975169127851\n",
      "DUNN:  0.7387590196194002\n",
      "DAV-BOUD:  1.020594235349151\n",
      "----------------------------------\n",
      "HAC + dtw distance: \n",
      "SC:  0.8740112363147372\n",
      "CHZ:  6294.693930453884\n",
      "DUNN:  1.048660137898133\n",
      "DAV-BOUD:  0.2528272369528758\n"
     ]
    }
   ],
   "source": [
    "#Experimentos HAC\n",
    "HAC_EUCLIDEAN=[]\n",
    "HAC_CORRELATION=[]\n",
    "HAC_SPEARMAN=[]\n",
    "HAC_DTW=[]\n",
    "\n",
    "HAC_EUCLIDEAN_CHZ=[]\n",
    "HAC_CORRELATION_CHZ=[]\n",
    "HAC_SPEARMAN_CHZ=[]\n",
    "HAC_DTW_CHZ=[]\n",
    "\n",
    "HAC_EUCLIDEAN_DUNN=[]\n",
    "HAC_CORRELATION_DUNN=[]\n",
    "HAC_SPEARMAN_DUNN=[]\n",
    "HAC_DTW_DUNN=[]\n",
    "\n",
    "HAC_EUCLIDEAN_DAVID=[]\n",
    "HAC_CORRELATION_DAVID=[]\n",
    "HAC_SPEARMAN_DAVID=[]\n",
    "HAC_DTW_DAVID=[]\n",
    "\n",
    "HAC_euc = AgglomerativeClustering(n_clusters=k).fit_predict(f_euclidean_dist)\n",
    "print(\"HAC + euclidian distance: \")\n",
    "\n",
    "sil = silhouette_score(f_euclidean_dist, HAC_euc)\n",
    "chz = calinski_harabasz_score(f_euclidean_dist, HAC_euc)\n",
    "try:\n",
    "    dunn_= dunn(HAC_euc, f_euclidean_dist, 'farthest', 'farthest')\n",
    "except:\n",
    "    dunn_=np.nan\n",
    "david_= davies_bouldin_score(f_euclidean_dist, HAC_euc)\n",
    "\n",
    "print(\"SC: \", sil)\n",
    "print(\"CHZ: \", chz)\n",
    "print(\"DUNN: \", dunn_)\n",
    "print(\"DAV-BOUD: \", david_)\n",
    "\n",
    "HAC_EUCLIDEAN.append(sil)\n",
    "HAC_EUCLIDEAN_CHZ.append(chz)\n",
    "HAC_EUCLIDEAN_DUNN.append(dunn_)\n",
    "HAC_EUCLIDEAN_DAVID.append(david_)\n",
    "\n",
    "print(\"----------------------------------\")\n",
    "\n",
    "HAC_corr = AgglomerativeClustering(n_clusters=k).fit_predict(corr_dist)\n",
    "print(\"HAC + corr distance: \")\n",
    "sil = silhouette_score(corr_dist, HAC_corr)\n",
    "chz = calinski_harabasz_score(corr_dist, HAC_corr)\n",
    "try:\n",
    "    dunn_ = dunn(HAC_corr, corr_dist, 'farthest', 'farthest')\n",
    "except:\n",
    "    dunn_=np.nan\n",
    "david_= davies_bouldin_score(corr_dist, HAC_corr)\n",
    "\n",
    "print(\"SC: \", sil)\n",
    "print(\"CHZ: \", chz)\n",
    "print(\"DUNN: \", dunn_)\n",
    "print(\"DAV-BOUD: \", david_)\n",
    "\n",
    "HAC_CORRELATION.append(sil)\n",
    "HAC_CORRELATION_CHZ.append(chz)\n",
    "HAC_CORRELATION_DUNN.append(dunn_)\n",
    "HAC_CORRELATION_DAVID.append(david_)\n",
    "\n",
    "print(\"----------------------------------\")\n",
    "\n",
    "HAC_scorr = AgglomerativeClustering(n_clusters=k).fit_predict(f_scorr_dist)\n",
    "print(\"HAC + scorr distance: \")\n",
    "sil = silhouette_score(f_scorr_dist, HAC_scorr)\n",
    "chz = calinski_harabasz_score(f_scorr_dist, HAC_scorr)\n",
    "try:\n",
    "    dunn_ = dunn(HAC_scorr, f_scorr_dist, 'farthest', 'farthest')\n",
    "except:\n",
    "    dunn_=np.nan\n",
    "david_= davies_bouldin_score(f_scorr_dist, HAC_scorr)\n",
    "\n",
    "print(\"SC: \", sil)\n",
    "print(\"CHZ: \", chz)\n",
    "print(\"DUNN: \", dunn_)\n",
    "print(\"DAV-BOUD: \", david_)\n",
    "\n",
    "HAC_SPEARMAN.append(sil)\n",
    "HAC_SPEARMAN_CHZ.append(chz)\n",
    "HAC_SPEARMAN_DUNN.append(dunn_)\n",
    "HAC_SPEARMAN_DAVID.append(david_)\n",
    "\n",
    "print(\"----------------------------------\")\n",
    "\n",
    "HAC_dtw = AgglomerativeClustering(n_clusters=k).fit_predict(f_dtw_dist)\n",
    "print(\"HAC + dtw distance: \")\n",
    "sil = silhouette_score(f_dtw_dist, HAC_dtw)\n",
    "chz = calinski_harabasz_score(f_dtw_dist, HAC_dtw)\n",
    "try:\n",
    "    dunn_ = dunn(HAC_dtw, f_dtw_dist, 'farthest', 'farthest')\n",
    "except:\n",
    "    dunn_=np.nan\n",
    "david_= davies_bouldin_score(f_dtw_dist, HAC_dtw)\n",
    "\n",
    "print(\"SC: \", sil)\n",
    "print(\"CHZ: \", chz)\n",
    "print(\"DUNN: \", dunn_)\n",
    "print(\"DAV-BOUD: \", david_)\n",
    "\n",
    "HAC_DTW.append(sil)\n",
    "HAC_DTW_CHZ.append(chz)\n",
    "HAC_DTW_DUNN.append(dunn_)\n",
    "HAC_DTW_DAVID.append(david_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KM + euclidian distance: \n",
      "SC:  0.8578706100444677\n",
      "CHZ:  6607.269465368838\n",
      "DUNN:  0.8499382828851052\n",
      "DAV-BOULD:  0.30505960809159094\n",
      "------------------------------\n",
      "KM + corr distance: \n",
      "SC:  0.5806454194695692\n",
      "CHZ:  1531.255910796374\n",
      "DUNN:  0.8164281077263447\n",
      "DAV-BOULD:  0.6339729635599659\n",
      "------------------------------\n",
      "KM + scorr distance: \n",
      "SC:  0.4219568365266967\n",
      "CHZ:  380.7790756633296\n",
      "DUNN:  0.7387590196194002\n",
      "DAV-BOULD:  0.9666775219049598\n",
      "------------------------------\n",
      "KM + dtw distance: \n",
      "SC:  0.8541791803301831\n",
      "CHZ:  6368.578708931667\n",
      "DUNN:  0.8978544516678802\n",
      "DAV-BOULD:  0.2946527109310228\n"
     ]
    }
   ],
   "source": [
    "KM_EUCLIDEAN=[]\n",
    "KM_CORRELATION=[]\n",
    "KM_SPEARMAN=[]\n",
    "KM_DTW=[]\n",
    "\n",
    "KM_EUCLIDEAN_CHZ=[]\n",
    "KM_CORRELATION_CHZ=[]\n",
    "KM_SPEARMAN_CHZ=[]\n",
    "KM_DTW_CHZ=[]\n",
    "\n",
    "KM_EUCLIDEAN_DUNN=[]\n",
    "KM_CORRELATION_DUNN=[]\n",
    "KM_SPEARMAN_DUNN=[]\n",
    "KM_DTW_DUNN=[]\n",
    "\n",
    "KM_EUCLIDEAN_DAVID=[]\n",
    "KM_CORRELATION_DAVID=[]\n",
    "KM_SPEARMAN_DAVID=[]\n",
    "KM_DTW_DAVID=[]\n",
    "\n",
    "#Experimentos K-Means\n",
    "km_euc = KMeans(n_clusters=k).fit_predict(f_euclidean_dist)\n",
    "print(\"KM + euclidian distance: \")\n",
    "sil = silhouette_score(f_euclidean_dist, km_euc)\n",
    "chz = calinski_harabasz_score(f_euclidean_dist, km_euc)\n",
    "try:\n",
    "    dunn_ = dunn(km_euc, f_euclidean_dist, 'farthest', 'farthest')\n",
    "except:\n",
    "    dunn_=np.nan\n",
    "david_ = davies_bouldin_score(f_euclidean_dist, km_euc)\n",
    "\n",
    "print(\"SC: \", sil)\n",
    "print(\"CHZ: \", chz)\n",
    "print(\"DUNN: \", dunn_)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "\n",
    "KM_EUCLIDEAN.append(sil)\n",
    "KM_EUCLIDEAN_CHZ.append(chz)\n",
    "KM_EUCLIDEAN_DUNN.append(dunn_)\n",
    "KM_EUCLIDEAN_DAVID.append(david_)\n",
    "\n",
    "print(\"------------------------------\")\n",
    "\n",
    "km_corr = KMeans(n_clusters=k).fit_predict(corr_dist)\n",
    "print(\"KM + corr distance: \")\n",
    "sil = silhouette_score(corr_dist, km_corr)\n",
    "chz = calinski_harabasz_score(corr_dist, km_corr)\n",
    "try:\n",
    "    dunn_ = dunn(km_corr, corr_dist, 'farthest', 'farthest') \n",
    "except:\n",
    "    dunn_=np.nan\n",
    "david_ = davies_bouldin_score(corr_dist, km_corr)\n",
    "\n",
    "print(\"SC: \", sil)\n",
    "print(\"CHZ: \", chz)\n",
    "print(\"DUNN: \", dunn_)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "\n",
    "KM_CORRELATION.append(sil)\n",
    "KM_CORRELATION_CHZ.append(chz)\n",
    "KM_CORRELATION_DUNN.append(dunn_)\n",
    "KM_CORRELATION_DAVID.append(david_)\n",
    "\n",
    "print(\"------------------------------\")\n",
    "\n",
    "km_scorr = KMeans(n_clusters=k).fit_predict(f_scorr_dist)\n",
    "print(\"KM + scorr distance: \")\n",
    "sil = silhouette_score(f_scorr_dist, km_scorr)\n",
    "chz = calinski_harabasz_score(f_scorr_dist, km_scorr)\n",
    "try:\n",
    "    dunn_ = dunn(km_scorr, f_scorr_dist, 'farthest', 'farthest')\n",
    "except:\n",
    "    dunn_=np.nan\n",
    "david_ = davies_bouldin_score(f_scorr_dist, km_scorr)\n",
    "\n",
    "print(\"SC: \", sil)\n",
    "print(\"CHZ: \", chz)\n",
    "print(\"DUNN: \", dunn_)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "\n",
    "KM_SPEARMAN.append(sil)\n",
    "KM_SPEARMAN_CHZ.append(chz)\n",
    "KM_SPEARMAN_DUNN.append(dunn_)\n",
    "KM_SPEARMAN_DAVID.append(david_)\n",
    "\n",
    "print(\"------------------------------\")\n",
    "\n",
    "km_dtw = KMeans(n_clusters=k).fit_predict(f_dtw_dist)\n",
    "print(\"KM + dtw distance: \")\n",
    "sil = silhouette_score(f_dtw_dist, km_dtw)\n",
    "chz = calinski_harabasz_score(f_dtw_dist, km_dtw)\n",
    "try:\n",
    "    dunn_ = dunn(km_dtw, f_dtw_dist, 'farthest', 'farthest')\n",
    "except:\n",
    "    dunn_=np.nan\n",
    "david_ = davies_bouldin_score(f_dtw_dist, km_dtw)\n",
    "\n",
    "print(\"SC: \", sil)\n",
    "print(\"CHZ: \", chz)\n",
    "print(\"DUNN: \", dunn_)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "\n",
    "KM_DTW.append(sil)\n",
    "KM_DTW_CHZ.append(chz)\n",
    "KM_DTW_DUNN.append(dunn_)\n",
    "KM_DTW_DAVID.append(david_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN + euclidian distance: \n",
      "SC:  -0.5569416925728353\n",
      "CHZ:  0.41189990940884863\n",
      "DUNN:  2.0032627641599044e-05\n",
      "DAV-BOULD:  1.6384171477273881\n",
      "------------------------------\n",
      "DBSCAN + corr distance: \n",
      "SC:  0.17114048500760087\n",
      "CHZ:  105.01375796229746\n",
      "DUNN:  0.7411983835976086\n",
      "DAV-BOULD:  1.0923175997157908\n",
      "------------------------------\n",
      "DBSCAN + scorr distance: \n",
      "SC:  -0.09514507091259121\n",
      "CHZ:  5.473580581686799\n",
      "DUNN:  0.5694398864740464\n",
      "DAV-BOULD:  1.165594854474498\n",
      "------------------------------\n",
      "DBSCAN + dtw distance: \n",
      "SC:  -0.6344809884942453\n",
      "CHZ:  0.2050395000274255\n",
      "DUNN:  8.641024087754016e-06\n",
      "DAV-BOULD:  1.654019614814473\n"
     ]
    }
   ],
   "source": [
    "DBSCAN_EUCLIDEAN=[]\n",
    "DBSCAN_CORRELATION=[]\n",
    "DBSCAN_SPEARMAN=[]\n",
    "DBSCAN_DTW=[]\n",
    "\n",
    "DBSCAN_EUCLIDEAN_CHZ=[]\n",
    "DBSCAN_CORRELATION_CHZ=[]\n",
    "DBSCAN_SPEARMAN_CHZ=[]\n",
    "DBSCAN_DTW_CHZ=[]\n",
    "\n",
    "DBSCAN_EUCLIDEAN_DUNN=[]\n",
    "DBSCAN_CORRELATION_DUNN=[]\n",
    "DBSCAN_SPEARMAN_DUNN=[]\n",
    "DBSCAN_DTW_DUNN=[]\n",
    "\n",
    "DBSCAN_EUCLIDEAN_DAVID=[]\n",
    "DBSCAN_CORRELATION_DAVID=[]\n",
    "DBSCAN_SPEARMAN_DAVID=[]\n",
    "DBSCAN_DTW_DAVID=[]\n",
    "\n",
    "#CON EUCLIDEAN\n",
    "DB_euc = DBSCAN(eps=170, min_samples=3).fit_predict(f_euclidean_dist)\n",
    "print(\"DBSCAN + euclidian distance: \")\n",
    "\n",
    "sil =  silhouette_score(f_euclidean_dist, DB_euc)\n",
    "CHZ_ = calinski_harabasz_score(f_euclidean_dist, DB_euc) \n",
    "try:\n",
    "    dunn_ = dunn(DB_euc, f_euclidean_dist, 'farthest', 'farthest')\n",
    "except:\n",
    "    dunn_ = np.nan\n",
    "david_ = davies_bouldin_score(f_euclidean_dist, DB_euc)\n",
    "\n",
    "print(\"SC: \", sil)\n",
    "print(\"CHZ: \", CHZ_)\n",
    "print(\"DUNN: \", dunn_)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "\n",
    "DBSCAN_EUCLIDEAN.append(sil)\n",
    "DBSCAN_EUCLIDEAN_CHZ.append(CHZ_)\n",
    "DBSCAN_EUCLIDEAN_DUNN.append(dunn_)\n",
    "DBSCAN_EUCLIDEAN_DAVID.append(david_)\n",
    "\n",
    "print(\"------------------------------\")\n",
    "\n",
    "\n",
    "#CON CORRELATION\n",
    "DB_corr = DBSCAN(eps=0.45, min_samples=3).fit_predict(corr_dist)\n",
    "print(\"DBSCAN + corr distance: \")\n",
    "\n",
    "sil = silhouette_score(corr_dist, DB_corr)\n",
    "CHZ_ = calinski_harabasz_score(corr_dist, DB_corr)\n",
    "try:\n",
    "    dunn_ = dunn(DB_corr, corr_dist, 'farthest', 'farthest')\n",
    "except:\n",
    "    dunn_ = np.nan\n",
    "david_ = davies_bouldin_score(corr_dist, DB_corr)\n",
    "\n",
    "print(\"SC: \", sil)\n",
    "print(\"CHZ: \", CHZ_)\n",
    "print(\"DUNN: \", dunn_)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "\n",
    "DBSCAN_CORRELATION.append(sil)\n",
    "DBSCAN_CORRELATION_CHZ.append(CHZ_)\n",
    "DBSCAN_CORRELATION_DUNN.append(dunn_)\n",
    "DBSCAN_CORRELATION_DAVID.append(david_)\n",
    "\n",
    "print(\"------------------------------\")\n",
    "\n",
    "#CON SPEARMAN\n",
    "DB_scorr = DBSCAN(eps=0.45, min_samples=3).fit_predict(f_scorr_dist)\n",
    "print(\"DBSCAN + scorr distance: \")\n",
    "\n",
    "sil = silhouette_score(f_scorr_dist, DB_scorr)\n",
    "CHZ_ = calinski_harabasz_score(f_scorr_dist, DB_scorr)\n",
    "try:\n",
    "    dunn_ = dunn(DB_scorr, f_scorr_dist, 'farthest', 'farthest')\n",
    "except:\n",
    "    dunn_ = np.nan\n",
    "david_ = davies_bouldin_score(f_scorr_dist, DB_scorr)\n",
    "\n",
    "print(\"SC: \", sil)\n",
    "print(\"CHZ: \", CHZ_)\n",
    "print(\"DUNN: \", dunn_)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "DBSCAN_SPEARMAN.append(sil)\n",
    "DBSCAN_SPEARMAN_CHZ.append(CHZ_)\n",
    "DBSCAN_SPEARMAN_DUNN.append(dunn_)\n",
    "DBSCAN_SPEARMAN_DAVID.append(david_)\n",
    "\n",
    "print(\"------------------------------\")\n",
    "\n",
    "#CON D TIME WARPING\n",
    "DB_dtw = DBSCAN(eps=170, min_samples=3).fit_predict(f_dtw_dist)\n",
    "print(\"DBSCAN + dtw distance: \")\n",
    "\n",
    "sil = silhouette_score(f_dtw_dist, DB_dtw)\n",
    "CHZ_ = calinski_harabasz_score(f_dtw_dist, DB_dtw)\n",
    "try:\n",
    "    dunn_ = dunn(DB_dtw, f_dtw_dist, 'farthest', 'farthest')\n",
    "except:\n",
    "    dunn_ = np.nan\n",
    "david_ = davies_bouldin_score(f_dtw_dist, DB_dtw)\n",
    "\n",
    "print(\"SC: \", sil)\n",
    "print(\"CHZ: \", CHZ_)\n",
    "print(\"DUNN: \", dunn_)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "DBSCAN_DTW.append(sil)\n",
    "DBSCAN_DTW_CHZ.append(CHZ_)\n",
    "DBSCAN_DTW_DUNN.append(dunn_)\n",
    "DBSCAN_DTW_DAVID.append(david_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux2 = pd.DataFrame()\n",
    "aux2['Distrito'] = listadistrito\n",
    "aux2['Cluster KM'] = km_euc\n",
    "aux2['Cluster HAC '] = HAC_euc\n",
    "aux2['Cluster DB SP'] = DB_scorr\n",
    "aux2.to_csv('ClusterFBFS_2015al2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scores_ = pd.DataFrame()\n",
    "Scores_['Metrica'] = ['Euclidean', 'Pearson', 'Spearman', 'DTW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scores_['SIL HAC 8'] = [ HAC_EUCLIDEAN[0], HAC_CORRELATION[0], HAC_SPEARMAN[0], HAC_DTW[0]]\n",
    "Scores_['SIL KM 8'] = [ KM_EUCLIDEAN[0], KM_CORRELATION[0], KM_SPEARMAN[0], KM_DTW[0]]\n",
    "Scores_['SIL DB 8'] = [ DBSCAN_EUCLIDEAN[0], DBSCAN_CORRELATION[0], DBSCAN_SPEARMAN[0], DBSCAN_DTW[0]]\n",
    "\n",
    "Scores_['CHZ HAC 8'] = [ HAC_EUCLIDEAN_CHZ[0], HAC_CORRELATION_CHZ[0], HAC_SPEARMAN_CHZ[0], HAC_DTW_CHZ[0]]\n",
    "Scores_['CHZ KM 8'] = [ KM_EUCLIDEAN_CHZ[0], KM_CORRELATION_CHZ[0], KM_SPEARMAN_CHZ[0], KM_DTW_CHZ[0]]\n",
    "Scores_['CHZ DB 8'] = [ DBSCAN_EUCLIDEAN_CHZ[0], DBSCAN_CORRELATION_CHZ[0], DBSCAN_SPEARMAN_CHZ[0], DBSCAN_DTW_CHZ[0]]\n",
    "\n",
    "Scores_['DAVIES HAC 8'] = [ HAC_EUCLIDEAN_DAVID[0], HAC_CORRELATION_DAVID[0], HAC_SPEARMAN_DAVID[0], HAC_DTW_DAVID[0]]\n",
    "Scores_['DAVIES KM 8'] = [ KM_EUCLIDEAN_DAVID[0], KM_CORRELATION_DAVID[0], KM_SPEARMAN_DAVID[0], KM_DTW_DAVID[0]]\n",
    "Scores_['DAVIES DB 8'] = [ DBSCAN_EUCLIDEAN_DAVID[0], DBSCAN_CORRELATION_DAVID[0], DBSCAN_SPEARMAN_DAVID[0], DBSCAN_DTW_DAVID[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scores_.to_csv(my_path_py+'\\\\3_FeatureSelection\\\\Resultados_Scores\\\\Scores8F_Based.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metrica</th>\n",
       "      <th>SIL HAC 8</th>\n",
       "      <th>SIL KM 8</th>\n",
       "      <th>SIL DB 8</th>\n",
       "      <th>CHZ HAC 8</th>\n",
       "      <th>CHZ KM 8</th>\n",
       "      <th>CHZ DB 8</th>\n",
       "      <th>DAVIES HAC 8</th>\n",
       "      <th>DAVIES KM 8</th>\n",
       "      <th>DAVIES DB 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Euclidean</td>\n",
       "      <td>0.878527</td>\n",
       "      <td>0.857871</td>\n",
       "      <td>-0.556942</td>\n",
       "      <td>6338.754832</td>\n",
       "      <td>6607.269465</td>\n",
       "      <td>0.411900</td>\n",
       "      <td>0.255872</td>\n",
       "      <td>0.305060</td>\n",
       "      <td>1.638417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pearson</td>\n",
       "      <td>0.587578</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.171140</td>\n",
       "      <td>1366.426737</td>\n",
       "      <td>1531.255911</td>\n",
       "      <td>105.013758</td>\n",
       "      <td>0.598082</td>\n",
       "      <td>0.633973</td>\n",
       "      <td>1.092318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spearman</td>\n",
       "      <td>0.391503</td>\n",
       "      <td>0.421957</td>\n",
       "      <td>-0.095145</td>\n",
       "      <td>349.097517</td>\n",
       "      <td>380.779076</td>\n",
       "      <td>5.473581</td>\n",
       "      <td>1.020594</td>\n",
       "      <td>0.966678</td>\n",
       "      <td>1.165595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTW</td>\n",
       "      <td>0.874011</td>\n",
       "      <td>0.854179</td>\n",
       "      <td>-0.634481</td>\n",
       "      <td>6294.693930</td>\n",
       "      <td>6368.578709</td>\n",
       "      <td>0.205040</td>\n",
       "      <td>0.252827</td>\n",
       "      <td>0.294653</td>\n",
       "      <td>1.654020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Metrica  SIL HAC 8  SIL KM 8  SIL DB 8    CHZ HAC 8     CHZ KM 8  \\\n",
       "0  Euclidean   0.878527  0.857871 -0.556942  6338.754832  6607.269465   \n",
       "1    Pearson   0.587578  0.580645  0.171140  1366.426737  1531.255911   \n",
       "2   Spearman   0.391503  0.421957 -0.095145   349.097517   380.779076   \n",
       "3        DTW   0.874011  0.854179 -0.634481  6294.693930  6368.578709   \n",
       "\n",
       "     CHZ DB 8  DAVIES HAC 8  DAVIES KM 8  DAVIES DB 8  \n",
       "0    0.411900      0.255872     0.305060     1.638417  \n",
       "1  105.013758      0.598082     0.633973     1.092318  \n",
       "2    5.473581      1.020594     0.966678     1.165595  \n",
       "3    0.205040      0.252827     0.294653     1.654020  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
