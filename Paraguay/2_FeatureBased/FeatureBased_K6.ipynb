{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Based con K=6\n",
    "\n",
    "#### Se debe ejecutar primero FeatureBased con K=5\n",
    "\n",
    "##### -------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs files: \n",
    "\n",
    "#### filesnotificaciones_clima_7_dias_COMBINADO_SEMANAL.csv\n",
    "#### Poblacion_Paraguay.csv\n",
    "\n",
    "##### -------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output files: \n",
    "\n",
    "#### Scores1_FeatureBasedK6.csv\n",
    "#### ClusterFB1_2009al2013K6.csv\n",
    "\n",
    "##### -------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import davies_bouldin_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tsfeature as tsf\n",
    "import entropy as ent\n",
    "\n",
    "my_path = os.path.abspath('')\n",
    "my_path = my_path.split('\\\\')\n",
    "my_path_py = \"\\\\\".join(my_path[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(my_path_py+'\\\\DatosRaw\\\\notificaciones_clima_7_dias_COMBINADO_SEMANAL.csv', sep=';')\n",
    "poblacion= pd.read_csv(my_path_py+'\\\\DatosRaw\\\\Poblacion_Paraguay.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "poblacion['#'] = poblacion['#'].str.upper()\n",
    "poblacion = poblacion.head(268)\n",
    "poblacion.rename(columns = {'#':'Ciudad'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de ciudades con casos es: 238\n",
      "La cantidad de ciudades con datos de población: 266\n"
     ]
    }
   ],
   "source": [
    "print(\"La cantidad de ciudades con casos es:\", df['distrito_notif'].nunique())\n",
    "print(\"La cantidad de ciudades con datos de población:\", poblacion['Ciudad'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anio</th>\n",
       "      <th>semana</th>\n",
       "      <th>distrito_notif</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmed</th>\n",
       "      <th>td</th>\n",
       "      <th>pres_est</th>\n",
       "      <th>pres_nm</th>\n",
       "      <th>prcp</th>\n",
       "      <th>hr</th>\n",
       "      <th>helio</th>\n",
       "      <th>nub</th>\n",
       "      <th>vmax_d</th>\n",
       "      <th>vmax_f</th>\n",
       "      <th>vmed</th>\n",
       "      <th>id_estacion</th>\n",
       "      <th>casos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>ASUNCION</td>\n",
       "      <td>29.7</td>\n",
       "      <td>20.5</td>\n",
       "      <td>23.9</td>\n",
       "      <td>16.85</td>\n",
       "      <td>1001.05</td>\n",
       "      <td>1010.55</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>6.6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>??</td>\n",
       "      <td>??</td>\n",
       "      <td>??</td>\n",
       "      <td>86218</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>FERNANDO DE LA MORA</td>\n",
       "      <td>38</td>\n",
       "      <td>24.6</td>\n",
       "      <td>29.2</td>\n",
       "      <td>22.1</td>\n",
       "      <td>998.3</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>11.1</td>\n",
       "      <td>5</td>\n",
       "      <td>??</td>\n",
       "      <td>??</td>\n",
       "      <td>??</td>\n",
       "      <td>86218</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>PEDRO JUAN CABALLERO</td>\n",
       "      <td>27.7</td>\n",
       "      <td>21.3</td>\n",
       "      <td>23.1</td>\n",
       "      <td>20.9</td>\n",
       "      <td>947</td>\n",
       "      <td>1008.3</td>\n",
       "      <td>32.6</td>\n",
       "      <td>88.5</td>\n",
       "      <td>1.85</td>\n",
       "      <td>6.5</td>\n",
       "      <td>??</td>\n",
       "      <td>??</td>\n",
       "      <td>??</td>\n",
       "      <td>86097</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>YBY YAU</td>\n",
       "      <td>27.4</td>\n",
       "      <td>20.65</td>\n",
       "      <td>22.65</td>\n",
       "      <td>20.475</td>\n",
       "      <td>947.1</td>\n",
       "      <td>1008.5</td>\n",
       "      <td>16.775</td>\n",
       "      <td>88.5</td>\n",
       "      <td>2.875</td>\n",
       "      <td>6.5</td>\n",
       "      <td>??</td>\n",
       "      <td>??</td>\n",
       "      <td>??</td>\n",
       "      <td>86097</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>YPANE</td>\n",
       "      <td>29</td>\n",
       "      <td>20.2</td>\n",
       "      <td>23.3</td>\n",
       "      <td>16</td>\n",
       "      <td>1001.6</td>\n",
       "      <td>1011.2</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6</td>\n",
       "      <td>??</td>\n",
       "      <td>??</td>\n",
       "      <td>??</td>\n",
       "      <td>86218</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8482</th>\n",
       "      <td>2013</td>\n",
       "      <td>52</td>\n",
       "      <td>VILLA HAYES</td>\n",
       "      <td>35.46666667</td>\n",
       "      <td>24.48333333</td>\n",
       "      <td>29.86666667</td>\n",
       "      <td>21.86666667</td>\n",
       "      <td>998.2666667</td>\n",
       "      <td>1007.683333</td>\n",
       "      <td>2.133333333</td>\n",
       "      <td>65.16666667</td>\n",
       "      <td>10.61666667</td>\n",
       "      <td>4</td>\n",
       "      <td>14.66666667</td>\n",
       "      <td>2.126666667</td>\n",
       "      <td>1.308333333</td>\n",
       "      <td>86218</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8483</th>\n",
       "      <td>2013</td>\n",
       "      <td>52</td>\n",
       "      <td>VILLETA</td>\n",
       "      <td>34.53333333</td>\n",
       "      <td>23.6</td>\n",
       "      <td>28.7</td>\n",
       "      <td>21.73333333</td>\n",
       "      <td>996.6666667</td>\n",
       "      <td>1006.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>67.66666667</td>\n",
       "      <td>7.866666667</td>\n",
       "      <td>3.333333333</td>\n",
       "      <td>14.33333333</td>\n",
       "      <td>1.573333333</td>\n",
       "      <td>0.786666667</td>\n",
       "      <td>86218</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8484</th>\n",
       "      <td>2013</td>\n",
       "      <td>52</td>\n",
       "      <td>YAGUARON</td>\n",
       "      <td>35</td>\n",
       "      <td>22.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>23.4</td>\n",
       "      <td>995.3</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86221</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8485</th>\n",
       "      <td>2013</td>\n",
       "      <td>52</td>\n",
       "      <td>YPACARAI</td>\n",
       "      <td>36</td>\n",
       "      <td>24</td>\n",
       "      <td>29.2</td>\n",
       "      <td>21.4</td>\n",
       "      <td>994.7</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>10.7</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.28</td>\n",
       "      <td>86221</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8486</th>\n",
       "      <td>2013</td>\n",
       "      <td>52</td>\n",
       "      <td>YPANE</td>\n",
       "      <td>35.5</td>\n",
       "      <td>25</td>\n",
       "      <td>29.75</td>\n",
       "      <td>22.05</td>\n",
       "      <td>994.6</td>\n",
       "      <td>1003.9</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>9.25</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>4.025</td>\n",
       "      <td>2.71</td>\n",
       "      <td>86218</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8487 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      anio  semana        distrito_notif         tmax         tmin  \\\n",
       "0     2009       2              ASUNCION         29.7         20.5   \n",
       "1     2009       2   FERNANDO DE LA MORA           38         24.6   \n",
       "2     2009       2  PEDRO JUAN CABALLERO         27.7         21.3   \n",
       "3     2009       2               YBY YAU         27.4        20.65   \n",
       "4     2009       2                 YPANE           29         20.2   \n",
       "...    ...     ...                   ...          ...          ...   \n",
       "8482  2013      52           VILLA HAYES  35.46666667  24.48333333   \n",
       "8483  2013      52               VILLETA  34.53333333         23.6   \n",
       "8484  2013      52              YAGUARON           35         22.8   \n",
       "8485  2013      52              YPACARAI           36           24   \n",
       "8486  2013      52                 YPANE         35.5           25   \n",
       "\n",
       "             tmed           td     pres_est      pres_nm         prcp  \\\n",
       "0            23.9        16.85      1001.05      1010.55            2   \n",
       "1            29.2         22.1        998.3       1007.6            0   \n",
       "2            23.1         20.9          947       1008.3         32.6   \n",
       "3           22.65       20.475        947.1       1008.5       16.775   \n",
       "4            23.3           16       1001.6       1011.2            0   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "8482  29.86666667  21.86666667  998.2666667  1007.683333  2.133333333   \n",
       "8483         28.7  21.73333333  996.6666667       1006.1          0.1   \n",
       "8484         29.7         23.4        995.3       1008.4            0   \n",
       "8485         29.2         21.4        994.7       1007.9            0   \n",
       "8486        29.75        22.05        994.6       1003.9            0   \n",
       "\n",
       "               hr        helio          nub       vmax_d       vmax_f  \\\n",
       "0              68          6.6          4.5           ??           ??   \n",
       "1              68         11.1            5           ??           ??   \n",
       "2            88.5         1.85          6.5           ??           ??   \n",
       "3            88.5        2.875          6.5           ??           ??   \n",
       "4              66          7.5            6           ??           ??   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "8482  65.16666667  10.61666667            4  14.66666667  2.126666667   \n",
       "8483  67.66666667  7.866666667  3.333333333  14.33333333  1.573333333   \n",
       "8484           70           10            1            0            0   \n",
       "8485           65         10.7            1           18         1.11   \n",
       "8486           65         9.25            4           23        4.025   \n",
       "\n",
       "             vmed  id_estacion  casos  \n",
       "0              ??        86218      2  \n",
       "1              ??        86218      1  \n",
       "2              ??        86097      2  \n",
       "3              ??        86097      4  \n",
       "4              ??        86218      1  \n",
       "...           ...          ...    ...  \n",
       "8482  1.308333333        86218      6  \n",
       "8483  0.786666667        86218      3  \n",
       "8484            0        86221      1  \n",
       "8485         0.28        86221      2  \n",
       "8486         2.71        86218      2  \n",
       "\n",
       "[8487 rows x 18 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S1 = set(list(dict.fromkeys(df['distrito_notif'].tolist())))\n",
    "S2 = set(list(dict.fromkeys(poblacion['Ciudad'].tolist())))\n",
    "ciudades = S1.intersection(S2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['anio','distrito_notif', 'semana', 'casos']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'anio':'Año', 'distrito_notif':'Distrito'}, inplace = True)\n",
    "df = df[df['Distrito'].isin(ciudades)]\n",
    "listaDistrito = df['Distrito'].tolist()\n",
    "listaDistrito = list(dict.fromkeys(listaDistrito))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distrito</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Var</th>\n",
       "      <th>ACF1</th>\n",
       "      <th>Trend</th>\n",
       "      <th>Linearity</th>\n",
       "      <th>Curvature</th>\n",
       "      <th>Season</th>\n",
       "      <th>Peak</th>\n",
       "      <th>Trough</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Lumpiness</th>\n",
       "      <th>Spikiness</th>\n",
       "      <th>Lshift</th>\n",
       "      <th>Vchange</th>\n",
       "      <th>Fspots</th>\n",
       "      <th>Cpoints</th>\n",
       "      <th>KlScore</th>\n",
       "      <th>ChangeIdx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUNCION</td>\n",
       "      <td>6.904494</td>\n",
       "      <td>5.239362e+01</td>\n",
       "      <td>8.135193e-01</td>\n",
       "      <td>0.922999</td>\n",
       "      <td>0.003082</td>\n",
       "      <td>-0.863262</td>\n",
       "      <td>0.025780</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-0.010495</td>\n",
       "      <td>5.978370e-01</td>\n",
       "      <td>1.772715e-04</td>\n",
       "      <td>2.497263e-09</td>\n",
       "      <td>1.086957e-02</td>\n",
       "      <td>5.250998e-05</td>\n",
       "      <td>172.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FERNANDO DE LA MORA</td>\n",
       "      <td>44.781615</td>\n",
       "      <td>4.841265e+03</td>\n",
       "      <td>9.371226e-01</td>\n",
       "      <td>0.958335</td>\n",
       "      <td>0.007501</td>\n",
       "      <td>0.391511</td>\n",
       "      <td>0.046909</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>-0.010903</td>\n",
       "      <td>1.698908e-01</td>\n",
       "      <td>7.906015e-05</td>\n",
       "      <td>5.201407e-10</td>\n",
       "      <td>1.813156e-01</td>\n",
       "      <td>1.006363e-02</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PEDRO JUAN CABALLERO</td>\n",
       "      <td>44.819130</td>\n",
       "      <td>1.042302e+04</td>\n",
       "      <td>9.285754e-01</td>\n",
       "      <td>0.962853</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>-0.361289</td>\n",
       "      <td>0.010942</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>-0.004989</td>\n",
       "      <td>1.317796e-01</td>\n",
       "      <td>3.606045e-04</td>\n",
       "      <td>5.397936e-10</td>\n",
       "      <td>6.596210e-02</td>\n",
       "      <td>3.044544e-03</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YBY YAU</td>\n",
       "      <td>18.306891</td>\n",
       "      <td>8.273701e+02</td>\n",
       "      <td>7.051710e-01</td>\n",
       "      <td>0.879186</td>\n",
       "      <td>0.003470</td>\n",
       "      <td>-0.677443</td>\n",
       "      <td>0.049205</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-0.018949</td>\n",
       "      <td>5.381565e-01</td>\n",
       "      <td>3.756719e-04</td>\n",
       "      <td>3.576345e-09</td>\n",
       "      <td>5.000000e-02</td>\n",
       "      <td>2.083333e-03</td>\n",
       "      <td>120.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YPANE</td>\n",
       "      <td>59.676847</td>\n",
       "      <td>1.191727e+04</td>\n",
       "      <td>9.103049e-01</td>\n",
       "      <td>0.940326</td>\n",
       "      <td>0.005569</td>\n",
       "      <td>-0.154082</td>\n",
       "      <td>0.019642</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>-0.005024</td>\n",
       "      <td>1.524750e-01</td>\n",
       "      <td>8.255672e-05</td>\n",
       "      <td>1.405710e-09</td>\n",
       "      <td>1.234592e-01</td>\n",
       "      <td>7.082626e-03</td>\n",
       "      <td>84.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>ISLA UMBU</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.984279</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>-0.016121</td>\n",
       "      <td>0.015653</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>3.203435e-11</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>VILLA OLIVA</td>\n",
       "      <td>27.129680</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.984279</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>-0.016121</td>\n",
       "      <td>0.015653</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>3.203435e-11</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>CARMELO PERALTA</td>\n",
       "      <td>23.540490</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.899220</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>-0.144232</td>\n",
       "      <td>0.020585</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>-0.007148</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>2.266590e-03</td>\n",
       "      <td>5.186532e-09</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>191.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>DESMOCHADOS</td>\n",
       "      <td>56.497175</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.984279</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>-0.016121</td>\n",
       "      <td>0.015653</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>3.203435e-11</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>R I 3 CORRALES</td>\n",
       "      <td>10.999890</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.984279</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>-0.016121</td>\n",
       "      <td>0.015653</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>3.203435e-11</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Distrito       Mean           Var          ACF1     Trend  \\\n",
       "0                ASUNCION   6.904494  5.239362e+01  8.135193e-01  0.922999   \n",
       "1     FERNANDO DE LA MORA  44.781615  4.841265e+03  9.371226e-01  0.958335   \n",
       "2    PEDRO JUAN CABALLERO  44.819130  1.042302e+04  9.285754e-01  0.962853   \n",
       "3                 YBY YAU  18.306891  8.273701e+02  7.051710e-01  0.879186   \n",
       "4                   YPANE  59.676847  1.191727e+04  9.103049e-01  0.940326   \n",
       "..                    ...        ...           ...           ...       ...   \n",
       "195             ISLA UMBU  33.333333  1.000000e-07  1.000000e-08  0.984279   \n",
       "196           VILLA OLIVA  27.129680  1.000000e-07  1.000000e-08  0.984279   \n",
       "197       CARMELO PERALTA  23.540490  1.000000e-07  1.000000e-08  0.899220   \n",
       "198           DESMOCHADOS  56.497175  1.000000e-07  1.000000e-08  0.984279   \n",
       "199        R I 3 CORRALES  10.999890  1.000000e-07  1.000000e-08  0.984279   \n",
       "\n",
       "     Linearity  Curvature    Season          Peak    Trough       Entropy  \\\n",
       "0     0.003082  -0.863262  0.025780  1.000000e+00 -0.010495  5.978370e-01   \n",
       "1     0.007501   0.391511  0.046909  1.000000e-07 -0.010903  1.698908e-01   \n",
       "2     0.004186  -0.361289  0.010942  1.000000e-07 -0.004989  1.317796e-01   \n",
       "3     0.003470  -0.677443  0.049205  1.000000e+00 -0.018949  5.381565e-01   \n",
       "4     0.005569  -0.154082  0.019642  1.000000e-07 -0.005024  1.524750e-01   \n",
       "..         ...        ...       ...           ...       ...           ...   \n",
       "195   0.000052  -0.016121  0.015653  1.000000e-07 -0.001953  1.000000e-08   \n",
       "196   0.000052  -0.016121  0.015653  1.000000e-07 -0.001953  1.000000e-08   \n",
       "197   0.000466  -0.144232  0.020585  1.000000e-07 -0.007148  1.000000e-08   \n",
       "198   0.000052  -0.016121  0.015653  1.000000e-07 -0.001953  1.000000e-08   \n",
       "199   0.000052  -0.016121  0.015653  1.000000e-07 -0.001953  1.000000e-08   \n",
       "\n",
       "        Lumpiness     Spikiness        Lshift       Vchange  Fspots  Cpoints  \\\n",
       "0    1.772715e-04  2.497263e-09  1.086957e-02  5.250998e-05   172.0      6.0   \n",
       "1    7.906015e-05  5.201407e-10  1.813156e-01  1.006363e-02    49.0     10.0   \n",
       "2    3.606045e-04  5.397936e-10  6.596210e-02  3.044544e-03    58.0      2.0   \n",
       "3    3.756719e-04  3.576345e-09  5.000000e-02  2.083333e-03   120.0      3.0   \n",
       "4    8.255672e-05  1.405710e-09  1.234592e-01  7.082626e-03    84.0      4.0   \n",
       "..            ...           ...           ...           ...     ...      ...   \n",
       "195  1.000000e-07  3.203435e-11  1.000000e-07  1.000000e-07   193.0      0.0   \n",
       "196  1.000000e-07  3.203435e-11  1.000000e-07  1.000000e-07   193.0      0.0   \n",
       "197  2.266590e-03  5.186532e-09  1.000000e-07  1.000000e-07   191.0      1.0   \n",
       "198  1.000000e-07  3.203435e-11  1.000000e-07  1.000000e-07   193.0      0.0   \n",
       "199  1.000000e-07  3.203435e-11  1.000000e-07  1.000000e-07   193.0      0.0   \n",
       "\n",
       "          KlScore     ChangeIdx  \n",
       "0    1.000000e-10  1.000000e-10  \n",
       "1    1.000000e-10  1.000000e-10  \n",
       "2    1.000000e-10  1.000000e-10  \n",
       "3    1.000000e-10  1.000000e-10  \n",
       "4    1.000000e-10  1.000000e-10  \n",
       "..            ...           ...  \n",
       "195  1.000000e-10  1.000000e-10  \n",
       "196  1.000000e-10  1.000000e-10  \n",
       "197  1.000000e-10  1.000000e-10  \n",
       "198  1.000000e-10  1.000000e-10  \n",
       "199  1.000000e-10  1.000000e-10  \n",
       "\n",
       "[200 rows x 19 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features= pd.read_csv('FB2_2009al2013.csv', sep=',')\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n= features.shape[0]\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones de Distancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import sqrt, log, floor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statistics import mean\n",
    "from fastdtw import fastdtw\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "#Euclidean\n",
    "def euclidean(x, y):\n",
    "    r=np.linalg.norm(x-y)\n",
    "    if math.isnan(r):\n",
    "        r=1\n",
    "    #print(r)\n",
    "    return r\n",
    "\n",
    "#Fast Dynamic time warping\n",
    "def fast_DTW(x, y):\n",
    "    r, _ = fastdtw(x, y, dist=euclidean)\n",
    "    if math.isnan(r):\n",
    "        r=1\n",
    "    #print(r)\n",
    "    return r\n",
    "\n",
    "#Spearman\n",
    "def scorr(x, y):\n",
    "    r = stats.spearmanr(x, y)[0]\n",
    "    if math.isnan(r):\n",
    "        r=0\n",
    "    #print(r)\n",
    "    return 1 - r\n",
    "\n",
    "#RMSE\n",
    "def rmse(x, y):\n",
    "    r=sqrt(mean_squared_error(x,y))\n",
    "    if math.isnan(r):\n",
    "        r=1\n",
    "    #print(r)\n",
    "    return r\n",
    "\n",
    "def lcs(a, b):  \n",
    "    lengths = [[0 for j in range(len(b)+1)] for i in range(len(a)+1)]\n",
    "    # row 0 and column 0 are initialized to 0 already\n",
    "    for i, x in enumerate(a):\n",
    "        for j, y in enumerate(b):\n",
    "            if x == y:\n",
    "                lengths[i+1][j+1] = lengths[i][j] + 1\n",
    "            else:\n",
    "                lengths[i+1][j+1] = max(lengths[i+1][j], lengths[i][j+1])\n",
    "    x, y = len(a), len(b)\n",
    "    result = lengths[x][y]\n",
    "    return result\n",
    "\n",
    "def discretise(x):\n",
    "    return int(x * 10)\n",
    "\n",
    "def multidim_lcs(a, b):\n",
    "    a = a.applymap(discretise)\n",
    "    b = b.applymap(discretise)\n",
    "    rows, dims = a.shape\n",
    "    lcss = [lcs(a[i+2], b[i+2]) for i in range(dims)]\n",
    "    return 1 - sum(lcss) / (rows * dims)\n",
    "\n",
    "#Correlation\n",
    "def corr(x, y):\n",
    "    r=np.dot(x-mean(x),y-mean(y))/((np.linalg.norm(x-mean(x)))*(np.linalg.norm(y-mean(y))))\n",
    "    if math.isnan(r):\n",
    "        r=0\n",
    "    #print(r)\n",
    "    return 1 - r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "import scipy.cluster.hierarchy as hac\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "\n",
    "DIAMETER_METHODS = ['mean_cluster', 'farthest']\n",
    "CLUSTER_DISTANCE_METHODS = ['nearest', 'farthest']\n",
    "\n",
    "def inter_cluster_distances(labels, distances, method='nearest'):\n",
    "    \"\"\"Calculates the distances between the two nearest points of each cluster.\n",
    "    :param labels: a list containing cluster labels for each of the n elements\n",
    "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
    "    :param method: `nearest` for the distances between the two nearest points in each cluster, or `farthest`\n",
    "    \"\"\"\n",
    "    if method not in CLUSTER_DISTANCE_METHODS:\n",
    "        raise ValueError(\n",
    "            'method must be one of {}'.format(CLUSTER_DISTANCE_METHODS))\n",
    "\n",
    "    if method == 'nearest':\n",
    "        return __cluster_distances_by_points(labels, distances)\n",
    "    elif method == 'farthest':\n",
    "        return __cluster_distances_by_points(labels, distances, farthest=True)\n",
    "\n",
    "\n",
    "def __cluster_distances_by_points(labels, distances, farthest=False):\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    cluster_distances = np.full((n_unique_labels, n_unique_labels),\n",
    "                                float('inf') if not farthest else 0)\n",
    "\n",
    "    np.fill_diagonal(cluster_distances, 0)\n",
    "\n",
    "    for i in np.arange(0, len(labels) - 1):\n",
    "        for ii in np.arange(i, len(labels)):\n",
    "            if labels[i] != labels[ii] and (\n",
    "                (not farthest and\n",
    "                 distances[i, ii] < cluster_distances[labels[i], labels[ii]])\n",
    "                    or\n",
    "                (farthest and\n",
    "                 distances[i, ii] > cluster_distances[labels[i], labels[ii]])):\n",
    "                cluster_distances[labels[i], labels[ii]] = cluster_distances[\n",
    "                    labels[ii], labels[i]] = distances[i, ii]\n",
    "    return cluster_distances\n",
    "\n",
    "\n",
    "def diameter(labels, distances, method='farthest'):\n",
    "    \"\"\"Calculates cluster diameters\n",
    "    :param labels: a list containing cluster labels for each of the n elements\n",
    "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
    "    :param method: either `mean_cluster` for the mean distance between all elements in each cluster, or `farthest` for the distance between the two points furthest from each other\n",
    "    \"\"\"\n",
    "    if method not in DIAMETER_METHODS:\n",
    "        raise ValueError('method must be one of {}'.format(DIAMETER_METHODS))\n",
    "\n",
    "    n_clusters = len(np.unique(labels))\n",
    "    diameters = np.zeros(n_clusters)\n",
    "\n",
    "    if method == 'mean_cluster':\n",
    "        for i in range(0, len(labels) - 1):\n",
    "            for ii in range(i + 1, len(labels)):\n",
    "                if labels[i] == labels[ii]:\n",
    "                    diameters[labels[i]] += distances[i, ii]\n",
    "\n",
    "        for i in range(len(diameters)):\n",
    "            diameters[i] /= sum(labels == i)\n",
    "\n",
    "    elif method == 'farthest':\n",
    "        for i in range(0, len(labels) - 1):\n",
    "            for ii in range(i + 1, len(labels)):\n",
    "                if labels[i] == labels[ii] and distances[i, ii] > diameters[\n",
    "                        labels[i]]:\n",
    "                    diameters[labels[i]] = distances[i, ii]\n",
    "    return diameters\n",
    "\n",
    "def dunn(labels, distances, diameter_method='farthest',\n",
    "         cdist_method='nearest'):\n",
    "    \"\"\"\n",
    "    Dunn index for cluster validation (larger is better).\n",
    "    \n",
    "    .. math:: D = \\\\min_{i = 1 \\\\ldots n_c; j = i + 1\\ldots n_c} \\\\left\\\\lbrace \\\\frac{d \\\\left( c_i,c_j \\\\right)}{\\\\max_{k = 1 \\\\ldots n_c} \\\\left(diam \\\\left(c_k \\\\right) \\\\right)} \\\\right\\\\rbrace\n",
    "    \n",
    "    where :math:`d(c_i,c_j)` represents the distance between\n",
    "    clusters :math:`c_i` and :math:`c_j`, and :math:`diam(c_k)` is the diameter of cluster :math:`c_k`.\n",
    "    Inter-cluster distance can be defined in many ways, such as the distance between cluster centroids or between their closest elements. Cluster diameter can be defined as the mean distance between all elements in the cluster, between all elements to the cluster centroid, or as the distance between the two furthest elements.\n",
    "    The higher the value of the resulting Dunn index, the better the clustering\n",
    "    result is considered, since higher values indicate that clusters are\n",
    "    compact (small :math:`diam(c_k)`) and far apart (large :math:`d \\\\left( c_i,c_j \\\\right)`).\n",
    "    :param labels: a list containing cluster labels for each of the n elements\n",
    "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
    "    :param diameter_method: see :py:function:`diameter` `method` parameter\n",
    "    :param cdist_method: see :py:function:`diameter` `method` parameter\n",
    "    \n",
    "    .. [Kovacs2005] Kovács, F., Legány, C., & Babos, A. (2005). Cluster validity measurement techniques. 6th International Symposium of Hungarian Researchers on Computational Intelligence.\n",
    "    \"\"\"\n",
    "\n",
    "    labels = LabelEncoder().fit(labels).transform(labels)\n",
    "    \n",
    "    \n",
    "\n",
    "    ic_distances = inter_cluster_distances(labels, distances, cdist_method)\n",
    "    #print(\"IC\",ic_distances)\n",
    "    if len(ic_distances[ic_distances.nonzero()])==0:\n",
    "        min_distance = 0\n",
    "    else:\n",
    "        min_distance = min(ic_distances[ic_distances.nonzero()])\n",
    "    max_diameter = max(diameter(labels, distances, diameter_method))\n",
    "    \n",
    "    \n",
    "\n",
    "    return min_distance / max_diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.replace('nan', np.nan).fillna(0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.drop('Distrito', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINICIÓN DEL NÚMERO DE CLUSTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "k=6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz Euclidiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Euclidean\n",
    "f_euclidean_dist = np.zeros((n,n))\n",
    "for i in range(0,n):\n",
    "    #print(\"i\",i)\n",
    "    for j in range(1,n):\n",
    "         f_euclidean_dist[i,j] = euclidean(features.iloc[i].values.flatten(), features.iloc[j].values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('MatrizEuclidiana_FB_K6.csv', f_euclidean_dist, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz Correlación Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corr\n",
    "corr_dist = np.zeros((n,n))\n",
    "for i in range(0,n):\n",
    "    for j in range(0,n):\n",
    "            corr_dist[i,j] = corr(features.iloc[i].values.flatten(), features.iloc[j].values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('MatrizPearson_FB_K6.csv', corr_dist, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz Correlación Spearman "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scorr\n",
    "f_scorr_dist = np.zeros((n,n))\n",
    "for i in range(0,n):\n",
    "    for j in range(0,n):\n",
    "        f_scorr_dist[i,j] = scorr(features.iloc[i].values.flatten(), features.iloc[j].values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('MatrizSpearman_FB_K6.csv', f_scorr_dist, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DTW\n",
    "f_dtw_dist = np.zeros((n,n))\n",
    "for i in range(0,n):\n",
    "    for j in range(0,n):\n",
    "        f_dtw_dist[i,j] = fast_DTW(features.iloc[i].values.flatten(), features.iloc[j].values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('MatrizDTW_FB_K6.csv', f_dtw_dist, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAC + euclidian distance: \n",
      "SC:  0.8369767125735053\n",
      "CHZ:  2742.2766327763857\n",
      "DUNN:  1.2758936028566583\n",
      "DAV-BOUD:  0.3951131390544735\n",
      "HAC + corr distance: \n",
      "SC:  0.6146927927802859\n",
      "CHZ:  1807.2673708790514\n",
      "DUNN:  5.039794930806593\n",
      "DAV-BOUD:  0.4562566129799433\n",
      "HAC + scorr distance: \n",
      "SC:  0.57198661536353\n",
      "CHZ:  386.43085920210643\n",
      "DUNN:  0.0\n",
      "DAV-BOUD:  0.7158918514778642\n",
      "HAC + dtw distance: \n",
      "SC:  0.8270216138722725\n",
      "CHZ:  2699.3107187795003\n",
      "DUNN:  0.38075437571440324\n",
      "DAV-BOUD:  0.34879191461132203\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "#Experimentos HAC\n",
    "HAC_EUCLIDEAN=[]\n",
    "HAC_CORRELATION=[]\n",
    "HAC_SPEARMAN=[]\n",
    "HAC_DTW=[]\n",
    "\n",
    "HAC_EUCLIDEAN_CHZ=[]\n",
    "HAC_CORRELATION_CHZ=[]\n",
    "HAC_SPEARMAN_CHZ=[]\n",
    "HAC_DTW_CHZ=[]\n",
    "\n",
    "HAC_EUCLIDEAN_DUNN=[]\n",
    "HAC_CORRELATION_DUNN=[]\n",
    "HAC_SPEARMAN_DUNN=[]\n",
    "HAC_DTW_DUNN=[]\n",
    "\n",
    "HAC_EUCLIDEAN_DAVID=[]\n",
    "HAC_CORRELATION_DAVID=[]\n",
    "HAC_SPEARMAN_DAVID=[]\n",
    "HAC_DTW_DAVID=[]\n",
    "\n",
    "HAC_euc = AgglomerativeClustering(n_clusters=k).fit_predict(f_euclidean_dist)\n",
    "print(\"HAC + euclidian distance: \")\n",
    "sil = silhouette_score(f_euclidean_dist, HAC_euc)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(f_euclidean_dist, HAC_euc)\n",
    "print(\"CHZ: \", chz)\n",
    "dunn_= dunn(HAC_euc, f_euclidean_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_= davies_bouldin_score(f_euclidean_dist, HAC_euc)\n",
    "print(\"DAV-BOUD: \", david_)\n",
    "HAC_EUCLIDEAN.append(sil)\n",
    "HAC_EUCLIDEAN_CHZ.append(chz)\n",
    "HAC_EUCLIDEAN_DUNN.append(dunn_)\n",
    "HAC_EUCLIDEAN_DAVID.append(david_)\n",
    "\n",
    "HAC_corr = AgglomerativeClustering(n_clusters=k).fit_predict(corr_dist)\n",
    "print(\"HAC + corr distance: \")\n",
    "sil = silhouette_score(corr_dist, HAC_corr)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(corr_dist, HAC_corr)\n",
    "print(\"CHZ: \", chz)\n",
    "dunn_ = dunn(HAC_corr, corr_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_= davies_bouldin_score(corr_dist, HAC_corr)\n",
    "print(\"DAV-BOUD: \", david_)\n",
    "HAC_CORRELATION.append(sil)\n",
    "HAC_CORRELATION_CHZ.append(chz)\n",
    "HAC_CORRELATION_DUNN.append(dunn_)\n",
    "HAC_CORRELATION_DAVID.append(david_)\n",
    "\n",
    "HAC_scorr = AgglomerativeClustering(n_clusters=k).fit_predict(f_scorr_dist)\n",
    "print(\"HAC + scorr distance: \")\n",
    "sil = silhouette_score(f_scorr_dist, HAC_scorr)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(f_scorr_dist, HAC_scorr)\n",
    "print(\"CHZ: \", chz)\n",
    "dunn_ = dunn(HAC_scorr, f_scorr_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_= davies_bouldin_score(f_scorr_dist, HAC_scorr)\n",
    "print(\"DAV-BOUD: \", david_)\n",
    "HAC_SPEARMAN.append(sil)\n",
    "HAC_SPEARMAN_CHZ.append(chz)\n",
    "HAC_SPEARMAN_DUNN.append(dunn_)\n",
    "HAC_SPEARMAN_DAVID.append(david_)\n",
    "\n",
    "HAC_dtw = AgglomerativeClustering(n_clusters=k).fit_predict(f_dtw_dist)\n",
    "print(\"HAC + dtw distance: \")\n",
    "sil = silhouette_score(f_dtw_dist, HAC_dtw)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(f_dtw_dist, HAC_dtw)\n",
    "print(\"CHZ: \", chz)\n",
    "dunn_ = dunn(HAC_dtw, f_dtw_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_= davies_bouldin_score(f_dtw_dist, HAC_dtw)\n",
    "print(\"DAV-BOUD: \", david_)\n",
    "HAC_DTW.append(sil)\n",
    "HAC_DTW_CHZ.append(chz)\n",
    "HAC_DTW_DUNN.append(dunn_)\n",
    "HAC_DTW_DAVID.append(david_)\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KM + euclidian distance: \n",
      "SC:  0.8630194086688542\n",
      "CHZ:  3238.982031182185\n",
      "DUNN:  1.4746546750805811\n",
      "DAV-BOULD:  0.3311495868455252\n",
      "KM + corr distance: \n",
      "SC:  0.6465186244464638\n",
      "CHZ:  2178.141310666236\n",
      "DUNN:  5.068902722050898\n",
      "DAV-BOULD:  0.4590616704078662\n",
      "KM + scorr distance: \n",
      "SC:  0.6019297578764374\n",
      "CHZ:  396.53642220947626\n",
      "DUNN:  0.0\n",
      "DAV-BOULD:  0.694827369793503\n",
      "KM + dtw distance: \n",
      "SC:  0.8610517516273068\n",
      "CHZ:  3164.7370663685992\n",
      "DUNN:  1.4930817578245092\n",
      "DAV-BOULD:  0.32984662213689697\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "KM_EUCLIDEAN=[]\n",
    "KM_CORRELATION=[]\n",
    "KM_SPEARMAN=[]\n",
    "KM_DTW=[]\n",
    "\n",
    "KM_EUCLIDEAN_CHZ=[]\n",
    "KM_CORRELATION_CHZ=[]\n",
    "KM_SPEARMAN_CHZ=[]\n",
    "KM_DTW_CHZ=[]\n",
    "\n",
    "KM_EUCLIDEAN_DUNN=[]\n",
    "KM_CORRELATION_DUNN=[]\n",
    "KM_SPEARMAN_DUNN=[]\n",
    "KM_DTW_DUNN=[]\n",
    "\n",
    "KM_EUCLIDEAN_DAVID=[]\n",
    "KM_CORRELATION_DAVID=[]\n",
    "KM_SPEARMAN_DAVID=[]\n",
    "KM_DTW_DAVID=[]\n",
    "#Experimentos K-Means\n",
    "km_euc = KMeans(n_clusters=k).fit_predict(f_euclidean_dist)\n",
    "print(\"KM + euclidian distance: \")\n",
    "sil = silhouette_score(f_euclidean_dist, km_euc)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(f_euclidean_dist, km_euc)\n",
    "print(\"CHZ: \", chz)\n",
    "dunn_ = dunn(km_euc, f_euclidean_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_ = davies_bouldin_score(f_euclidean_dist, km_euc)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "KM_EUCLIDEAN.append(sil)\n",
    "KM_EUCLIDEAN_CHZ.append(chz)\n",
    "KM_EUCLIDEAN_DUNN.append(dunn_)\n",
    "KM_EUCLIDEAN_DAVID.append(david_)\n",
    "\n",
    "km_corr = KMeans(n_clusters=k).fit_predict(corr_dist)\n",
    "print(\"KM + corr distance: \")\n",
    "sil = silhouette_score(corr_dist, km_corr)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(corr_dist, km_corr)\n",
    "print(\"CHZ: \", chz)\n",
    "dunn_ = dunn(km_corr, corr_dist, 'farthest', 'farthest') \n",
    "print(\"DUNN: \", dunn_)\n",
    "david_ = davies_bouldin_score(corr_dist, km_corr)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "KM_CORRELATION.append(sil)\n",
    "KM_CORRELATION_CHZ.append(chz)\n",
    "KM_CORRELATION_DUNN.append(dunn_)\n",
    "KM_CORRELATION_DAVID.append(david_)\n",
    "\n",
    "km_scorr = KMeans(n_clusters=k).fit_predict(f_scorr_dist)\n",
    "print(\"KM + scorr distance: \")\n",
    "sil = silhouette_score(f_scorr_dist, km_scorr)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(f_scorr_dist, km_scorr)\n",
    "print(\"CHZ: \", chz)\n",
    "dunn_ = dunn(km_scorr, f_scorr_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_ = davies_bouldin_score(f_scorr_dist, km_scorr)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "KM_SPEARMAN.append(sil)\n",
    "KM_SPEARMAN_CHZ.append(chz)\n",
    "KM_SPEARMAN_DUNN.append(dunn_)\n",
    "KM_SPEARMAN_DAVID.append(david_)\n",
    "\n",
    "km_dtw = KMeans(n_clusters=k).fit_predict(f_dtw_dist)\n",
    "print(\"KM + dtw distance: \")\n",
    "sil = silhouette_score(f_dtw_dist, km_dtw)\n",
    "print(\"SC: \", sil)\n",
    "chz = calinski_harabasz_score(f_dtw_dist, km_dtw)\n",
    "print(\"CHZ: \", chz)\n",
    "dunn_ = dunn(km_dtw, f_dtw_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_ = davies_bouldin_score(f_dtw_dist, km_dtw)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "KM_DTW.append(sil)\n",
    "KM_DTW_CHZ.append(chz)\n",
    "KM_DTW_DUNN.append(dunn_)\n",
    "KM_DTW_DAVID.append(david_)\n",
    "print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN + euclidian distance: \n",
      "SC:  0.38137143796771467\n",
      "CHZ:  14.568195181109074\n",
      "DUNN:  0.001842577705547823\n",
      "DAV-BOULD:  1.1297310737849198\n",
      "DBSCAN + corr distance: \n",
      "SC:  0.32026800441110714\n",
      "CHZ:  426.2008139229266\n",
      "DUNN: \n",
      "DAV-BOULD:  0.5146606588804018\n",
      "DBSCAN + scorr distance: \n",
      "SC:  0.5924323213851097\n",
      "CHZ:  158.97621012769451\n",
      "DUNN:  0.0\n",
      "DAV-BOULD:  1.0407991393298126\n",
      "DBSCAN + dtw distance: \n",
      "SC:  0.5175923960115791\n",
      "CHZ:  31.070024281328855\n",
      "DUNN:  1.0007970449603274\n",
      "DAV-BOULD:  1.2133298906377463\n"
     ]
    }
   ],
   "source": [
    "DBSCAN_EUCLIDEAN=[]\n",
    "DBSCAN_CORRELATION=[]\n",
    "DBSCAN_SPEARMAN=[]\n",
    "DBSCAN_DTW=[]\n",
    "\n",
    "DBSCAN_EUCLIDEAN_CHZ=[]\n",
    "DBSCAN_CORRELATION_CHZ=[]\n",
    "DBSCAN_SPEARMAN_CHZ=[]\n",
    "DBSCAN_DTW_CHZ=[]\n",
    "\n",
    "DBSCAN_EUCLIDEAN_DUNN=[]\n",
    "DBSCAN_CORRELATION_DUNN=[]\n",
    "DBSCAN_SPEARMAN_DUNN=[]\n",
    "DBSCAN_DTW_DUNN=[]\n",
    "\n",
    "DBSCAN_EUCLIDEAN_DAVID=[]\n",
    "DBSCAN_CORRELATION_DAVID=[]\n",
    "DBSCAN_SPEARMAN_DAVID=[]\n",
    "DBSCAN_DTW_DAVID=[]\n",
    "\n",
    "#CON EUCLIDEAN\n",
    "DB_euc = DBSCAN(eps=500, min_samples=4).fit_predict(f_euclidean_dist)\n",
    "print(\"DBSCAN + euclidian distance: \")\n",
    "sil =  silhouette_score(f_euclidean_dist, DB_euc)\n",
    "print(\"SC: \", sil)\n",
    "CHZ_ = calinski_harabasz_score(f_euclidean_dist, DB_euc) \n",
    "print(\"CHZ: \", CHZ_)\n",
    "dunn_ = dunn(DB_euc, f_euclidean_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_ = davies_bouldin_score(f_euclidean_dist, DB_euc)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "DBSCAN_EUCLIDEAN.append(sil)\n",
    "DBSCAN_EUCLIDEAN_CHZ.append(CHZ_)\n",
    "DBSCAN_EUCLIDEAN_DUNN.append(dunn_)\n",
    "DBSCAN_EUCLIDEAN_DAVID.append(david_)\n",
    "\n",
    "#CON CORRELATION\n",
    "DB_corr = DBSCAN(eps=0.4, min_samples=4).fit_predict(corr_dist)\n",
    "print(\"DBSCAN + corr distance: \")\n",
    "sil = silhouette_score(corr_dist, DB_corr)\n",
    "print(\"SC: \", sil)\n",
    "CHZ_ = calinski_harabasz_score(corr_dist, DB_corr)\n",
    "print(\"CHZ: \", CHZ_)\n",
    "dunn_ = dunn(DB_corr, corr_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \",)\n",
    "david_ = davies_bouldin_score(corr_dist, DB_corr)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "DBSCAN_CORRELATION.append(sil)\n",
    "DBSCAN_CORRELATION_CHZ.append(CHZ_)\n",
    "DBSCAN_CORRELATION_DUNN.append(dunn_)\n",
    "DBSCAN_CORRELATION_DAVID.append(david_)\n",
    "\n",
    "#CON SPEARMAN\n",
    "DB_scorr = DBSCAN(eps=0.4, min_samples=4).fit_predict(f_scorr_dist)\n",
    "print(\"DBSCAN + scorr distance: \")\n",
    "sil = silhouette_score(f_scorr_dist, DB_scorr)\n",
    "print(\"SC: \", sil)\n",
    "CHZ_ = calinski_harabasz_score(f_scorr_dist, DB_scorr)\n",
    "print(\"CHZ: \", CHZ_)\n",
    "dunn_ = dunn(DB_scorr, f_scorr_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_ = davies_bouldin_score(f_scorr_dist, DB_scorr)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "DBSCAN_SPEARMAN.append(sil)\n",
    "DBSCAN_SPEARMAN_CHZ.append(CHZ_)\n",
    "DBSCAN_SPEARMAN_DUNN.append(dunn_)\n",
    "DBSCAN_SPEARMAN_DAVID.append(david_)\n",
    "\n",
    "#CON D TIME WARPING\n",
    "DB_dtw = DBSCAN(eps=500, min_samples=4).fit_predict(f_dtw_dist)\n",
    "print(\"DBSCAN + dtw distance: \")\n",
    "sil = silhouette_score(f_dtw_dist, DB_dtw)\n",
    "print(\"SC: \", sil)\n",
    "CHZ_ = calinski_harabasz_score(f_dtw_dist, DB_dtw)\n",
    "print(\"CHZ: \", CHZ_)\n",
    "dunn_ = dunn(DB_dtw, f_dtw_dist, 'farthest', 'farthest')\n",
    "print(\"DUNN: \", dunn_)\n",
    "david_ = davies_bouldin_score(f_dtw_dist, DB_dtw)\n",
    "print(\"DAV-BOULD: \", david_)\n",
    "DBSCAN_DTW.append(sil)\n",
    "DBSCAN_DTW_CHZ.append(CHZ_)\n",
    "DBSCAN_DTW_DUNN.append(dunn_)\n",
    "DBSCAN_DTW_DAVID.append(david_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "KM1 = KM_EUCLIDEAN + KM_CORRELATION + KM_SPEARMAN + KM_DTW\n",
    "KM2 = KM_EUCLIDEAN_CHZ + KM_CORRELATION_CHZ + KM_SPEARMAN_CHZ + KM_DTW_CHZ\n",
    "KM3 = KM_EUCLIDEAN_DUNN + KM_CORRELATION_DUNN + KM_SPEARMAN_DUNN + KM_DTW_DUNN\n",
    "KM4 = KM_EUCLIDEAN_DAVID + KM_CORRELATION_DAVID + KM_SPEARMAN_DAVID + KM_DTW_DAVID\n",
    "HAC1 = HAC_EUCLIDEAN + HAC_CORRELATION + HAC_SPEARMAN + HAC_DTW\n",
    "HAC2 = HAC_EUCLIDEAN_CHZ + HAC_CORRELATION_CHZ + HAC_SPEARMAN_CHZ + HAC_DTW_CHZ\n",
    "HAC3 = HAC_EUCLIDEAN_DUNN + HAC_CORRELATION_DUNN + HAC_SPEARMAN_DUNN + HAC_DTW_DUNN\n",
    "HAC4 = HAC_EUCLIDEAN_DAVID + HAC_CORRELATION_DAVID + HAC_SPEARMAN_DAVID + HAC_DTW_DAVID\n",
    "DBS1 = DBSCAN_EUCLIDEAN + DBSCAN_CORRELATION + DBSCAN_SPEARMAN + DBSCAN_DTW\n",
    "DBS2 = DBSCAN_EUCLIDEAN_CHZ + DBSCAN_CORRELATION_CHZ + DBSCAN_SPEARMAN_CHZ + DBSCAN_DTW_CHZ\n",
    "DBS3 = DBSCAN_EUCLIDEAN_DUNN + DBSCAN_CORRELATION_DUNN + DBSCAN_SPEARMAN_DUNN + DBSCAN_DTW_DUNN\n",
    "DBS4 = DBSCAN_EUCLIDEAN_DAVID + DBSCAN_CORRELATION_DAVID + DBSCAN_SPEARMAN_DAVID + DBSCAN_DTW_DAVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_scores = pd.DataFrame()\n",
    "sil_scores['METRICA'] = ['Euclidean Distance', 'Pearson Correlation', 'Spearman Correlation', 'Dynamic Time Warping'] \n",
    "sil_scores['SIL - HAC'] = np.array(HAC1)\n",
    "sil_scores['SIL - KM'] = np.array(KM1)\n",
    "sil_scores['SIL - DB'] = np.array(DBS1)\n",
    "sil_scores['CHZ - HAC'] = np.array(HAC2)\n",
    "sil_scores['CHZ - KM'] = np.array(KM2)\n",
    "sil_scores['CHZ - DB'] = np.array(DBS2)\n",
    "sil_scores['DUNN - HAC'] = np.array(HAC3)\n",
    "sil_scores['DUNN - KM'] = np.array(KM3)\n",
    "sil_scores['DUNN - DB'] = np.array(DBS3)\n",
    "sil_scores['DAVID - HAC'] = np.array(HAC4)\n",
    "sil_scores['DAVID - KM'] = np.array(KM4)\n",
    "sil_scores['DAVID - DB'] = np.array(DBS4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_scores.to_csv('Scores1_FeatureBasedK6.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux2 = pd.DataFrame()\n",
    "aux2['Distrito'] = listaDistrito\n",
    "aux2['Cluster KM'] = km_euc\n",
    "aux2['Cluster HAC '] = HAC_euc\n",
    "aux2['Cluster DB SP'] = DB_corr\n",
    "aux2.to_csv('ClusterFB1_2009al2013K6.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1,  2], dtype=int64)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(DB_euc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5], dtype=int64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(HAC_euc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(km_euc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
