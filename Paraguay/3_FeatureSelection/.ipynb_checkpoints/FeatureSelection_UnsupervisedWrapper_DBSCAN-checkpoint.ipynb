{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELECCION DE ATRIBUTOS WRAPPER - DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import sqrt, log, floor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statistics import mean\n",
    "from fastdtw import fastdtw\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import pdist\n",
    " \n",
    "#Euclidean\n",
    "def euclidean(x, y):\n",
    "    r=np.linalg.norm(x-y)\n",
    "    if math.isnan(r):\n",
    "        r=1\n",
    "    #print(r)\n",
    "    return r\n",
    "\n",
    "#Fast Dynamic time warping\n",
    "def fast_DTW(x, y):\n",
    "    r, _ = fastdtw(x, y, dist=euclidean)\n",
    "    if math.isnan(r):\n",
    "        r=1\n",
    "    #print(r)\n",
    "    return r\n",
    "\n",
    "#Spearman\n",
    "def scorr(x, y):\n",
    "    r = stats.spearmanr(x, y)[0]\n",
    "    if math.isnan(r):\n",
    "        r=0\n",
    "    #print(r)\n",
    "    return 1 - r\n",
    "\n",
    "#RMSE\n",
    "def rmse(x, y):\n",
    "    r=sqrt(mean_squared_error(x,y))\n",
    "    if math.isnan(r):\n",
    "        r=1\n",
    "    #print(r)\n",
    "    return r\n",
    "\n",
    "def lcs(a, b):  \n",
    "    lengths = [[0 for j in range(len(b)+1)] for i in range(len(a)+1)]\n",
    "    # row 0 and column 0 are initialized to 0 already\n",
    "    for i, x in enumerate(a):\n",
    "        for j, y in enumerate(b):\n",
    "            if x == y:\n",
    "                lengths[i+1][j+1] = lengths[i][j] + 1\n",
    "            else:\n",
    "                lengths[i+1][j+1] = max(lengths[i+1][j], lengths[i][j+1])\n",
    "    x, y = len(a), len(b)\n",
    "    result = lengths[x][y]\n",
    "    return result\n",
    "\n",
    "def discretise(x):\n",
    "    return int(x * 10)\n",
    "\n",
    "def multidim_lcs(a, b):\n",
    "    a = a.applymap(discretise)\n",
    "    b = b.applymap(discretise)\n",
    "    rows, dims = a.shape\n",
    "    lcss = [lcs(a[i+2], b[i+2]) for i in range(dims)]\n",
    "    return 1 - sum(lcss) / (rows * dims)\n",
    "\n",
    "#Correlation\n",
    "def corr(x, y):\n",
    "    r=np.dot(x-mean(x),y-mean(y))/((np.linalg.norm(x-mean(x)))*(np.linalg.norm(y-mean(y))))\n",
    "    if math.isnan(r):\n",
    "        r=0\n",
    "    #print(r)\n",
    "    return 1 - r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from yellowbrick.cluster import KElbowVisualizer\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "import scipy.cluster.hierarchy as hac\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "\n",
    "DIAMETER_METHODS = ['mean_cluster', 'farthest']\n",
    "CLUSTER_DISTANCE_METHODS = ['nearest', 'farthest']\n",
    "\n",
    "def inter_cluster_distances(labels, distances, method='nearest'):\n",
    "    \"\"\"Calculates the distances between the two nearest points of each cluster.\n",
    "    :param labels: a list containing cluster labels for each of the n elements\n",
    "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
    "    :param method: `nearest` for the distances between the two nearest points in each cluster, or `farthest`\n",
    "    \"\"\"\n",
    "    if method not in CLUSTER_DISTANCE_METHODS:\n",
    "        raise ValueError(\n",
    "            'method must be one of {}'.format(CLUSTER_DISTANCE_METHODS))\n",
    "\n",
    "    if method == 'nearest':\n",
    "        return __cluster_distances_by_points(labels, distances)\n",
    "    elif method == 'farthest':\n",
    "        return __cluster_distances_by_points(labels, distances, farthest=True)\n",
    "\n",
    "\n",
    "def __cluster_distances_by_points(labels, distances, farthest=False):\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    cluster_distances = np.full((n_unique_labels, n_unique_labels),\n",
    "                                float('inf') if not farthest else 0)\n",
    "\n",
    "    np.fill_diagonal(cluster_distances, 0)\n",
    "\n",
    "    for i in np.arange(0, len(labels) - 1):\n",
    "        for ii in np.arange(i, len(labels)):\n",
    "            if labels[i] != labels[ii] and (\n",
    "                (not farthest and\n",
    "                 distances[i, ii] < cluster_distances[labels[i], labels[ii]])\n",
    "                    or\n",
    "                (farthest and\n",
    "                 distances[i, ii] > cluster_distances[labels[i], labels[ii]])):\n",
    "                cluster_distances[labels[i], labels[ii]] = cluster_distances[\n",
    "                    labels[ii], labels[i]] = distances[i, ii]\n",
    "    return cluster_distances\n",
    "\n",
    "\n",
    "def diameter(labels, distances, method='farthest'):\n",
    "    \"\"\"Calculates cluster diameters\n",
    "    :param labels: a list containing cluster labels for each of the n elements\n",
    "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
    "    :param method: either `mean_cluster` for the mean distance between all elements in each cluster, or `farthest` for the distance between the two points furthest from each other\n",
    "    \"\"\"\n",
    "    if method not in DIAMETER_METHODS:\n",
    "        raise ValueError('method must be one of {}'.format(DIAMETER_METHODS))\n",
    "\n",
    "    n_clusters = len(np.unique(labels))\n",
    "    diameters = np.zeros(n_clusters)\n",
    "\n",
    "    if method == 'mean_cluster':\n",
    "        for i in range(0, len(labels) - 1):\n",
    "            for ii in range(i + 1, len(labels)):\n",
    "                if labels[i] == labels[ii]:\n",
    "                    diameters[labels[i]] += distances[i, ii]\n",
    "\n",
    "        for i in range(len(diameters)):\n",
    "            diameters[i] /= sum(labels == i)\n",
    "\n",
    "    elif method == 'farthest':\n",
    "        for i in range(0, len(labels) - 1):\n",
    "            for ii in range(i + 1, len(labels)):\n",
    "                if labels[i] == labels[ii] and distances[i, ii] > diameters[\n",
    "                        labels[i]]:\n",
    "                    diameters[labels[i]] = distances[i, ii]\n",
    "    return diameters\n",
    "\n",
    "def dunn(labels, distances, diameter_method='farthest',\n",
    "         cdist_method='nearest'):\n",
    "    \"\"\"\n",
    "    Dunn index for cluster validation (larger is better).\n",
    "    \n",
    "    .. math:: D = \\\\min_{i = 1 \\\\ldots n_c; j = i + 1\\ldots n_c} \\\\left\\\\lbrace \\\\frac{d \\\\left( c_i,c_j \\\\right)}{\\\\max_{k = 1 \\\\ldots n_c} \\\\left(diam \\\\left(c_k \\\\right) \\\\right)} \\\\right\\\\rbrace\n",
    "    \n",
    "    where :math:`d(c_i,c_j)` represents the distance between\n",
    "    clusters :math:`c_i` and :math:`c_j`, and :math:`diam(c_k)` is the diameter of cluster :math:`c_k`.\n",
    "    Inter-cluster distance can be defined in many ways, such as the distance between cluster centroids or between their closest elements. Cluster diameter can be defined as the mean distance between all elements in the cluster, between all elements to the cluster centroid, or as the distance between the two furthest elements.\n",
    "    The higher the value of the resulting Dunn index, the better the clustering\n",
    "    result is considered, since higher values indicate that clusters are\n",
    "    compact (small :math:`diam(c_k)`) and far apart (large :math:`d \\\\left( c_i,c_j \\\\right)`).\n",
    "    :param labels: a list containing cluster labels for each of the n elements\n",
    "    :param distances: an n x n numpy.array containing the pairwise distances between elements\n",
    "    :param diameter_method: see :py:function:`diameter` `method` parameter\n",
    "    :param cdist_method: see :py:function:`diameter` `method` parameter\n",
    "    \n",
    "    .. [Kovacs2005] Kovács, F., Legány, C., & Babos, A. (2005). Cluster validity measurement techniques. 6th International Symposium of Hungarian Researchers on Computational Intelligence.\n",
    "    \"\"\"\n",
    "\n",
    "    labels = LabelEncoder().fit(labels).transform(labels)\n",
    "    \n",
    "    \n",
    "\n",
    "    ic_distances = inter_cluster_distances(labels, distances, cdist_method)\n",
    "    #print(\"IC\",ic_distances)\n",
    "    if len(ic_distances[ic_distances.nonzero()])==0:\n",
    "        min_distance = 0\n",
    "    else:\n",
    "        min_distance = min(ic_distances[ic_distances.nonzero()])\n",
    "    max_diameter = max(diameter(labels, distances, diameter_method))\n",
    "    \n",
    "    \n",
    "\n",
    "    return min_distance / max_diameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "my_path = os.path.abspath('')\n",
    "my_path = my_path.split('\\\\')\n",
    "my_path_py = \"\\\\\".join(my_path[:-1])\n",
    "\n",
    "features = pd.read_csv(my_path_py+'\\\\2_FeatureBased\\\\FB2_2009al2013.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Distrito</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Var</th>\n",
       "      <th>ACF1</th>\n",
       "      <th>Trend</th>\n",
       "      <th>Linearity</th>\n",
       "      <th>Curvature</th>\n",
       "      <th>Season</th>\n",
       "      <th>Peak</th>\n",
       "      <th>Trough</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Lumpiness</th>\n",
       "      <th>Spikiness</th>\n",
       "      <th>Lshift</th>\n",
       "      <th>Vchange</th>\n",
       "      <th>Fspots</th>\n",
       "      <th>Cpoints</th>\n",
       "      <th>KlScore</th>\n",
       "      <th>ChangeIdx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ASUNCION</td>\n",
       "      <td>6.904494</td>\n",
       "      <td>5.239362e+01</td>\n",
       "      <td>8.135193e-01</td>\n",
       "      <td>0.922999</td>\n",
       "      <td>0.003082</td>\n",
       "      <td>-0.863262</td>\n",
       "      <td>0.025780</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-0.010495</td>\n",
       "      <td>5.978370e-01</td>\n",
       "      <td>1.772715e-04</td>\n",
       "      <td>2.497263e-09</td>\n",
       "      <td>1.086957e-02</td>\n",
       "      <td>5.250998e-05</td>\n",
       "      <td>172.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FERNANDO DE LA MORA</td>\n",
       "      <td>44.781615</td>\n",
       "      <td>4.841265e+03</td>\n",
       "      <td>9.371226e-01</td>\n",
       "      <td>0.958335</td>\n",
       "      <td>0.007501</td>\n",
       "      <td>0.391511</td>\n",
       "      <td>0.046909</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>-0.010903</td>\n",
       "      <td>1.698908e-01</td>\n",
       "      <td>7.906015e-05</td>\n",
       "      <td>5.201407e-10</td>\n",
       "      <td>1.813156e-01</td>\n",
       "      <td>1.006363e-02</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>PEDRO JUAN CABALLERO</td>\n",
       "      <td>44.819130</td>\n",
       "      <td>1.042302e+04</td>\n",
       "      <td>9.285754e-01</td>\n",
       "      <td>0.962853</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>-0.361289</td>\n",
       "      <td>0.010942</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>-0.004989</td>\n",
       "      <td>1.317796e-01</td>\n",
       "      <td>3.606045e-04</td>\n",
       "      <td>5.397936e-10</td>\n",
       "      <td>6.596210e-02</td>\n",
       "      <td>3.044544e-03</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>YBY YAU</td>\n",
       "      <td>18.306891</td>\n",
       "      <td>8.273701e+02</td>\n",
       "      <td>7.051710e-01</td>\n",
       "      <td>0.879186</td>\n",
       "      <td>0.003470</td>\n",
       "      <td>-0.677443</td>\n",
       "      <td>0.049205</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-0.018949</td>\n",
       "      <td>5.381565e-01</td>\n",
       "      <td>3.756719e-04</td>\n",
       "      <td>3.576345e-09</td>\n",
       "      <td>5.000000e-02</td>\n",
       "      <td>2.083333e-03</td>\n",
       "      <td>120.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>YPANE</td>\n",
       "      <td>59.676847</td>\n",
       "      <td>1.191727e+04</td>\n",
       "      <td>9.103049e-01</td>\n",
       "      <td>0.940326</td>\n",
       "      <td>0.005569</td>\n",
       "      <td>-0.154082</td>\n",
       "      <td>0.019642</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>-0.005024</td>\n",
       "      <td>1.524750e-01</td>\n",
       "      <td>8.255672e-05</td>\n",
       "      <td>1.405710e-09</td>\n",
       "      <td>1.234592e-01</td>\n",
       "      <td>7.082626e-03</td>\n",
       "      <td>84.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>ISLA UMBU</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.984279</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>-0.016121</td>\n",
       "      <td>0.015653</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>3.203435e-11</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>VILLA OLIVA</td>\n",
       "      <td>27.129680</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.984279</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>-0.016121</td>\n",
       "      <td>0.015653</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>3.203435e-11</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>CARMELO PERALTA</td>\n",
       "      <td>23.540490</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.899220</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>-0.144232</td>\n",
       "      <td>0.020585</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>-0.007148</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>2.266590e-03</td>\n",
       "      <td>5.186532e-09</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>191.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>DESMOCHADOS</td>\n",
       "      <td>56.497175</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.984279</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>-0.016121</td>\n",
       "      <td>0.015653</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>3.203435e-11</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>R I 3 CORRALES</td>\n",
       "      <td>10.999890</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.984279</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>-0.016121</td>\n",
       "      <td>0.015653</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>3.203435e-11</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0              Distrito       Mean           Var          ACF1  \\\n",
       "0             0              ASUNCION   6.904494  5.239362e+01  8.135193e-01   \n",
       "1             1   FERNANDO DE LA MORA  44.781615  4.841265e+03  9.371226e-01   \n",
       "2             2  PEDRO JUAN CABALLERO  44.819130  1.042302e+04  9.285754e-01   \n",
       "3             3               YBY YAU  18.306891  8.273701e+02  7.051710e-01   \n",
       "4             4                 YPANE  59.676847  1.191727e+04  9.103049e-01   \n",
       "..          ...                   ...        ...           ...           ...   \n",
       "195         195             ISLA UMBU  33.333333  1.000000e-07  1.000000e-08   \n",
       "196         196           VILLA OLIVA  27.129680  1.000000e-07  1.000000e-08   \n",
       "197         197       CARMELO PERALTA  23.540490  1.000000e-07  1.000000e-08   \n",
       "198         198           DESMOCHADOS  56.497175  1.000000e-07  1.000000e-08   \n",
       "199         199        R I 3 CORRALES  10.999890  1.000000e-07  1.000000e-08   \n",
       "\n",
       "        Trend  Linearity  Curvature    Season          Peak    Trough  \\\n",
       "0    0.922999   0.003082  -0.863262  0.025780  1.000000e+00 -0.010495   \n",
       "1    0.958335   0.007501   0.391511  0.046909  1.000000e-07 -0.010903   \n",
       "2    0.962853   0.004186  -0.361289  0.010942  1.000000e-07 -0.004989   \n",
       "3    0.879186   0.003470  -0.677443  0.049205  1.000000e+00 -0.018949   \n",
       "4    0.940326   0.005569  -0.154082  0.019642  1.000000e-07 -0.005024   \n",
       "..        ...        ...        ...       ...           ...       ...   \n",
       "195  0.984279   0.000052  -0.016121  0.015653  1.000000e-07 -0.001953   \n",
       "196  0.984279   0.000052  -0.016121  0.015653  1.000000e-07 -0.001953   \n",
       "197  0.899220   0.000466  -0.144232  0.020585  1.000000e-07 -0.007148   \n",
       "198  0.984279   0.000052  -0.016121  0.015653  1.000000e-07 -0.001953   \n",
       "199  0.984279   0.000052  -0.016121  0.015653  1.000000e-07 -0.001953   \n",
       "\n",
       "          Entropy     Lumpiness     Spikiness        Lshift       Vchange  \\\n",
       "0    5.978370e-01  1.772715e-04  2.497263e-09  1.086957e-02  5.250998e-05   \n",
       "1    1.698908e-01  7.906015e-05  5.201407e-10  1.813156e-01  1.006363e-02   \n",
       "2    1.317796e-01  3.606045e-04  5.397936e-10  6.596210e-02  3.044544e-03   \n",
       "3    5.381565e-01  3.756719e-04  3.576345e-09  5.000000e-02  2.083333e-03   \n",
       "4    1.524750e-01  8.255672e-05  1.405710e-09  1.234592e-01  7.082626e-03   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "195  1.000000e-08  1.000000e-07  3.203435e-11  1.000000e-07  1.000000e-07   \n",
       "196  1.000000e-08  1.000000e-07  3.203435e-11  1.000000e-07  1.000000e-07   \n",
       "197  1.000000e-08  2.266590e-03  5.186532e-09  1.000000e-07  1.000000e-07   \n",
       "198  1.000000e-08  1.000000e-07  3.203435e-11  1.000000e-07  1.000000e-07   \n",
       "199  1.000000e-08  1.000000e-07  3.203435e-11  1.000000e-07  1.000000e-07   \n",
       "\n",
       "     Fspots  Cpoints       KlScore     ChangeIdx  \n",
       "0     172.0      6.0  1.000000e-10  1.000000e-10  \n",
       "1      49.0     10.0  1.000000e-10  1.000000e-10  \n",
       "2      58.0      2.0  1.000000e-10  1.000000e-10  \n",
       "3     120.0      3.0  1.000000e-10  1.000000e-10  \n",
       "4      84.0      4.0  1.000000e-10  1.000000e-10  \n",
       "..      ...      ...           ...           ...  \n",
       "195   193.0      0.0  1.000000e-10  1.000000e-10  \n",
       "196   193.0      0.0  1.000000e-10  1.000000e-10  \n",
       "197   191.0      1.0  1.000000e-10  1.000000e-10  \n",
       "198   193.0      0.0  1.000000e-10  1.000000e-10  \n",
       "199   193.0      0.0  1.000000e-10  1.000000e-10  \n",
       "\n",
       "[200 rows x 20 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.iloc[:, 1:]\n",
    "listadistrito = features.Distrito.values\n",
    "features = features.drop('Distrito', axis=1)\n",
    "features = features.drop('Mean', axis = 1)\n",
    "features = features.drop('Var', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_excluded = features.columns.tolist()\n",
    "#lista_excluded.insert(0, 'None')\n",
    "#lista_excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mm in list(range(10)):\n",
    "    DB_EUCLIDEAN=[]\n",
    "    DB_CORRELATION=[]\n",
    "    DB_SPEARMAN=[]\n",
    "    DB_DTW=[]\n",
    "    for i in list(range(len(features.columns))):\n",
    "        features2 = features.drop(features.columns[i], axis=1)\n",
    "        #Euclidean\n",
    "        n = features.shape[0]\n",
    "        f_euclidean_dist = np.zeros((n,n))\n",
    "        for i in range(0,n):\n",
    "            #print(\"i\",i)\n",
    "            for j in range(1,n):\n",
    "                #print(\"j\",j)\n",
    "                f_euclidean_dist[i,j] = euclidean(features2.iloc[i].values.flatten(), features2.iloc[j].values.flatten())\n",
    "        #Corr\n",
    "        f_corr_dist = np.zeros((n,n))\n",
    "        for i in range(0,n):\n",
    "            #print(\"i\",i)\n",
    "            for j in range(0,n):\n",
    "               # print(\"j\",j)\n",
    "                f_corr_dist[i,j] = corr(features2.iloc[i].values.flatten(), features2.iloc[j].values.flatten())\n",
    "\n",
    "        #scorr\n",
    "        f_scorr_dist = np.zeros((n,n))\n",
    "        for i in range(0,n):\n",
    "            #print(\"i\",i)\n",
    "            for j in range(0,n):\n",
    "               # print(\"j\",j)\n",
    "                f_scorr_dist[i,j] = scorr(features2.iloc[i].values.flatten(), features2.iloc[j].values.flatten())\n",
    "        #DTW\n",
    "        f_dtw_dist = np.zeros((n,n))\n",
    "        for i in range(0,n):\n",
    "            #print(\"i\",i)\n",
    "            for j in range(0,n):\n",
    "                # print(\"j\",j)\n",
    "                f_dtw_dist[i,j] = fast_DTW(features2.iloc[i].values.flatten(), features2.iloc[j].values.flatten())\n",
    "        print(\"--------------DBSCAN------------------\")\n",
    "        DBSCAN_EUCLIDEAN=[]\n",
    "        DBSCAN_CORRELATION=[]\n",
    "        DBSCAN_SPEARMAN=[]\n",
    "        DBSCAN_DTW=[]\n",
    "\n",
    "        #CON EUCLIDEAN\n",
    "        DB_euc = DBSCAN(eps=35, min_samples=4).fit_predict(f_euclidean_dist)\n",
    "        print(\"DBSCAN + euclidian distance: \")\n",
    "        sil =  silhouette_score(f_euclidean_dist, DB_euc)\n",
    "        print(\"SC: \", sil)\n",
    "        DBSCAN_EUCLIDEAN.append(sil)\n",
    "\n",
    "        #CON D TIME WARPING\n",
    "        DB_dtw = DBSCAN(eps=35, min_samples=4).fit_predict(f_dtw_dist)\n",
    "        print(\"DBSCAN + dtw distance: \")\n",
    "        sil = silhouette_score(f_dtw_dist, DB_dtw)\n",
    "        print(\"SC: \", sil)\n",
    "        DBSCAN_DTW.append(sil)\n",
    "        \n",
    "        #CON CORRELATION\n",
    "        try:\n",
    "            DB_corr = DBSCAN(eps=0.06, min_samples=4).fit_predict(f_corr_dist)\n",
    "            print(\"DBSCAN + corr distance: \")\n",
    "            sil = silhouette_score(f_corr_dist, DB_corr)\n",
    "            print(\"SC: \", sil)\n",
    "            DBSCAN_CORRELATION.append(sil)\n",
    "\n",
    "            #CON SPEARMAN\n",
    "            DB_scorr = DBSCAN(eps=0.06, min_samples=4).fit_predict(f_scorr_dist)\n",
    "            print(\"DBSCAN + scorr distance: \")\n",
    "            sil = silhouette_score(f_scorr_dist, DB_scorr)\n",
    "            print(\"SC: \", sil)\n",
    "            DBSCAN_SPEARMAN.append(sil)\n",
    "        except:\n",
    "            DB_corr = DBSCAN(eps=0.6, min_samples=4).fit_predict(f_corr_dist)\n",
    "            print(\"DBSCAN + corr distance: \")\n",
    "            sil = silhouette_score(f_corr_dist, DB_corr)\n",
    "            print(\"SC: \", sil)\n",
    "            DBSCAN_CORRELATION.append(sil)\n",
    "\n",
    "            #CON SPEARMAN\n",
    "            DB_scorr = DBSCAN(eps=0.6, min_samples=4).fit_predict(f_scorr_dist)\n",
    "            print(\"DBSCAN + scorr distance: \")\n",
    "            sil = silhouette_score(f_scorr_dist, DB_scorr)\n",
    "            print(\"SC: \", sil)\n",
    "            DBSCAN_SPEARMAN.append(sil)\n",
    "            \n",
    "    print(\"Máximo de Euclidean \", np.argmax(DBSCAN_EUCLIDEAN))\n",
    "    print(\"Máximo de Pearson \", np.argmax(DBSCAN_CORRELATION))\n",
    "    print(\"Máximo de Spearman \", np.argmax(DBSCAN_SPEARMAN))\n",
    "    print(\"Máximo de DWT \", np.argmax(DBSCAN_DTW))  \n",
    "    print(\"ELIMINANDO \", lista_excluded[np.argmax(DBSCAN_SPEARMAN)])\n",
    "    del lista_excluded[np.argmax(DBSCAN_SPEARMAN)]\n",
    "    max_DB_SPEARMAN = max(DBSCAN_SPEARMAN)\n",
    "    features = features.drop(features.columns[np.argmax(DBSCAN_SPEARMAN)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('SeleccionadosPorEliminacionDBScan', 'w') as f:\n",
    "      \n",
    "    # using csv.writer method from CSV package\n",
    "    write = csv.writer(f)\n",
    "      \n",
    "    write.writerow(lista_excluded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
